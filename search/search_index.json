{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83d\ude80 PG-DITISS: IT Infrastructure &amp; DevOps","text":""},{"location":"#about-the-course","title":"\ud83c\udf10 About the Course","text":"<p>The Post Graduate Diploma in IT Infrastructure &amp; Systems Security (PG-DITISS) blends theory, labs, and real-world simulations to prepare you for the rapidly evolving world of cloud, data centers, and DevOps practices.  </p> <p>Think of this course not as a classroom, but as your onboarding at TechOps Inc. \u2013 a fictional tech company where you\u2019ll play the role of a DevOps Engineer, Cloud Architect, or System Administrator. You\u2019ll solve real challenges, build scalable systems, and automate workflows \u2014 just like in industry.</p>"},{"location":"#what-youll-learn","title":"\ud83c\udfaf What You\u2019ll Learn","text":"<ul> <li>How to design, manage, and secure data centers.  </li> <li>The power of virtualization, SANs, and cloud platforms.  </li> <li>Hands-on DevOps tools: Git, Jenkins, Docker, Kubernetes, Terraform, Ansible.  </li> <li>Building CI/CD pipelines and deploying microservices at scale.  </li> <li>Automating infrastructure and monitoring systems like an enterprise pro.  </li> </ul>"},{"location":"#course-structure","title":"\ud83c\udfd7\ufe0f Course Structure","text":"<p>The course is structured into 3 Phases + Foundation. Each phase includes theory + labs (2\u20136 hours per module) and culminates in checkpoints that mimic real workplace reviews.</p>"},{"location":"#foundation-phase-0-agile-devops-mindset","title":"\ud83d\udcd6 Foundation (Phase 0) \u2013 Agile &amp; DevOps Mindset","text":"<ul> <li>Agile, Scrum, Kanban, Lean Thinking.  </li> <li>Slack, Jira, GitHub onboarding.  </li> <li>Labs: Team collaboration, backlog creation, Kanban workflows.  </li> </ul>"},{"location":"#phase-1-data-center-management","title":"\ud83c\udfe2 Phase 1 \u2013 Data Center Management","text":"<ul> <li>Data center architecture, power, cooling, networks, and site selection.  </li> <li>Infrastructure: cabling, WAN links, NOC operations, servers, and DR planning.  </li> <li>Security: physical, logical, and internet-level protections.  </li> <li>Labs: Design a data center for TechOps Inc. with budget and resilience constraints.  </li> </ul>"},{"location":"#phase-2-virtualization-cloud","title":"\u2601\ufe0f Phase 2 \u2013 Virtualization &amp; Cloud","text":"<ul> <li>Virtualization concepts, hypervisors, and clusters.  </li> <li>SAN design and high availability labs.  </li> <li>Cloud computing with OpenStack, AWS, Azure, GCP.  </li> <li>Labs: Deploy VMs, configure SAN, launch EC2 instances, simulate cloud migration, set up monitoring.  </li> </ul>"},{"location":"#phase-3-devops","title":"\u26a1 Phase 3 \u2013 DevOps","text":"<ul> <li>DevOps lifecycle and culture.  </li> <li>Git, Jenkins, Docker, Kubernetes basics \u2192 advanced orchestration.  </li> <li>Infrastructure as Code with Terraform.  </li> <li>Microservices deployment and automation with Ansible.  </li> <li>Labs: End-to-end CI/CD pipeline, Terraform infra, Kubernetes microservices, Ansible playbooks.  </li> </ul>"},{"location":"#course-experience","title":"\ud83c\udfae Course Experience","text":"<ul> <li>Simulation: You\u2019re part of TechOps Inc. \u2014 every lab is a mission.  </li> <li>Gamification: Earn badges for completing sprints, solving outages, or optimizing deployments.  </li> <li>Collaboration: Work in squads, review each other\u2019s code, and submit via GitHub PRs.  </li> <li>Evaluation:  </li> <li>40% Theory Exam  </li> <li>40% Lab Exam  </li> <li>20% Internal Assessment (sprints, checkpoints, peer reviews)  </li> </ul>"},{"location":"#tools-youll-use","title":"\ud83d\udee0\ufe0f Tools You\u2019ll Use","text":"<ul> <li>VirtualBox, FreeNAS (TrueNAS CORE), MinIO.  </li> <li>AWS Free Tier, Azure for Students, OpenStack.  </li> <li>Docker, Kubernetes (Minikube).  </li> <li>Jenkins, GitHub Actions, Terraform, Ansible.  </li> <li>Nagios, Prometheus.  </li> <li>Ansible, Chef</li> </ul>"},{"location":"#why-this-course-stands-out","title":"\ud83c\udf1f Why This Course Stands Out","text":"<ul> <li>Hands-on first: Every session ties to a lab.  </li> <li>Industry workflows: GitHub repos, CI/CD pipelines, team retrospectives.  </li> <li>Career-ready skills: Everything you do here mirrors real DevOps engineer roles.  </li> <li>Innovation focus: Learn not just to use tools, but to design and optimize infrastructure.  </li> </ul>"},{"location":"#next-steps","title":"\ud83d\udccc Next Steps","text":"<ul> <li>Start with Syllabus for a detailed breakdown.  </li> <li>Join the Slack workspace and set up your Jira board (see Phase 0 Lab 00).  </li> <li>Clone the starter GitHub repo and get ready to push your first PR.  </li> </ul> <p>Welcome aboard, Engineer. Your first sprint at TechOps Inc. begins now. \ud83d\ude80</p>"},{"location":"about/overview/","title":"Course Overview \u2014 IT Infrastructure &amp; DevOps","text":"<p>Welcome to PG-DITISS Aug 2025 \u2014 IT Infrastructure &amp; DevOps.</p> <p>This course prepares students to design, deploy, automate, and operate modern IT infrastructure using both on-premise systems and cloud platforms, while adopting DevOps principles for agility and reliability.</p>"},{"location":"about/overview/#learning-outcomes","title":"Learning Outcomes","text":"<p>By the end of the course, students will be able to:</p> <ul> <li>Explain the key components of IT infrastructure: compute, storage, networking, virtualization, cloud.</li> <li>Design and simulate a data center with realistic constraints.</li> <li>Configure NAS and SAN storage solutions.</li> <li>Build and manage VM clusters and hybrid cloud deployments (AWS Free Tier).</li> <li>Containerize applications with Docker and orchestrate with Kubernetes/Minikube.</li> <li>Automate infrastructure provisioning with Ansible and Terraform.</li> <li>Set up CI/CD pipelines with Jenkins/GitHub Actions.</li> <li>Implement monitoring and logging with Prometheus &amp; Grafana.</li> <li>Enforce security practices, IAM, secrets management, and high availability designs.</li> </ul>"},{"location":"about/overview/#teaching-approach","title":"Teaching Approach","text":"<ul> <li>Simulation-based: Students act as teams inside a fictional company \u2014 TechOps Inc.</li> <li>Agile methodology: Slack for communication, Taiga for sprint planning &amp; backlog management.</li> <li>Hands-on labs: 44 hours of guided labs using open-source and cloud-free tier tools.</li> <li>Gamification: Badges, checkpoints, and a \u201cBest Performing Company\u201d award.</li> <li>Evaluation mix:</li> <li>Theory exam: 40%</li> <li>Lab exam: 40%</li> <li>Internal assessment (participation, documentation, teamwork): 20%</li> </ul>"},{"location":"about/overview/#course-structure","title":"Course Structure","text":"<ul> <li>Session 0: Agile &amp; Tools setup (Slack, Taiga, GitHub)</li> <li>Sessions 6\u20139: Infrastructure Foundations</li> <li>Sessions 10\u201313: Virtualization &amp; Cloud</li> <li>Sessions 14\u201317: DevOps Foundations</li> <li>Sessions 18\u201320: CI/CD &amp; Monitoring</li> <li>Sessions 21\u201323: Security &amp; HA, Final Integration</li> </ul> <p>Each session includes: Objectives \u00b7 Theory \u00b7 Lab \u00b7 Scenario \u00b7 Quiz \u00b7 Deliverables \u00b7 Rubric.</p>"},{"location":"about/overview/#primary-reference","title":"Primary Reference","text":"<ul> <li>Cloud Computing Black Book (Wiley India, 2024)   by Kogent Learning Solutions Inc., Kailash Jayaswal</li> </ul> <p>Additional references: AWS, Docker, Kubernetes, Jenkins, Ansible, Terraform, Prometheus, Grafana documentation.</p>"},{"location":"capstone/01_overview/","title":"\ud83d\udcd8 Capstone Project \u2014 TechOps Inc. Cloud-Native Build","text":""},{"location":"capstone/01_overview/#project-introduction","title":"\ud83d\ude80 Project Introduction","text":"<p>Welcome to your final capstone project! Over three days (22 hours), you and your team will function as a mini company inside TechOps Inc.. Each team receives its own AWS account and must collaboratively design, provision, configure, deploy, and operate a cloud-native application pipeline with real-world tools.</p> <p>Unlike earlier labs, this project is end-to-end: You will build everything from infrastructure to application monitoring while working in assigned roles (IAM, Architect, Network, SysAdmin, Storage, Monitoring, Developers, DevOps, Scrum Master).  </p> <p>The ultimate goal: Deliver a working web application running in both staging and production, deployed via Jenkins pipelines, containerized with Docker, monitored with Prometheus/Grafana or Nagios, and backed up with runbooks and recovery plans.</p>"},{"location":"capstone/01_overview/#learning-objectives","title":"\ud83c\udfaf Learning Objectives","text":"<p>By the end of this Capstone, you will be able to:</p> <ul> <li>Provision infrastructure as code using Terraform Cloud.  </li> <li>Manage users, roles, and permissions with AWS IAM.  </li> <li>Build and configure a self-hosted Jenkins server.  </li> <li>Create CI/CD pipelines that build Docker images, push them to Docker Hub, and deploy to staging &amp; production.  </li> <li>Deploy a containerized web application on EC2.  </li> <li>Implement monitoring &amp; alerting with Prometheus/Grafana or Nagios.  </li> <li>Configure backup &amp; restore workflows for Jenkins.  </li> <li>Write runbooks for incidents, outages, and recovery.  </li> <li>Collaborate as a real DevOps team using GitHub + Jira under Scrum practices.  </li> </ul>"},{"location":"capstone/01_overview/#project-architecture","title":"\ud83c\udfd7\ufe0f Project Architecture","text":"<p>Your system will include:</p> <ul> <li>IAM &amp; Governance: Roles for each function, least-privilege policies.  </li> <li>Networking: VPC, subnets, routing, security groups.  </li> <li>Infrastructure: EC2 instances for Jenkins, staging app, production app, monitoring server.  </li> <li>Configuration Management: Ansible for Jenkins and host setup.  </li> <li>Application Layer: Sample web app (frontend + backend + SQLite DB).  </li> <li>CI/CD: Jenkins pipelines (checkout \u2192 test \u2192 build \u2192 push \u2192 deploy).  </li> <li>Container Registry: Docker Hub (team namespace).  </li> <li>Monitoring: Prometheus + Grafana (or Nagios) with dashboards and alerts.  </li> <li>Storage: S3 buckets for backups and (optionally) Terraform state.  </li> <li>Collaboration: GitHub repo for code + Jira for agile tracking.  </li> </ul>"},{"location":"capstone/01_overview/#roles-responsibilities","title":"\ud83d\udc65 Roles &amp; Responsibilities","text":"<p>Each student assumes a dedicated role, simulating how real small companies work:</p> <ul> <li>Project Owner / IAM Engineer \u2014 Sets up AWS account, IAM policies, Terraform Cloud workspace.  </li> <li>Architect \u2014 Designs repo structure, ensures staging/prod separation, defines standards.  </li> <li>Network Engineers \u2014 Build VPC, subnets, and SGs with Terraform.  </li> <li>SysAdmin / Infra \u2014 Provision EC2 (Jenkins, apps, monitoring), bootstrap with Ansible.  </li> <li>Storage \u2014 Manage S3 buckets, EBS volumes, and backup workflows.  </li> <li>Monitoring \u2014 Deploy Prometheus/Grafana (or Nagios), configure exporters &amp; alerts.  </li> <li>Developers \u2014 Write app code, Dockerfiles, and unit tests.  </li> <li>DevOps \u2014 Create Jenkins pipelines, integrate GitHub &amp; Docker Hub, manage staging \u2192 prod rollout.  </li> <li>Scrum Master \u2014 Manage Jira board, coordinate tasks, ensure team velocity.  </li> </ul>"},{"location":"capstone/01_overview/#tools-you-will-use","title":"\ud83d\udd27 Tools You Will Use","text":"<ul> <li>AWS \u2014 EC2, IAM, S3, VPC  </li> <li>Terraform Cloud \u2014 Infrastructure as Code (IaC)  </li> <li>Ansible \u2014 Configuration management  </li> <li>Jenkins \u2014 CI/CD orchestrator  </li> <li>Docker + Docker Hub \u2014 Containerization and registry  </li> <li>Prometheus + Grafana / Nagios \u2014 Monitoring and dashboards  </li> <li>SQLite \u2014 Lightweight DB for app  </li> <li>GitHub \u2014 Version control  </li> <li>Jira \u2014 Agile project tracking  </li> </ul>"},{"location":"capstone/01_overview/#execution-plan-3-day-intensive","title":"\ud83d\udcc5 Execution Plan (3-Day Intensive)","text":"<p>Day 1 (4 hrs) - Setup AWS account &amp; Terraform Cloud workspace. - IAM roles/users created; team onboarded. - Provision networking (VPC, subnets, SGs). - Initialize GitHub repo with Terraform structure.  </p> <p>Day 2 (9 hrs) - Provision EC2 hosts (Jenkins, staging app, prod app, monitoring). - Jenkins installed &amp; configured (Ansible). - Developers build &amp; dockerize app. - Jenkins credentials configured for Docker Hub. - First Jenkins build runs (build \u2192 push).  </p> <p>Day 3 (9 hrs) - Extend pipelines: deploy to staging &amp; production. - Deploy monitoring stack (Prometheus/Grafana or Nagios). - Configure alerts &amp; dashboards. - Setup backup jobs (Jenkins \u2192 S3). - Conduct incident drill &amp; finalize runbook. - Deliver final demo: app live in staging &amp; production.  </p>"},{"location":"capstone/01_overview/#deliverables","title":"\ud83d\udce6 Deliverables","text":"<ol> <li>GitHub Repo containing:  </li> <li>Terraform code (network, infra, Jenkins, monitoring).  </li> <li>Ansible playbooks.  </li> <li>Application code (frontend + backend + SQLite).  </li> <li>Jenkinsfiles.  </li> <li> <p>Documentation (<code>architecture.md</code>, <code>runbook.md</code>, <code>README.md</code>).  </p> </li> <li> <p>Terraform Cloud Workspace with remote state.  </p> </li> <li>Working Jenkins Instance with CI/CD pipelines.  </li> <li>Live App in staging &amp; production.  </li> <li>Monitoring Dashboard (Grafana/Nagios).  </li> <li>Final Demo &amp; Presentation.  </li> </ol>"},{"location":"capstone/01_overview/#evaluation-rubric","title":"\ud83d\udcdd Evaluation Rubric","text":"<ul> <li>Infrastructure &amp; IAM setup \u2014 20%  </li> <li>Jenkins CI/CD pipelines \u2014 25%  </li> <li>Application deployment (staging + prod) \u2014 20%  </li> <li>Monitoring &amp; backup/recovery \u2014 15%  </li> <li>Team collaboration &amp; documentation \u2014 20%  </li> </ul>"},{"location":"capstone/01_overview/#labs-table-of-contents","title":"\ud83d\udcda Labs \u2014 Table of Contents","text":"<pre><code>- [Lab 01: Pre-Requisites &amp; Local Setup](lab01.md) \u2014 All Roles\n- [Lab 02: GitHub Repo &amp; Project Structure](lab02.md) \u2014 Architect\n- [Lab 03: AWS IAM Setup](lab03.md) \u2014 IAM Engineer\n- [Lab 04: Terraform Cloud Setup &amp; Workspace](lab04.md) \u2014 IAM Engineer, Architect\n- [Lab 05: Networking with Terraform (VPC, Subnets, SGs)](lab05.md) \u2014 Network Engineers\n- [Lab 06: Provision Jenkins EC2 with Terraform](lab06.md) \u2014 SysAdmin / Infra\n- [Lab 07: Bootstrap Jenkins with Ansible](lab07.md) \u2014 SysAdmin / Infra\n- [Lab 08: Configure Jenkins Credentials](lab08.md) \u2014 SysAdmin / Infra, DevOps\n- [Lab 09: Build Sample App &amp; Dockerize](lab09.md) \u2014 Developers\n- [Lab 10: Push Images to Docker Hub](lab10.md) \u2014 Developers, DevOps\n- [Lab 11: Jenkins Pipeline Setup (CI)](lab11.md) \u2014 DevOps\n- [Lab 12: Deploy to Staging (CD)](lab12.md) \u2014 DevOps\n- [Lab 13: Deploy to Production (CD)](lab13.md) \u2014 DevOps\n- [Lab 14: Monitoring Setup (Prometheus/Grafana or Nagios)](lab14.md) \u2014 Monitoring\n- [Lab 15: Configure Alerts &amp; Dashboards](lab15.md) \u2014 Monitoring\n- [Lab 16: Backup &amp; Restore Jenkins](lab16.md) \u2014 Storage, SysAdmin\n- [Lab 17: Incident Drill &amp; Runbook Validation](lab17.md) \u2014 All Roles\n- [Lab 18: Final Demo &amp; Presentation Prep](lab18.md) \u2014 All Roles\n</code></pre>"},{"location":"capstone/01_overview/#final-note","title":"\u2705 Final Note","text":"<p>Think of yourself as an engineer in a small DevOps company. Your team\u2019s success depends on collaboration, documentation, and working systems \u2014 not just theory. By the end, you\u2019ll have portfolio-ready, real-world DevOps experience.</p>"},{"location":"capstone/02_labs_guide/","title":"\ud83e\uddd1\u200d\ud83d\udcbb Capstone Labs Guide \u2014 TechOps Inc.","text":"<p>This guide helps you navigate all Capstone labs with clarity. It shows which role is responsible, and which labs can run in parallel to optimize the 3-day schedule.  </p>"},{"location":"capstone/02_labs_guide/#labs-table","title":"\ud83d\udccb Labs Table","text":"Lab No. Lab Name Roles Responsible Can Run in Parallel With Lab 01 Pre-Requisites &amp; Local Setup All Roles \u2014 (must be first) Lab 02 GitHub Repo &amp; Project Structure Architect Lab 03 (IAM Setup) Lab 03 AWS IAM Setup IAM Engineer Lab 02 (Repo Setup) Lab 04 Terraform Cloud Setup &amp; Workspace IAM Engineer, Architect After Lab 02 &amp; 03 Lab 05 Networking with Terraform (VPC, Subnets, SGs) Network Engineers \u2014 (infra dependency) Lab 06 Provision Jenkins EC2 with Terraform SysAdmin / Infra Lab 09 (App Build) can start in parallel Lab 07 Bootstrap Jenkins with Ansible SysAdmin / Infra Must follow Lab 06 Lab 08 Configure Jenkins Credentials SysAdmin / Infra, DevOps Can overlap with Lab 09 Lab 09 Build Sample App &amp; Dockerize Developers Parallel to Lab 06/07 Lab 10 Push Images to Docker Hub Developers, DevOps After Lab 09 Lab 11 Jenkins Pipeline Setup (CI) DevOps Needs Lab 08 &amp; 10 completed Lab 12 Deploy to Staging (CD) DevOps Sequential after Lab 11 Lab 13 Deploy to Production (CD) DevOps Sequential after Lab 12 Lab 14 Monitoring Setup (Prometheus/Grafana or Nagios) Monitoring Can start after Lab 06 (infra ready) Lab 15 Configure Alerts &amp; Dashboards Monitoring After Lab 14 Lab 16 Backup &amp; Restore Jenkins Storage, SysAdmin Can run in parallel with Lab 14/15 Lab 17 Incident Drill &amp; Runbook Validation All Roles Final day (depends on 12, 15, 16) Lab 18 Final Demo &amp; Presentation Prep All Roles Last activity"},{"location":"capstone/02_labs_guide/#parallelization-strategy","title":"\u26a1 Parallelization Strategy","text":"<ul> <li> <p>Day 1 (Setup):   Labs 02 + 03 can run in parallel.   Labs 04 \u2192 05 must follow sequentially.  </p> </li> <li> <p>Day 2 (Build &amp; Infra):   Labs 06 (Jenkins EC2) and 09 (App build) can proceed in parallel.   Lab 07 (Jenkins Ansible) must wait for 06.   Lab 08 (Credentials) can overlap with app-related work (09 \u2192 10).  </p> </li> <li> <p>Day 3 (Integration &amp; Monitoring):   DevOps flows (11 \u2192 12 \u2192 13) are sequential.   Monitoring (14 \u2192 15) can run parallel to deployments.   Backup (16) can run alongside monitoring tasks.   Incident Drill (17) only after deployments &amp; monitoring.  </p> </li> </ul>"},{"location":"capstone/02_labs_guide/#pro-tip","title":"\u2705 Pro Tip","text":"<p>Use Scrum-style coordination: - Daily syncs (15 mins max). - Assign dependencies clearly. - Document everything in your repo as you go.  </p>"},{"location":"capstone/03_lab01/","title":"03 lab01","text":"<p>Great \ud83d\udc4d \u2014 using the Capstone Lab Generation Master Prompt, here is the first lab (Lab 01) fully written out.</p>"},{"location":"capstone/03_lab01/#lab-01-pre-requisites-local-setup","title":"Lab 01: Pre-Requisites &amp; Local Setup","text":""},{"location":"capstone/03_lab01/#roles-responsible","title":"Role(s) Responsible","text":"<p>All Roles \u2014 Every student must complete this lab before continuing.</p>"},{"location":"capstone/03_lab01/#objectives","title":"Objectives","text":"<ul> <li>Set up all required local tools for the Capstone Project.</li> <li>Verify access to AWS, Terraform Cloud, GitHub, Docker Hub.</li> <li>Ensure a consistent working environment across all team members.</li> </ul>"},{"location":"capstone/03_lab01/#pre-requisites","title":"Pre-Requisites","text":"<ul> <li>Personal AWS account (already created, Free Tier).</li> <li>Terraform Cloud account (sign up at Terraform Cloud).</li> <li>GitHub account.</li> <li>Docker Hub account.</li> <li>Laptop/VM running Linux/macOS (Windows with WSL2 also supported).</li> </ul>"},{"location":"capstone/03_lab01/#step-by-step-instructions","title":"Step-by-Step Instructions","text":""},{"location":"capstone/03_lab01/#1-install-aws-cli-v2","title":"1. Install AWS CLI v2","text":"<pre><code># Linux\nsudo apt install unzip -y\ncurl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\nunzip awscliv2.zip\nsudo ./aws/install\n\n# Verify\naws --version\n</code></pre>"},{"location":"capstone/03_lab01/#2-configure-aws-cli","title":"2. Configure AWS CLI","text":"<p>Ask your IAM Engineer (Project Owner) for AWS Access Key + Secret. Then:</p> <p>Tip</p> <p>You can do this step once IAM Engineer has done configuring your access</p> <pre><code>aws configure\n# AWS Access Key ID: &lt;provided&gt;\n# AWS Secret Access Key: &lt;provided&gt;\n# Default region: ap-south-1  (or as defined by Architect)\n# Output format: json\n</code></pre> <p>Validate:</p> <pre><code>aws sts get-caller-identity\n</code></pre> <p>Expected: Your AWS user ARN.</p>"},{"location":"capstone/03_lab01/#3-install-terraform-cli","title":"3. Install Terraform CLI","text":"<pre><code># Linux\nsudo apt-get update &amp;&amp; sudo apt-get install -y gnupg software-properties-common curl\ncurl -fsSL https://apt.releases.hashicorp.com/gpg | sudo apt-key add -\nsudo apt-add-repository \"deb [arch=amd64] https://apt.releases.hashicorp.com $(lsb_release -cs) main\"\nsudo apt-get update &amp;&amp; sudo apt-get install terraform\n\n# Verify\nterraform -version\n</code></pre>"},{"location":"capstone/03_lab01/#4-log-into-terraform-cloud","title":"4. Log Into Terraform Cloud","text":"<p>Generate a User Token:</p> <ul> <li>Go to Terraform Cloud \u2192 Account Settings \u2192 Tokens \u2192 Create an API token.</li> <li>Copy the token and keep it somewhere safe, as Terraform does not display it again</li> </ul> <p>On CLI:</p> <pre><code>terraform login\n</code></pre> <p>Paste token when prompted. Validation:</p> <pre><code>terraform -help\n# should not error\n</code></pre>"},{"location":"capstone/03_lab01/#5-install-ansible","title":"5. Install Ansible","text":"<pre><code># Ubuntu\nsudo apt update\nsudo apt install -y ansible\n\n# Verify\nansible --version\n</code></pre>"},{"location":"capstone/03_lab01/#6-install-docker","title":"6. Install Docker","text":"<pre><code># Ubuntu\nsudo apt-get update\nsudo apt-get install -y docker.io docker-compose\nsudo systemctl enable docker\nsudo systemctl start docker\n\n# Add your user to docker group\nsudo usermod -aG docker $USER\nnewgrp docker\n\n# Verify\ndocker run hello-world\n</code></pre>"},{"location":"capstone/03_lab01/#7-configure-git","title":"7. Configure Git","text":"<pre><code>sudo apt-get install git -y\ngit config --global user.name \"Your Name\"\ngit config --global user.email \"you@example.com\"\n</code></pre> <p>Generate SSH key for GitHub:</p> <pre><code>ssh-keygen -t rsa -b 4096 -C \"you@example.com\"\ncat ~/.ssh/id_rsa.pub\n</code></pre> <p>Copy the key into GitHub \u2192 Settings \u2192 SSH and GPG keys \u2192 New Key.</p> <p>Test:</p> <pre><code>ssh -T git@github.com\n</code></pre>"},{"location":"capstone/03_lab01/#8-create-accounts-for-registries","title":"8. Create Accounts for Registries","text":"<ul> <li>Log into Docker Hub and note your username.</li> <li>Share Docker Hub usernames with DevOps for later pipeline setup.</li> </ul>"},{"location":"capstone/03_lab01/#checkpoint-validation","title":"Checkpoint / Validation","text":"<ul> <li>Run:</li> </ul> <p><pre><code>aws sts get-caller-identity\nterraform -version\nansible --version\ndocker --version\ngit --version\n</code></pre> * Confirm all tools return versions without errors. * Run <code>docker run hello-world</code> and confirm successful message.</p>"},{"location":"capstone/03_lab01/#troubleshooting-tips","title":"Troubleshooting Tips","text":"<ul> <li>AWS CLI error \u2192 check if credentials are correct, ensure IAM role has permissions.</li> <li>Docker permission denied \u2192 ensure user is added to <code>docker</code> group, re-login.</li> <li>Terraform login fails \u2192 regenerate token from Terraform Cloud.</li> <li>GitHub SSH auth fails \u2192 check that your SSH key was added correctly to GitHub.</li> </ul>"},{"location":"capstone/03_lab01/#deliverables","title":"Deliverables","text":"<ul> <li> <p>Screenshot of:</p> </li> <li> <p><code>aws sts get-caller-identity</code> output.</p> </li> <li><code>terraform -version</code>, <code>ansible --version</code>, <code>docker run hello-world</code>.</li> <li>GitHub SSH key test (<code>ssh -T git@github.com</code>).</li> </ul>"},{"location":"capstone/03_lab01/#reflection-question","title":"Reflection Question","text":"<p>Why do we use Terraform Cloud for managing state instead of keeping <code>.tfstate</code> files locally or in GitHub?</p> <p>\u2705 This completes Lab 01: Pre-Requisites &amp; Local Setup.</p>"},{"location":"capstone/04_lab02/","title":"Lab 02: GitHub Repo &amp; Project Structure","text":""},{"location":"capstone/04_lab02/#roles-responsible","title":"Role(s) Responsible","text":"<p>Architect</p> <p>Role</p> <p>This lab is to be only performed by the team \"Architect\".</p>"},{"location":"capstone/04_lab02/#objectives","title":"Objectives","text":"<ul> <li>Create a team GitHub repository for the Capstone Project.</li> <li>Define the directory structure for infrastructure, app code, Ansible, CI/CD, and docs.</li> <li>Add collaborators (all team members) with correct permissions.</li> <li>Verify that the repository is ready to be linked with Terraform Cloud (next lab).</li> </ul>"},{"location":"capstone/04_lab02/#pre-requisites","title":"Pre-requisites","text":"<ul> <li>Completion of Lab 01: Pre-Requisites &amp; Local Setup.</li> <li>Architect has a GitHub account.</li> <li>All teammates have GitHub accounts.</li> </ul>"},{"location":"capstone/04_lab02/#step-by-step-instructions","title":"Step-by-Step Instructions","text":""},{"location":"capstone/04_lab02/#1-create-a-new-orgnization-for-your-team","title":"1. Create a New Orgnization for your team","text":"<ol> <li>Log in to GitHub.</li> <li>Click on your user picture, top right corner -&gt; Click on Organizations</li> <li>Click on <code>New Organization</code></li> <li>Choose the Free plan -&gt; <code>Create a free organization</code></li> <li>Enter following details:<ol> <li>Organization name: <code>ditiis-&lt;your-team-name&gt;</code></li> <li>Contact Email: Your personal email address</li> <li>This orgnization belongs to: <code>My personal account</code></li> <li>Verify your account</li> <li>Click on <code>Next</code></li> </ol> </li> <li>Add all of your team members to the orgization by typing their usernames/email addresses</li> <li>Click on <code>Complete Setup</code></li> </ol>"},{"location":"capstone/04_lab02/#2-create-a-new-repository","title":"2. Create a New Repository","text":"<ol> <li>Verify in the url that you are in your orgnization space i.e. <code>https://github.com/ditiss-&lt;your-team-mname&gt;</code></li> <li>Click on <code>Repositories</code></li> <li>Click New Repository.</li> <li> <p>Fill details:</p> <ul> <li> <p>Owner</p> <p><pre><code>ditiss-&lt;your-team-name&gt;\n</code></pre>       * Repository name:</p> <pre><code>techops-capstone-teamX\n</code></pre> <p>(replace <code>X</code> with your team number).       * Description:</p> <p><pre><code>Capstone Project - TechOps Inc. (Team X)\n</code></pre>       * Visibility: Public       * Initialize with:</p> <ul> <li>\u2705 <code>README.md</code></li> <li>\u2705 <code>.gitignore</code> (select Terraform template)<ul> <li>License: MIT</li> </ul> </li> </ul> </li> </ul> </li> <li> <p>Click Create Repository.</p> </li> </ol>"},{"location":"capstone/04_lab02/#2-add-team-members","title":"2. Add Team Members","text":"<ol> <li>Go to Settings \u2192 Collaborators &amp; Teams.</li> <li>Click Add People.</li> <li>Add all teammates by their GitHub usernames. <p>Note all team members must accept the invitation first before this or their name might not show up in Add People</p> </li> <li> <p>Permissions:</p> </li> <li> <p>Write Access \u2192 All team members.</p> </li> <li>Admin Access \u2192 Scrum Master + IAM Engineer (they\u2019ll need repo admin rights for secrets/integrations).</li> </ol> <p>Important</p> <p>Do not forget to add yourself as Admin</p>"},{"location":"capstone/04_lab02/#3-clone-the-repo-locally","title":"3. Clone the Repo Locally","text":"<p>You can find the ssh url by clicking <code>Code</code> button from repository home page.</p> <pre><code>git clone git@github.com:&lt;your-orgname&gt;/techops-capstone-teamX.git\ncd techops-capstone-teamX\n</code></pre>"},{"location":"capstone/04_lab02/#4-create-repository-structure","title":"4. Create Repository Structure","text":"<p>Inside the repo, create the following folders:</p> <pre><code>mkdir -p infrastructure/{network,infra,jenkins,monitoring}\nmkdir -p apps/{backend,frontend}\nmkdir -p ansible/{playbooks,inventories}\nmkdir -p ci\nmkdir -p docs/runbooks\n</code></pre> <p>Add placeholder files for clarity:</p> <pre><code>touch infrastructure/{network,infra,jenkins,monitoring}/README.md\ntouch apps/backend/README.md apps/frontend/README.md\ntouch ansible/playbooks/README.md ansible/inventories/README.md\ntouch ci/README.md\ntouch docs/architecture.md docs/runbooks/incident.md\n</code></pre>"},{"location":"capstone/04_lab02/#5-initial-commit-push","title":"5. Initial Commit &amp; Push","text":"<pre><code>git add .\ngit commit -m \"Initial repo structure for capstone project\"\ngit push origin main\n</code></pre>"},{"location":"capstone/04_lab02/#6-protect-your-repository","title":"6. Protect Your Repository","text":"<ol> <li>Open your repo on GitHub \u2192 click Settings.</li> <li>Left menu \u2192 Branches \u2192 under \"Branch protection rules\" click Add classic branch protection rile.</li> <li>Under Branch name pattern enter: <code>main</code> (or <code>refs/heads/main</code>).</li> <li> <p>Tick the boxes and fill fields as recommended:</p> </li> <li> <p>Require a pull request before merging \u2713</p> <ul> <li>Require approvals: enter <code>1</code> (or <code>2</code>)</li> <li>Check Dismiss stale pull request approvals when new commits are pushed \u2713</li> <li> <p>Require status checks to pass before merging \u2713</p> </li> <li> <p>Choose required checks (e.g., <code>jenkins-ci</code>, <code>terraform-plan</code>) \u2014 you can add them after Jenkins runs.</p> </li> <li>Check Require branches to be up to date before merging \u2713</li> <li>Do not allow bypassing the above settings \u2014 check this to enforce for admins \u2713</li> </ul> </li> <li> <p>Click Create/Save Changes.</p> </li> </ol>"},{"location":"capstone/04_lab02/#7-verify-repo-readiness","title":"7. Verify Repo Readiness","text":"<ul> <li>Confirm all folders are visible in GitHub.</li> <li>Confirm all teammates have accepted invitations.</li> <li>Leave repo empty of <code>.tfstate</code> files or secrets.</li> <li>This repo will be linked to Terraform Cloud in Lab 04.</li> </ul>"},{"location":"capstone/04_lab02/#checkpoint-validation","title":"Checkpoint / Validation","text":"<ul> <li>Repository <code>techops-capstone-teamX</code> exists with proper structure.</li> <li>Team members added as collaborators with correct roles.</li> <li>Initial commit pushed and visible in GitHub.</li> <li>Branches are protected</li> </ul>"},{"location":"capstone/04_lab02/#troubleshooting-tips","title":"Troubleshooting Tips","text":"<ul> <li>Permission denied (SSH) \u2192 Ensure SSH key from Lab 01 is added to GitHub.</li> <li>Can\u2019t add collaborators \u2192 Only Architect (repo owner) can invite them.</li> <li>Wrong branch name \u2192 Default branch should be <code>main</code>; rename if needed:</li> </ul> <pre><code>git branch -M main\ngit push -u origin main\n</code></pre>"},{"location":"capstone/04_lab02/#deliverables","title":"Deliverables","text":"<ul> <li>Screenshot of repo structure in GitHub.</li> <li>Screenshot showing team members as collaborators.</li> <li>GitHub commit log with initial repo structure.</li> </ul>"},{"location":"capstone/05_lab03/","title":"Lab 03 \u2014 AWS IAM Setup","text":"<p>Role(s) Responsible: Project Owner / IAM Engineer</p> <p>Objectives</p> <ul> <li>Create IAM users for each team role with console + CLI access.</li> <li>Create and attach simplified, role-appropriate IAM policies (no full Admin to users).</li> <li>Create Terraform service user and attach Terraform policy (used by Terraform Cloud).</li> <li>Create Jenkins EC2 role and App EC2 role (instance profiles) with appropriate permissions.</li> <li>Produce and securely distribute credentials for every user in the format:</li> </ul> <p><pre><code>Role:\nUsername:\nPassword:\nAccount ID:\nAccess Key:\nSecret Key:\n</code></pre> * Validate each user can log in and use CLI actions allowed for their role.</p>"},{"location":"capstone/05_lab03/#pre-requisites","title":"Pre-requisites","text":"<ul> <li>You are logged into the AWS account with an IAM user that has AdministratorAccess (Project Owner / IAM Engineer).</li> <li>AWS CLI v2 installed and configured for the admin user (<code>aws configure</code>).</li> <li>A local folder for lab files, e.g. <code>labs/lab03/</code> to store policy JSON files and outputs.</li> </ul>"},{"location":"capstone/05_lab03/#high-level-plan-what-we-will-create","title":"High-level plan (what we will create)","text":"<ol> <li><code>techops-teamX</code> IAM group (base membership).</li> <li>Per-role policies (simplified scoped): Architect, Network, SysAdmin, Storage, Monitoring, Developer, DevOps, Scrum Master.</li> <li>IAM users (one per role) \u2014 create login profile + access keys.</li> <li>Terraform service user <code>techops-terraform</code> + attach TerraformPolicy.</li> <li>Jenkins EC2 Role (instance profile) + App EC2 Role (instance profile).</li> <li>Produce per-user credential file and confirm login &amp; CLI access.</li> </ol>"},{"location":"capstone/05_lab03/#files-you-will-create","title":"Files you will create","text":"<p>Create a working folder and store all JSON policy files there:</p> <pre><code>labs/lab03/policies/\n  - terraform-policy.json\n  - architect-policy.json\n  - network-policy.json\n  - sysadmin-policy.json\n  - storage-policy.json\n  - monitoring-policy.json\n  - developer-policy.json\n  - devops-policy.json\n  - scrum-policy.json\n  - jenkins-ec2-policy.json\n  - app-ec2-policy.json\n  - ec2-trust.json\n</code></pre> <p>One Command to Create Above Strucutre</p> <p>You can use following command to create the folder structure in one go:</p> <pre><code>mkdir -p labs/lab03/policies &amp;&amp; touch labs/lab03/policies/{terraform-policy.json,architect-policy.json,network-policy.json,sysadmin-policy.json,storage-policy.json,monitoring-policy.json,developer-policy.json,devops-policy.json,scrum-policy.json,jenkins-ec2-policy.json,app-ec2-policy.json,ec2-trust.json}\n</code></pre>"},{"location":"capstone/05_lab03/#step-by-step-instructions-copypaste","title":"Step-by-step instructions (copy/paste)","text":"<p>Step 0 \u2014 Set variables</p> <pre><code># Adjust team name/ids\nTEAM=\"teamX\"\nGROUP=\"techops-${TEAM}\"\nACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)\nREGION=\"ap-south-1\"    # or your chosen region\nOUTDIR=\"labs/lab03/output\"\nmkdir -p labs/lab03/policies $OUTDIR\n</code></pre>"},{"location":"capstone/05_lab03/#step-1-create-group","title":"Step 1 \u2014 Create group","text":"<pre><code>aws iam create-group --group-name ${GROUP}\n</code></pre>"},{"location":"capstone/05_lab03/#step-2-create-simplified-policies","title":"Step 2 \u2014 Create simplified policies","text":"<p>Save the following JSON files under <code>labs/lab03/policies/</code> and create them via <code>aws iam create-policy</code>. (I include compact, safe-but-functional policies tailored per role.)</p> <p>Use Nano</p> <ul> <li>Use nano editor to create policies faster. If you do not have nano install you can run <code>sudo apt install nano</code></li> <li>Then you can run command like <code>nano /labs/lab03/policy/terraform-policy.json</code></li> <li>Copy the contents from lab and paste them</li> <li>To save &amp; exit use shortcut <code>Crtl+O</code> -&gt; <code>Enter</code> -&gt; <code>Crtl+X</code></li> </ul> <p>A. Terraform policy (broader infra access for Terraform Cloud) \u2014 <code>terraform-policy.json</code></p> <pre><code>{\n  \"Version\":\"2012-10-17\",\n  \"Statement\":[\n    {\"Effect\":\"Allow\",\"Action\":[\"ec2:*\",\"elasticloadbalancing:*\",\"autoscaling:*\",\"vpc:*\",\"route53:*\",\"ecr:*\",\"s3:*\",\"iam:PassRole\",\"cloudwatch:*\",\"logs:*\",\"kms:*\",\"dynamodb:*\"],\"Resource\":\"*\"}\n  ]\n}\n</code></pre> <p>B. Architect policy \u2014 <code>architect-policy.json</code> (read + limited write for tagging / describe)</p> <pre><code>{\n  \"Version\":\"2012-10-17\",\n  \"Statement\":[\n    {\"Effect\":\"Allow\",\"Action\":[\"ec2:Describe*\",\"vpc:Describe*\",\"route53:ListHostedZones\",\"ec2:DescribeTags\",\"s3:ListAllMyBuckets\",\"s3:GetBucketLocation\"],\"Resource\":\"*\"},\n    {\"Effect\":\"Allow\",\"Action\":[\"tag:GetResources\",\"tag:TagResources\"],\"Resource\":\"*\"}\n  ]\n}\n</code></pre> <p>C. Network policy \u2014 <code>network-policy.json</code> (VPC, subnets, SG manage)</p> <pre><code>{\n  \"Version\":\"2012-10-17\",\n  \"Statement\":[\n    {\"Effect\":\"Allow\",\"Action\":[\"ec2:CreateVpc\",\"ec2:DeleteVpc\",\"ec2:CreateSubnet\",\"ec2:ModifySubnetAttribute\",\"ec2:CreateSecurityGroup\",\"ec2:AuthorizeSecurityGroupIngress\",\"ec2:RevokeSecurityGroupIngress\",\"ec2:DeleteSecurityGroup\",\"ec2:Describe*\"],\"Resource\":\"*\"}\n  ]\n}\n</code></pre> <p>D. SysAdmin policy \u2014 <code>sysadmin-policy.json</code> (manage EC2 instances, EBS, SSM)</p> <pre><code>{\n  \"Version\":\"2012-10-17\",\n  \"Statement\":[\n    {\"Effect\":\"Allow\",\"Action\":[\"ec2:RunInstances\",\"ec2:TerminateInstances\",\"ec2:StartInstances\",\"ec2:StopInstances\",\"ec2:DescribeInstances\",\"ec2:CreateTags\",\"ec2:AttachVolume\",\"ec2:DetachVolume\",\"ec2:DescribeVolumes\",\"ssm:SendCommand\"],\"Resource\":\"*\"}\n  ]\n}\n</code></pre> <p>E. Storage policy \u2014 <code>storage-policy.json</code> (S3 + EBS operations)</p> <pre><code>{\n  \"Version\":\"2012-10-17\",\n  \"Statement\":[\n    {\"Effect\":\"Allow\",\"Action\":[\"s3:PutObject\",\"s3:GetObject\",\"s3:ListBucket\",\"s3:CreateBucket\",\"s3:DeleteObject\",\"ec2:CreateSnapshot\",\"ec2:DeleteSnapshot\",\"ec2:DescribeVolumes\"],\"Resource\":\"*\"}\n  ]\n}\n</code></pre> <p>F. Monitoring policy \u2014 <code>monitoring-policy.json</code> (logs, create metric filters; since we use Prometheus, grant EC2 + S3)</p> <pre><code>{\n  \"Version\":\"2012-10-17\",\n  \"Statement\":[\n    {\"Effect\":\"Allow\",\"Action\":[\"logs:CreateLogGroup\",\"logs:CreateLogStream\",\"logs:PutLogEvents\",\"logs:DescribeLogStreams\",\"ec2:DescribeInstances\",\"s3:PutObject\",\"s3:GetObject\",\"cloudwatch:PutMetricData\"],\"Resource\":\"*\"}\n  ]\n}\n</code></pre> <p>G. Developer policy \u2014 <code>developer-policy.json</code> (limited EC2, ECR push/pull)</p> <pre><code>{\n  \"Version\":\"2012-10-17\",\n  \"Statement\":[\n    {\"Effect\":\"Allow\",\"Action\":[\"ecr:GetAuthorizationToken\",\"ecr:BatchGetImage\",\"ecr:GetDownloadUrlForLayer\",\"ecr:BatchCheckLayerAvailability\",\"ecr:InitiateLayerUpload\",\"ecr:UploadLayerPart\",\"ecr:CompleteLayerUpload\",\"ecr:PutImage\"],\"Resource\":\"*\"},\n    {\"Effect\":\"Allow\",\"Action\":[\"ec2:DescribeInstances\",\"ec2:RunInstances\",\"ec2:StopInstances\",\"ec2:StartInstances\"],\"Resource\":\"*\"}\n  ]\n}\n</code></pre> <p>H. DevOps policy \u2014 <code>devops-policy.json</code> (ECR push/pull, S3 for artifacts, and limited EC2 deploy)</p> <pre><code>{\n  \"Version\":\"2012-10-17\",\n  \"Statement\":[\n    {\"Effect\":\"Allow\",\"Action\":[\"ecr:*\",\"s3:*\",\"ec2:DescribeInstances\",\"ec2:StartInstances\",\"ec2:StopInstances\",\"ssm:SendCommand\",\"iam:PassRole\"],\"Resource\":\"*\"}\n  ]\n}\n</code></pre> <p>I. Scrum Master policy \u2014 <code>scrum-policy.json</code> (read-only)</p> <pre><code>{\n  \"Version\":\"2012-10-17\",\n  \"Statement\":[\n    {\"Effect\":\"Allow\",\"Action\":[\"ec2:Describe*\",\"vpc:Describe*\",\"s3:ListAllMyBuckets\",\"s3:GetBucketLocation\",\"cloudwatch:GetMetricData\",\"logs:DescribeLogGroups\",\"logs:DescribeLogStreams\"],\"Resource\":\"*\"}\n  ]\n}\n</code></pre> <p>J. Jenkins EC2 policy \u2014 <code>jenkins-ec2-policy.json</code></p> <pre><code>{\n  \"Version\":\"2012-10-17\",\n  \"Statement\":[\n    {\"Effect\":\"Allow\",\"Action\":[\"ecr:GetAuthorizationToken\",\"ecr:BatchGetImage\",\"ecr:GetDownloadUrlForLayer\",\"ecr:BatchCheckLayerAvailability\",\"s3:GetObject\",\"s3:PutObject\",\"ssm:GetParameters\",\"ssm:GetParameter\",\"secretsmanager:GetSecretValue\",\"iam:PassRole\"],\"Resource\":\"*\"}\n  ]\n}\n</code></pre> <p>K. App EC2 policy \u2014 <code>app-ec2-policy.json</code></p> <pre><code>{\n  \"Version\":\"2012-10-17\",\n  \"Statement\":[\n    {\"Effect\":\"Allow\",\"Action\":[\"s3:GetObject\",\"s3:PutObject\",\"logs:CreateLogStream\",\"logs:PutLogEvents\"],\"Resource\":\"*\"}\n  ]\n}\n</code></pre> <p>L. EC2 trust policy for instance profiles \u2014 <code>ec2-trust.json</code></p> <pre><code>{\n  \"Version\":\"2012-10-17\",\n  \"Statement\":[\n    {\n      \"Effect\":\"Allow\",\n      \"Principal\":{\"Service\":\"ec2.amazonaws.com\"},\n      \"Action\":\"sts:AssumeRole\"\n    }\n  ]\n}\n</code></pre> <p>Create all policies</p> <pre><code>cd labs/lab03/policies\naws iam create-policy --policy-name TechOps_TerraformPolicy --policy-document file://terraform-policy.json\naws iam create-policy --policy-name TechOps_ArchitectPolicy --policy-document file://architect-policy.json\naws iam create-policy --policy-name TechOps_NetworkPolicy --policy-document file://network-policy.json\naws iam create-policy --policy-name TechOps_SysAdminPolicy --policy-document file://sysadmin-policy.json\naws iam create-policy --policy-name TechOps_StoragePolicy --policy-document file://storage-policy.json\naws iam create-policy --policy-name TechOps_MonitoringPolicy --policy-document file://monitoring-policy.json\naws iam create-policy --policy-name TechOps_DeveloperPolicy --policy-document file://developer-policy.json\naws iam create-policy --policy-name TechOps_DevOpsPolicy --policy-document file://devops-policy.json\naws iam create-policy --policy-name TechOps_ScrumPolicy --policy-document file://scrum-policy.json\naws iam create-policy --policy-name TechOps_JenkinsEC2Policy --policy-document file://jenkins-ec2-policy.json\naws iam create-policy --policy-name TechOps_AppEC2Policy --policy-document file://app-ec2-policy.json\n</code></pre> <p>Note: <code>create-policy</code> will output the policy ARN \u2014 copy them or run <code>aws iam list-policies --scope Local</code> later.</p>"},{"location":"capstone/05_lab03/#step-3-create-roles-instance-profiles-for-ec2-jenkins-and-app","title":"Step 3 \u2014 Create roles / instance-profiles for EC2 (Jenkins and App)","text":"<pre><code>aws iam create-role --role-name TechOps_JenkinsRole --assume-role-policy-document file://labs/lab03/policies/ec2-trust.json\naws iam attach-role-policy --role-name TechOps_JenkinsRole --policy-arn arn:aws:iam::${ACCOUNT_ID}:policy/TechOps_JenkinsEC2Policy\naws iam create-instance-profile --instance-profile-name TechOps_JenkinsInstanceProfile\naws iam add-role-to-instance-profile --instance-profile-name TechOps_JenkinsInstanceProfile --role-name TechOps_JenkinsRole\n\naws iam create-role --role-name TechOps_AppRole --assume-role-policy-document file://labs/lab03/policies/ec2-trust.json\naws iam attach-role-policy --role-name TechOps_AppRole --policy-arn arn:aws:iam::${ACCOUNT_ID}:policy/TechOps_AppEC2Policy\naws iam create-instance-profile --instance-profile-name TechOps_AppInstanceProfile\naws iam add-role-to-instance-profile --instance-profile-name TechOps_AppInstanceProfile --role-name TechOps_AppRole\n</code></pre>"},{"location":"capstone/05_lab03/#step-4-create-the-terraform-service-user-and-attach-terraform-policy","title":"Step 4 \u2014 Create the Terraform service user and attach Terraform policy","text":"<pre><code>aws iam create-user --user-name techops-terraform\naws iam add-user-to-group --group-name ${GROUP} --user-name techops-terraform\n\n# Attach policy (use ARN from create-policy or list-policies)\naws iam attach-user-policy --user-name techops-terraform --policy-arn arn:aws:iam::${ACCOUNT_ID}:policy/TechOps_TerraformPolicy\n\n# Create access keys (save output)\naws iam create-access-key --user-name techops-terraform &gt; ${OUTDIR}/techops-terraform-keys.json\n</code></pre> <p>Record <code>AccessKeyId</code> and <code>SecretAccessKey</code> from <code>${OUTDIR}/techops-terraform-keys.json</code>.</p> <p>Add these as environment variables in Terraform Cloud workspace (sensitive):</p> <ul> <li>AWS_ACCESS_KEY_ID = <code>AccessKeyId</code></li> <li>AWS_SECRET_ACCESS_KEY = <code>SecretAccessKey</code></li> <li>AWS_DEFAULT_REGION = <code>${REGION}</code></li> </ul>"},{"location":"capstone/05_lab03/#step-5-create-human-users-per-role-and-attach-role-specific-policies","title":"Step 5 \u2014 Create human users per role and attach role-specific policies","text":"<ol> <li>Install <code>jq</code> libraries by running command <code>sudo apt install jq -y</code></li> <li>Create bsah script: <code>nano create_iam_users.sh</code></li> <li>Copy and paste below script then save and exit <code>(Ctrl+O, Enter, Ctrl+X)</code>.</li> </ol> <p><pre><code>#!/bin/bash\n\n# Exit on any error\nset -e\n\n# Validate environment variables\nif [[ -z \"$ACCOUNT_ID\" || -z \"$GROUP\" || -z \"$OUTDIR\" ]]; then\n  echo \"Error: ACCOUNT_ID, GROUP, and OUTDIR must be set.\"\n  exit 1\nfi\n\n# Ensure output directory exists\nmkdir -p \"$OUTDIR\" || { echo \"Failed to create $OUTDIR\"; exit 1; }\n\ndeclare -A USERS\nUSERS=(\n  [\"iam-engineer\"]=\"iam_engineer\"\n  [\"architect\"]=\"architect1\"\n  [\"network\"]=\"network1\"\n  [\"sysadmin\"]=\"sysadmin1\"\n  [\"storage\"]=\"storage1\"\n  [\"monitoring\"]=\"monitoring1\"\n  [\"developer\"]=\"developer1\"\n  [\"devops\"]=\"devops1\"\n  [\"scrum\"]=\"scrum1\"\n)\n\ndeclare -A POLICYMAP\nPOLICYMAP=(\n  [\"iam-engineer\"]=\"arn:aws:iam::${ACCOUNT_ID}:policy/TechOps_TerraformPolicy\"\n  [\"architect\"]=\"arn:aws:iam::${ACCOUNT_ID}:policy/TechOps_ArchitectPolicy\"\n  [\"network\"]=\"arn:aws:iam::${ACCOUNT_ID}:policy/TechOps_NetworkPolicy\"\n  [\"sysadmin\"]=\"arn:aws:iam::${ACCOUNT_ID}:policy/TechOps_SysAdminPolicy\"\n  [\"storage\"]=\"arn:aws:iam::${ACCOUNT_ID}:policy/TechOps_StoragePolicy\"\n  [\"monitoring\"]=\"arn:aws:iam::${ACCOUNT_ID}:policy/TechOps_MonitoringPolicy\"\n  [\"developer\"]=\"arn:aws:iam::${ACCOUNT_ID}:policy/TechOps_DeveloperPolicy\"\n  [\"devops\"]=\"arn:aws:iam::${ACCOUNT_ID}:policy/TechOps_DevOpsPolicy\"\n  [\"scrum\"]=\"arn:aws:iam::${ACCOUNT_ID}:policy/TechOps_ScrumPolicy\"\n)\n\nfor role in \"${!USERS[@]}\"; do\n  username=${USERS[$role]}\n  echo \"Creating user $username for role $role\"\n\n  # Skip if user exists\n  if aws iam get-user --user-name \"$username\" &gt;/dev/null 2&gt;&amp;1; then\n    echo \"User $username already exists, skipping.\"\n    continue\n  fi\n\n  aws iam create-user --user-name \"$username\" || { echo \"Failed to create user $username\"; exit 1; }\n  aws iam add-user-to-group --group-name \"${GROUP}\" --user-name \"$username\" || { echo \"Failed to add $username to group\"; exit 1; }\n\n  # Create console password\n  PASSWORD=\"ChangeMe!$(openssl rand -hex 4)\"\n  aws iam create-login-profile --user-name \"$username\" --password \"$PASSWORD\" --password-reset-required || { echo \"Failed to create login profile for $username\"; exit 1; }\n\n  # Create access key\n  KEY_OUTPUT=$(aws iam create-access-key --user-name \"$username\") || { echo \"Failed to create access key for $username\"; exit 1; }\n  AKID=$(echo \"$KEY_OUTPUT\" | jq -r '.AccessKey.AccessKeyId')\n  SAK=$(echo \"$KEY_OUTPUT\" | jq -r '.AccessKey.SecretAccessKey')\n\n  # Attach role policy\n  aws iam attach-user-policy --user-name \"$username\" --policy-arn \"${POLICYMAP[$role]}\" || { echo \"Failed to attach policy for $username\"; exit 1; }\n\n  # Save credentials\n  cat &gt; \"${OUTDIR}/${username}.txt\" &lt;&lt;EOF\nRole: $role\nUsername: $username\nPassword: $PASSWORD\nAccount ID: $ACCOUNT_ID\nAccess Key: $AKID\nSecret Key: $SAK\nEOF\n\n  echo \"Created $username; credentials saved to ${OUTDIR}/${username}.txt\"\ndone\n</code></pre> 4. Make the Script Executable: <pre><code>chmod +x create_iam_users.sh\n</code></pre> 5. Run the Script: Execute the script:    <pre><code>./create_iam_users.sh\n</code></pre></p> <p>Attach additional permissions if needed</p> <p>If any role needs an extra permission discovered during manual testing, attach it with:</p> <pre><code>aws iam attach-user-policy --user-name developer1 --policy-arn arn:aws:iam::aws:policy/AmazonS3FullAccess\n</code></pre> <p>(Prefer attaching your custom TechOps_* policies, not AWS managed full-access policies unless needed.)</p>"},{"location":"capstone/05_lab03/#step-6-commit-your-policies-to-github-repo","title":"Step 6 \u2014 Commit your policies to GitHub Repo","text":"<ol> <li>Create directories inside your repo folder (Replace  with your actual team name and repo folder)    <pre><code>mkdir techops-capstone-&lt;your-team-name&gt;/infrastructure/iam\nmkdir techops-capstone-&lt;your-team-name&gt;/infrastructure/iam/policies\ncp labs/lab03/policies/*.json techops-capstone-&lt;your-team-name&gt;/infrastructure/iam/policies/\n</code></pre> <li><code>cd</code> into your repo folder    <pre><code>cd techops-capstone-&lt;your-team-name&gt;\n</code></pre></li> <li>Commit and push to new Git branch    <pre><code>git add .\ngit commit -m \"Added IAM Policies\"\ngit checkout -b \"iam-1\"\ngit push origin iam-1\n</code></pre></li> <li>Go to Github and in your orgisation where you have created the repo. For example https://github.com/ditiss-your-team-name/techops-capstone-your-team-name</li> <li>Click on <code>Compare &amp; pull Request</code></li> <li> <p>Add following Details</p> <ul> <li>Title: <code>Added IAM Policies</code></li> <li>Description: <code>Created policies and users in AWS IAM</code></li> </ul> </li> <li> <p>Click on <code>Create pull request</code></p> </li> <li>Ask Project Owner/Any other person in your team to go your repo</li> <li>Click on <code>Pull Requests</code></li> <li>Click on <code>Added IAM Policies</code> or any other title that you have given in above step 6.1</li> <li>Click on <code>Files Changed</code></li> <li>Click on <code>Review Changes</code></li> <li>Select <code>Approve</code> radio button</li> <li>Click on <code>Submit review</code></li> <li>Now back on your screen, refresh the page and you will see <code>Merge Pull request</code> button enabled. Click on it to Merge the pull request </li> <li>Click on <code>Confirm merge</code></li> <p>You have successfully merged your chagnes to your Github Repo now!</p>"},{"location":"capstone/05_lab03/#step-7-validate-each-user-user-must-run-this-on-their-workstation","title":"Step 7 \u2014 Validate each user (user must run this on their workstation)","text":"<p>Each user should run:</p> <pre><code>aws configure      # enter their Access Key &amp; Secret Key, region, json\naws sts get-caller-identity\n</code></pre> <p>Expected: JSON with <code>Account</code> = <code>${ACCOUNT_ID}</code> and <code>Arn</code> containing <code>user/&lt;username&gt;</code>.</p> <p>Test role-specific actions (examples):</p> <ul> <li>Architect (describe VPC):</li> </ul> <p><pre><code>aws ec2 describe-vpcs\n</code></pre> * Network (create a test security group in test VPC):</p> <p><pre><code>aws ec2 create-security-group --group-name test-sg --description \"test\"\n</code></pre> * SysAdmin (launch a test EC2 instance):</p> <p><pre><code>aws ec2 run-instances --image-id ami-XXXX --count 1 --instance-type t3.micro --security-group-ids sg-XXXX\n</code></pre> * Developer (attempt ECR login/push \u2014 use Docker credentials flow later during pipeline). * Scrum Master (try a describe command, should return OK but not allow destructive actions).</p>"},{"location":"capstone/05_lab03/#checkpoint-validation","title":"Checkpoint / Validation","text":"<ul> <li>Per-user credential files exist in <code>${OUTDIR}</code> for distribution (format exactly):</li> </ul> <p><pre><code>Role:\nUsername:\nPassword:\nAccount ID:\nAccess Key:\nSecret Key:\n</code></pre> * All custom policies exist (<code>aws iam list-policies --scope Local</code>). * Instance roles and instance profiles exist:</p> <p><pre><code>aws iam get-role --role-name TechOps_JenkinsRole\naws iam get-instance-profile --instance-profile-name TechOps_JenkinsInstanceProfile\naws iam get-role --role-name TechOps_AppRole\naws iam get-instance-profile --instance-profile-name TechOps_AppInstanceProfile\n</code></pre> * Terraform user keys saved at <code>${OUTDIR}/techops-terraform-keys.json</code>. (Instructor must add to Terraform Cloud workspace variables.) * Each user confirmed by running <code>aws sts get-caller-identity</code> with their CLI creds.</p>"},{"location":"capstone/05_lab03/#deliverables-to-commit-hand-to-instructor","title":"Deliverables (to commit / hand to instructor)","text":"<ul> <li>Commit to repo: <code>infrastructure/iam/policies/*.json</code> (policy definitions only, do not commit any keys/passwords).</li> <li>Submit <code>labs/lab03/output/</code> directory to instructor securely (zipped and shared privately) \u2014 includes per-user credential files (or better: instructor distributes them individually).</li> <li> <p><code>iam-report.md</code> in <code>/docs/</code> listing:</p> </li> <li> <p>Users created &amp; matching roles</p> </li> <li>Policy ARNs (custom TechOps_*)</li> <li>Role ARNs &amp; instance-profile names</li> <li>Confirmation that Terraform keys were added to Terraform Cloud (note only, do not paste keys in report)</li> </ul>"},{"location":"capstone/05_lab03/#troubleshooting-tips","title":"Troubleshooting tips","text":"<ul> <li><code>create-login-profile</code> fails: user might already have login profile; remove then recreate or reset password in Console.</li> <li>Access key lost: you cannot retrieve SecretAccessKey after creation \u2014 create a new key and delete the old one.</li> <li>User gets AccessDenied on action: check the policy attached to their user and augment minimally (use CloudTrail / CLI error message to find missing action).</li> <li>Terraform Cloud fails with IAM permissions: use <code>terraform plan</code> failure output to identify missing actions and add them to <code>TechOps_TerraformPolicy</code>.</li> <li>Credentials files left on disk: instruct IAM Engineer to securely delete after distribution (use <code>shred</code>/secure delete if required).</li> </ul>"},{"location":"capstone/05_lab03/#security-notes-must-read","title":"Security notes (must-read)","text":"<ul> <li>DO NOT commit keys or passwords to Git. Commit only policy JSONs.</li> <li>Store per-user credentials securely when distributing (private message, encrypted file).</li> <li>Enforce <code>password-reset-required</code> on first login (script above sets that).</li> <li>Consider rotating Terraform user keys after the lab.</li> <li>Consider removing <code>AdministratorAccess</code> from human accounts after setup.</li> </ul>"},{"location":"capstone/05_lab03/#reflection-questions","title":"Reflection Questions","text":"<ol> <li>Why do we give <code>techops-terraform</code> broader infra permissions while giving humans role-specific, limited permissions?</li> <li>What are the risks of giving every human a programmatic access key, and how would you mitigate them in a production environment?</li> </ol>"},{"location":"capstone/05_lab03/#next-steps-after-lab-03","title":"Next steps (after Lab 03)","text":"<ul> <li>IAM Engineer adds <code>techops-terraform</code> keys to Terraform Cloud workspace (Lab 04).</li> <li>Architect links GitHub repo to Terraform Cloud (Lab 04).</li> <li>Network team begins Lab 05 (Networking with Terraform) using Terraform Cloud execution.</li> </ul>"},{"location":"capstone/06_lab04/","title":"Lab 04: Terraform Cloud Setup &amp; Workspace","text":""},{"location":"capstone/06_lab04/#roles-responsible","title":"Role(s) Responsible","text":"<p>IAM Engineer, Architect</p>"},{"location":"capstone/06_lab04/#objectives","title":"Objectives","text":"<ul> <li>Create a Terraform Cloud organization for the team.</li> <li>Connect Terraform Cloud to the team GitHub repo.</li> <li>Create a dedicated workspace (<code>capstone-infra</code>) for infrastructure.</li> <li>Add Terraform Cloud variables with the Terraform service user\u2019s Access Key &amp; Secret Key from Lab 03.</li> <li>Verify Terraform Cloud runs a test plan successfully.</li> </ul>"},{"location":"capstone/06_lab04/#pre-requisites","title":"Pre-requisites","text":"<ul> <li>Lab 02: GitHub Repo &amp; Project Structure completed.</li> <li>Lab 03: AWS IAM Setup completed (Terraform service user + keys created).</li> <li>GitHub repo must exist and contain <code>infrastructure/</code> folder.</li> <li>IAM Engineer has Terraform service user\u2019s <code>Access Key</code> and <code>Secret Key</code>.</li> </ul>"},{"location":"capstone/06_lab04/#step-by-step-instructions","title":"Step-by-Step Instructions","text":""},{"location":"capstone/06_lab04/#1-sign-up-log-in-to-terraform-cloud","title":"1. Sign up / Log in to Terraform Cloud","text":"<ol> <li>Go to Terraform Cloud.</li> <li>Sign up with your GitHub account or email.</li> <li>IAM Engineer creates a new organization for the team:</li> </ol> <pre><code>TechOps-TeamX\n</code></pre>"},{"location":"capstone/06_lab04/#2-create-a-workspace","title":"2. Create a Workspace","text":"<ol> <li>Inside your organization, click New Workspace.</li> <li>Choose Version Control Workflow.</li> <li>Connect to GitHub and authorize Terraform Cloud.</li> <li>Make sure to select the orgisation for your team instead of your personal account</li> <li>Select your team repo (<code>techops-capstone-teamX</code>).</li> <li>Name the workspace:    <pre><code>capstone-infra\n</code></pre></li> <li>Click on <code>Advanced Options</code></li> <li>Set the Working Directory =</li> </ol> <pre><code>infrastructure/\n</code></pre> <p>(so Terraform Cloud only runs code inside that folder). 9. Under VCS Trigger Type:       *  Select Branch-based       *  VCS Branch: <code>main</code> 10. Click on <code>Create</code> 11. Go to your workspace on left side menu, find Settings -&gt; General 12. Select/Tick Mark Auto-appy API, UI &amp; VCS runs under Auto-Apply 13. Save Settings</p>"},{"location":"capstone/06_lab04/#3-configure-workspace-variables","title":"3. Configure Workspace Variables","text":"<ol> <li>In the workspace \u2192 Variables tab \u2192 Add variables. or <code>Configure variables</code></li> <li> <p>Add AWS credentials for the <code>techops-terraform</code> user created in Lab 03:</p> <ul> <li> <p>Environment Variables:</p> <ul> <li><code>AWS_ACCESS_KEY_ID</code> = <code>&lt;TerraformUser_AccessKeyId&gt;</code> (mark as Sensitive)</li> <li><code>AWS_SECRET_ACCESS_KEY</code> = <code>&lt;TerraformUser_SecretKey&gt;</code> (mark as Sensitive)</li> <li><code>AWS_DEFAULT_REGION</code> = <code>ap-south-1</code> (or your chosen region)</li> </ul> </li> </ul> </li> <li> <p>Add optional Terraform settings:</p> <ul> <li><code>TF_VAR_team</code> = <code>\"teamX\"</code></li> <li><code>TF_VAR_environment</code> = <code>\"staging\"</code></li> </ul> </li> </ol>"},{"location":"capstone/06_lab04/#4-add-backend-configuration-in-repo","title":"4. Add Backend Configuration (in repo)","text":"<p>IAM Engineer: On your Linux or WSL enabeld machine or from the machine where you ran the previous AWS commands</p> <ol> <li>In your repo, <code>nano infrastructure/backend.tf</code>:</li> </ol> <p><pre><code>terraform {\n  cloud {\n    organization = \"TechOps-TeamX\"\n\n    workspaces {\n      name = \"capstone-infra\"\n    }\n  }\n}\n</code></pre> 2. Commit &amp; push:</p> <p><pre><code>git checkout -b terra-1\ngit add infrastructure/backend.tf\ngit commit -m \"Added Terraform Cloud backend config\"\ngit push origin terra-1\n</code></pre> 3. Repeat the steps to create and merge pull request mentioned in Lab 03 (Step 6.4 to 6.13)</p> <p>Do Not Forget Above Step</p> <p>DO NOT FORGET TO RUN THE ABOVE STEP AS WITHOUT WHICH Architect cannot do the next step</p>"},{"location":"capstone/06_lab04/#5-initialize-terraform-with-remote-backend","title":"5. Initialize Terraform with Remote Backend","text":"<p>Role Chage: Architect</p> <p>Following step will be run by Architect on his local machine. If IAM &amp; Architect are same then IAM can continue</p> <ol> <li>Clone or update repo</li> </ol> <pre><code># If you don't already have it locally\ngit clone git@github.com:TechOps-TeamX/techops-capstone-teamX.git\ncd techops-capstone-teamX/infrastructure\n\n# OR if you already cloned earlier\ncd techops-capstone-teamX\ngit pull origin main\ncd infrastructure\n</code></pre> <ol> <li>Run Terraform init</li> </ol> <pre><code>terraform init\n</code></pre> <p>Expected output: Terraform downloads providers, configures backend, and shows:</p> <pre><code>Terraform has been successfully initialized!\n</code></pre>"},{"location":"capstone/06_lab04/#6-test-run-with-a-null-resource","title":"6. Test Run with a Null Resource","text":"<ol> <li> <p>Create a test file <code>infrastructure/test.tf</code> using nano or any editor if you are on Windows:</p> <pre><code>resource \"null_resource\" \"hello\" {\n# this trigger forces recreation if you change the message\ntriggers = {\n    message = \"Hello from Terraform Cloud at ${timestamp()}\"\n}\n\nprovisioner \"local-exec\" {\n    command = \"echo \\\"${self.triggers.message}\\\"\"\n}\n}\n\noutput \"hello_message_trigger\" {\nvalue = null_resource.hello.triggers.message\n}\n</code></pre> </li> <li> <p>Commit &amp; push:</p> <p><pre><code>git checkout -b architect-1\ngit add infrastructure/test.tf\ngit commit -m \"Terraform Cloud test run\"\ngit push origin architect-1\n</code></pre> 3. Repeat the steps to create and merge pull request mentioned in Lab 03 (Step 6.4 to 6.13)</p> </li> </ol> <p>4, Go to Terraform Cloud \u2192 Workspace \u2192 Runs \u2192 A run should appear automatically. Output should show <code>Hello from Terraform Cloud!</code>.</p>"},{"location":"capstone/06_lab04/#checkpoint-validation","title":"Checkpoint / Validation","text":"<ul> <li>Terraform Cloud organization <code>TechOps-TeamX</code> exists.</li> <li>Workspace <code>capstone-infra</code> linked to GitHub repo.</li> <li>Terraform service user keys added as workspace variables.</li> <li><code>terraform init</code> confirms remote backend.</li> <li>Terraform Cloud run triggers on push and completes successfully.</li> </ul>"},{"location":"capstone/06_lab04/#troubleshooting-tips","title":"Troubleshooting Tips","text":"<ul> <li>No run triggered \u2192 check VCS integration between Terraform Cloud and GitHub.</li> <li>Invalid AWS credentials \u2192 verify you pasted correct keys from <code>techops-terraform</code>.</li> <li>Backend init error \u2192 confirm <code>organization</code> and <code>workspace</code> names match exactly.</li> <li>Plan fails with permission denied \u2192 update <code>TechOps_TerraformPolicy</code> in Lab 03 with missing actions.</li> </ul>"},{"location":"capstone/06_lab04/#deliverables","title":"Deliverables","text":"<ul> <li>Screenshot of Terraform Cloud workspace variables showing AWS env vars (sensitive keys hidden).</li> <li>Screenshot of successful test run in Terraform Cloud.</li> <li>Commit log with <code>backend.tf</code> and <code>test.tf</code>.</li> </ul>"},{"location":"capstone/06_lab04/#reflection-question","title":"Reflection Question","text":"<p>Why is it better to store Terraform state in Terraform Cloud (with locking &amp; RBAC) instead of local <code>.tfstate</code> files in GitHub?</p> <p>\u2705 This completes Lab 04: Terraform Cloud Setup &amp; Workspace.</p>"},{"location":"capstone/07_lab05/","title":"Lab 05: Networking with Terraform (VPC, Subnets, Security Groups)","text":""},{"location":"capstone/07_lab05/#roles-responsible","title":"Role(s) Responsible","text":"<p>Network Engineers</p>"},{"location":"capstone/07_lab05/#objectives","title":"Objectives","text":"<ul> <li>Remove temporary <code>test.tf</code> used in Lab 04.</li> <li>Create a root <code>main.tf</code> under <code>infrastructure/</code> that references the <code>network</code> module.</li> <li>Define global variable for region in <code>infrastructure/variables.tf</code>.</li> <li>Move all network-specific variables inside <code>infrastructure/network/variables.tf</code>.</li> <li> <p>Apply Terraform via Terraform Cloud to provision:</p> <ul> <li>VPC</li> <li>Public &amp; private subnets</li> <li>Internet Gateway + NAT Gateway</li> <li>Route Tables + associations</li> <li>Security Groups (for Jenkins &amp; App servers)</li> </ul> </li> </ul>"},{"location":"capstone/07_lab05/#pre-requisites","title":"Pre-requisites","text":"<ul> <li>Lab 04: Terraform Cloud Setup &amp; Workspace completed.</li> <li>Terraform Cloud workspace <code>capstone-infra</code> connected to GitHub repo.</li> <li>AWS credentials for Terraform service user added as sensitive variables in Terraform Cloud.</li> </ul>"},{"location":"capstone/07_lab05/#step-by-step-instructions","title":"Step-by-Step Instructions","text":""},{"location":"capstone/07_lab05/#1-create-a-terraform-module-for-networking","title":"1. Create a Terraform module for networking","text":"<p>Clone or update repo</p> <pre><code># If you don't already have it locally\ngit clone git@github.com:TechOps-TeamX/techops-capstone-teamX.git\ncd techops-capstone-teamX/infrastructure\n\n# OR if you already cloned earlier\ncd techops-capstone-teamX\ngit pull origin main\ncd infrastructure\n</code></pre>"},{"location":"capstone/07_lab05/#2-remove-testtf","title":"2. Remove <code>test.tf</code>","text":"<p>From your local repo:</p> <pre><code>cd techops-capstone-teamX/infrastructure\ngit rm test.tf\ngit commit -m \"Remove test.tf from root module\"\n</code></pre>"},{"location":"capstone/07_lab05/#3-create-root-module","title":"3. Create Root Module","text":"<p>In <code>infrastructure/main.tf</code>:</p> <pre><code>terraform {\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~&gt; 5.0\"\n    }\n  }\n}\n\nprovider \"aws\" {\n  region = var.aws_region\n}\n\nmodule \"network\" {\n  source = \"./network\"\n\n  aws_region = var.aws_region\n}\n</code></pre> <p>Use Nano</p> <p>Use <code>nano &lt;path&gt;/filename.extension</code> to quickly create or edit files</p>"},{"location":"capstone/07_lab05/#4-create-global-variables-root-level","title":"4. Create Global Variables (root level)","text":"<p>In <code>infrastructure/variables.tf</code>:</p> <pre><code>variable \"aws_region\" {\n  description = \"AWS region for deployment\"\n  type        = string\n  default     = \"ap-south-1\"\n}\n</code></pre>"},{"location":"capstone/07_lab05/#5-create-network-module-files","title":"5. Create Network Module Files","text":"<p>Inside <code>infrastructure/network/</code>:</p> <p><code>main.tf</code></p> <pre><code>resource \"aws_vpc\" \"main\" {\n  cidr_block           = var.vpc_cidr\n  enable_dns_hostnames = true\n  tags = { Name = \"techops-vpc\" }\n}\n\nresource \"aws_internet_gateway\" \"igw\" {\n  vpc_id = aws_vpc.main.id\n  tags   = { Name = \"techops-igw\" }\n}\n\nresource \"aws_subnet\" \"public_a\" {\n  vpc_id                  = aws_vpc.main.id\n  cidr_block              = var.public_subnet_cidr\n  availability_zone       = \"${var.aws_region}a\"\n  map_public_ip_on_launch = true\n  tags = { Name = \"techops-public-a\" }\n}\n\nresource \"aws_subnet\" \"private_a\" {\n  vpc_id            = aws_vpc.main.id\n  cidr_block        = var.private_subnet_cidr\n  availability_zone = \"${var.aws_region}a\"\n  tags = { Name = \"techops-private-a\" }\n}\n\nresource \"aws_eip\" \"nat\" {\n  vpc = true\n}\n\nresource \"aws_nat_gateway\" \"natgw\" {\n  allocation_id = aws_eip.nat.id\n  subnet_id     = aws_subnet.public_a.id\n  tags          = { Name = \"techops-natgw\" }\n}\n\nresource \"aws_route_table\" \"public\" {\n  vpc_id = aws_vpc.main.id\n  route {\n    cidr_block = \"0.0.0.0/0\"\n    gateway_id = aws_internet_gateway.igw.id\n  }\n  tags = { Name = \"techops-public-rt\" }\n}\n\nresource \"aws_route_table_association\" \"public_a\" {\n  subnet_id      = aws_subnet.public_a.id\n  route_table_id = aws_route_table.public.id\n}\n\nresource \"aws_route_table\" \"private\" {\n  vpc_id = aws_vpc.main.id\n  route {\n    cidr_block     = \"0.0.0.0/0\"\n    nat_gateway_id = aws_nat_gateway.natgw.id\n  }\n  tags = { Name = \"techops-private-rt\" }\n}\n\nresource \"aws_route_table_association\" \"private_a\" {\n  subnet_id      = aws_subnet.private_a.id\n  route_table_id = aws_route_table.private.id\n}\n\nresource \"aws_security_group\" \"jenkins_sg\" {\n  name        = \"jenkins-sg\"\n  description = \"Allow SSH + Jenkins UI\"\n  vpc_id      = aws_vpc.main.id\n\n  ingress {\n    description = \"SSH\"\n    from_port   = 22\n    to_port     = 22\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  ingress {\n    description = \"Jenkins UI\"\n    from_port   = 8080\n    to_port     = 8080\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n}\n\nresource \"aws_security_group\" \"app_sg\" {\n  name        = \"app-sg\"\n  description = \"Allow HTTP/HTTPS\"\n  vpc_id      = aws_vpc.main.id\n\n  ingress {\n    from_port   = 80\n    to_port     = 80\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  ingress {\n    from_port   = 443\n    to_port     = 443\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n}\n</code></pre> <p><code>variables.tf</code></p> <pre><code>variable \"aws_region\" {\n  description = \"AWS region (passed from root)\"\n  type        = string\n}\n\nvariable \"vpc_cidr\" {\n  description = \"CIDR for VPC\"\n  type        = string\n  default     = \"10.0.0.0/16\"\n}\n\nvariable \"public_subnet_cidr\" {\n  description = \"CIDR for public subnet\"\n  type        = string\n  default     = \"10.0.1.0/24\"\n}\n\nvariable \"private_subnet_cidr\" {\n  description = \"CIDR for private subnet\"\n  type        = string\n  default     = \"10.0.2.0/24\"\n}\n</code></pre> <p><code>outputs.tf</code></p> <pre><code>output \"vpc_id\" {\n  value = aws_vpc.main.id\n}\n\noutput \"public_subnet_id\" {\n  value = aws_subnet.public_a.id\n}\n\noutput \"private_subnet_id\" {\n  value = aws_subnet.private_a.id\n}\n\noutput \"jenkins_sg_id\" {\n  value = aws_security_group.jenkins_sg.id\n}\n\noutput \"app_sg_id\" {\n  value = aws_security_group.app_sg.id\n}\n</code></pre>"},{"location":"capstone/07_lab05/#6-commit-push","title":"6. Commit &amp; push","text":"<pre><code>git checkout -b network-2\ngit add infrastructure/main.tf infrastructure/variables.tf infrastructure/network/*\ngit commit -m \"Network module with VPC, subnets, SGs; referenced from root\"\ngit push origin network-2\n</code></pre> <p>Terraform Cloud will trigger a run.</p>"},{"location":"capstone/07_lab05/#7-create-merge-pull-requst","title":"7. Create &amp; Merge Pull Requst","text":"<p>Repeat the steps to create and merge pull request mentioned in Lab 03 (Step 6.4 to 6.13)</p>"},{"location":"capstone/07_lab05/#8-apply-in-terraform-cloud","title":"8. Apply in Terraform Cloud","text":"<ul> <li>Go to Workspace \u2192 Runs.</li> <li>Review the Plan (should show VPC, Subnets, SGs).</li> <li>Confirm &amp; Apply.</li> </ul>"},{"location":"capstone/07_lab05/#checkpoint-validation","title":"Checkpoint / Validation","text":"<ul> <li>In AWS Console \u2192 VPC \u2192 confirm VPC, subnets, IGW, NAT exist.</li> <li>In AWS Console \u2192 EC2 \u2192 Security Groups: verify <code>jenkins-sg</code> and <code>app-sg</code>.</li> <li>Run:</li> </ul> <pre><code>aws ec2 describe-vpcs --query \"Vpcs[].VpcId\"\naws ec2 describe-subnets --query \"Subnets[].SubnetId\"\n</code></pre> <p>IDs should match Terraform outputs.</p>"},{"location":"capstone/07_lab05/#deliverables","title":"Deliverables","text":"<ul> <li><code>infrastructure/main.tf</code> (root module calling network).</li> <li><code>infrastructure/variables.tf</code> (region variable).</li> <li><code>infrastructure/network/*</code> with main/variables/outputs.</li> <li>Screenshot of AWS Console showing VPC + subnets + SGs.</li> <li>Screenshot of successful run in Terraform Cloud.</li> </ul>"},{"location":"capstone/07_lab05/#reflection-question","title":"Reflection Question","text":"<p>Why do we keep global variables like <code>aws_region</code> in the root module, while each submodule (network, Jenkins, monitoring) keeps its own variables inside its folder?</p> <p>\u2705 Lab 05 is completed</p>"},{"location":"capstone/08_lab06/","title":"Lab 06: Provision Jenkins EC2 with Terraform (Final Rebuild)","text":""},{"location":"capstone/08_lab06/#roles-responsible","title":"Role(s) Responsible","text":"<p>SysAdmin / Infra</p>"},{"location":"capstone/08_lab06/#objectives","title":"Objectives","text":"<ul> <li>Generate and manage an SSH key pair for Jenkins EC2 access.</li> <li>Commit the public key into repo, keep the private key secure.</li> <li>Launch a Jenkins EC2 instance inside the TechOps VPC using Terraform Cloud.</li> <li>Attach the Jenkins IAM Instance Profile created in Lab 03.</li> <li>Use the <code>jenkins-sg</code> security group from Lab 05.</li> <li>Expose root outputs so Jenkins public IP and instance details are visible in Terraform Cloud.</li> </ul>"},{"location":"capstone/08_lab06/#pre-requisites","title":"Pre-requisites","text":"<ul> <li>Lab 03: IAM complete \u2014 <code>TechOps_JenkinsInstanceProfile</code> exists.</li> <li>Lab 04: Terraform Cloud setup complete \u2014 workspace <code>capstone-infra</code>.</li> <li>Lab 05: Networking complete \u2014 <code>module.network</code> with subnet + SGs.</li> <li>Git and Terraform CLI installed, Terraform Cloud linked to repo.</li> </ul>"},{"location":"capstone/08_lab06/#quick-theory-recap","title":"Quick theory recap","text":"<p>In AWS, EC2 login is only possible if a valid key pair is associated. Terraform lets us create a key pair from a provided public key file, ensuring consistent access for all teammates. We must store the private key locally (never commit) and use it for SSH into Jenkins.</p>"},{"location":"capstone/08_lab06/#step-by-step-instructions","title":"Step-by-Step Instructions","text":""},{"location":"capstone/08_lab06/#0-clone-or-update-the-repo","title":"0. Clone or update the repo","text":"<p>If new machine:</p> <pre><code>git clone git@github.com:&lt;org&gt;/&lt;techops-capstone-teamX&gt;.git\ncd techops-capstone-teamX\n</code></pre> <p>If repo already cloned:</p> <pre><code>cd techops-capstone-teamX\ngit checkout main\ngit pull origin main\n</code></pre> <p>Create a branch:</p> <pre><code>git checkout -b infra-jenkins\ncd infrastructure\n</code></pre>"},{"location":"capstone/08_lab06/#1-generate-ssh-key-pair-locally","title":"1. Generate SSH key pair (locally)","text":"<p>Run on your workstation (Linux/Mac/WSL):</p> <pre><code>ssh-keygen -t rsa -b 4096 -C \"jenkins@techops\" -f id_rsa\n</code></pre> <p>This creates two files:</p> <ul> <li><code>id_rsa</code> \u2192 private key (keep safe, do NOT commit).</li> <li><code>id_rsa.pub</code> \u2192 public key (safe to commit).</li> </ul> <p>Move the <code>.pub</code> file into the repo:</p> <pre><code>mv ~/.ssh/id_rsa.pub /your-repo-name/infrastructure/jenkins_id_rsa.pub\n</code></pre> <p>Add <code>id_rsa</code> to your SSH agent or store securely.</p> <p>\u26a0\ufe0f Important: Add <code>id_rsa</code> to your <code>.gitignore</code> so it never gets committed.</p> <pre><code>echo \"infrastructure/id_rsa\" &gt;&gt; .gitignore\n</code></pre>"},{"location":"capstone/08_lab06/#2-create-jenkins-module","title":"2. Create Jenkins module","text":"<p>Make a folder:</p> <pre><code>mkdir -p infrastructure/jenkins\n</code></pre> <p><code>infrastructure/jenkins/main.tf</code></p> <pre><code># Create SSH key pair in AWS from local public key\nresource \"aws_key_pair\" \"jenkins_key\" {\n  key_name   = \"techops-jenkins-key\"\n  public_key = file(\"${path.module}/../jenkins_id_rsa.pub\")\n}\n\n# Jenkins EC2 instance\nresource \"aws_instance\" \"jenkins\" {\n  ami                         = var.ami_id\n  instance_type               = var.instance_type\n  subnet_id                   = var.subnet_id\n  vpc_security_group_ids      = [var.jenkins_sg_id]\n  iam_instance_profile        = var.instance_profile\n  associate_public_ip_address = true\n  key_name                    = aws_key_pair.jenkins_key.key_name\n\n  tags = {\n    Name = \"jenkins-server\"\n    Role = \"jenkins\"\n  }\n}\n</code></pre> <p><code>infrastructure/jenkins/variables.tf</code></p> <pre><code>variable \"ami_id\" {\n  description = \"AMI ID for Jenkins server\"\n  type        = string\n  default     = \"ami-08e5424edfe926b43\" # Ubuntu 22.04 LTS in ap-south-1\n}\n\nvariable \"instance_type\" {\n  description = \"EC2 instance type\"\n  type        = string\n  default     = \"t3.micro\"\n}\n\nvariable \"subnet_id\" {\n  description = \"Public subnet ID for Jenkins\"\n  type        = string\n}\n\nvariable \"jenkins_sg_id\" {\n  description = \"Security Group ID for Jenkins\"\n  type        = string\n}\n\nvariable \"instance_profile\" {\n  description = \"IAM instance profile for Jenkins EC2\"\n  type        = string\n}\n</code></pre> <p><code>infrastructure/jenkins/outputs.tf</code></p> <pre><code>output \"jenkins_public_ip\" {\n  value       = aws_instance.jenkins.public_ip\n  description = \"Public IP of Jenkins server\"\n}\n\noutput \"jenkins_id\" {\n  value       = aws_instance.jenkins.id\n  description = \"Instance ID of Jenkins server\"\n}\n</code></pre>"},{"location":"capstone/08_lab06/#3-reference-jenkins-module-in-root","title":"3. Reference Jenkins module in root","text":"<p>Edit <code>infrastructure/main.tf</code>:</p> <pre><code>module \"network\" {\n  source     = \"./network\"\n  aws_region = var.aws_region\n}\n\nmodule \"jenkins\" {\n  source           = \"./jenkins\"\n  subnet_id        = module.network.public_subnet_id\n  jenkins_sg_id    = module.network.jenkins_sg_id\n  instance_profile = \"TechOps_JenkinsInstanceProfile\"\n}\n</code></pre>"},{"location":"capstone/08_lab06/#4-add-root-level-outputs","title":"4. Add root-level outputs","text":"<p>Create/Update <code>infrastructure/outputs.tf</code>:</p> <pre><code># Network outputs\noutput \"vpc_id\" {\n  value       = module.network.vpc_id\n  description = \"VPC ID\"\n}\n\noutput \"public_subnet_id\" {\n  value       = module.network.public_subnet_id\n  description = \"Public Subnet ID\"\n}\n\noutput \"jenkins_sg_id\" {\n  value       = module.network.jenkins_sg_id\n  description = \"Jenkins SG ID\"\n}\n\n# Jenkins outputs\noutput \"jenkins_public_ip\" {\n  value       = module.jenkins.jenkins_public_ip\n  description = \"Public IP of Jenkins EC2\"\n}\n\noutput \"jenkins_instance_id\" {\n  value       = module.jenkins.jenkins_id\n  description = \"EC2 Instance ID for Jenkins\"\n}\n</code></pre>"},{"location":"capstone/08_lab06/#5-commit-push","title":"5. Commit &amp; push","text":"<pre><code>git add infrastructure/jenkins/* infrastructure/main.tf infrastructure/outputs.tf infrastructure/jenkins_id_rsa.pub .gitignore\ngit commit -m \"Provision Jenkins EC2 with SSH key pair and root outputs\"\ngit push origin infra-jenkins\n</code></pre>"},{"location":"capstone/08_lab06/#6-pr-merge","title":"6. PR &amp; Merge","text":"<ul> <li>Open PR \u2192 Title: <code>Provision Jenkins EC2 with SSH Key</code></li> <li>Request review, approve, merge into <code>main</code>.</li> </ul> <p>Terraform Cloud will auto-run and apply.</p>"},{"location":"capstone/08_lab06/#7-validate-outputs","title":"7. Validate Outputs","text":"<p>In Terraform Cloud \u2192 Runs \u2192 check Outputs:</p> <pre><code>jenkins_public_ip = \"3.110.xx.xx\"\njenkins_instance_id = \"i-0abcdef123456\"\n</code></pre> <p>Locally:</p> <pre><code>terraform output jenkins_public_ip\n</code></pre>"},{"location":"capstone/08_lab06/#8-ssh-into-jenkins-ec2","title":"8. SSH into Jenkins EC2","text":"<p>Use the private key (<code>id_rsa</code>) you generated in Step 1:</p> <pre><code>ssh -i infrastructure/id_rsa ubuntu@&lt;jenkins_public_ip&gt;\n</code></pre>"},{"location":"capstone/08_lab06/#checkpoint-validation","title":"Checkpoint / Validation","text":"<ul> <li>Jenkins EC2 instance created in AWS Console.</li> <li>Terraform Cloud Outputs show <code>jenkins_public_ip</code>.</li> <li>Able to SSH into EC2 using generated private key.</li> </ul>"},{"location":"capstone/08_lab06/#troubleshooting-tips","title":"Troubleshooting Tips","text":"<ul> <li>Permission denied (publickey) \u2192 confirm you used <code>ssh -i id_rsa</code> and that AWS KeyPair resource used the <code>.pub</code> file you committed.</li> <li>AMI not found \u2192 update <code>ami_id</code> to a valid Ubuntu AMI in your region.</li> <li>No Outputs \u2192 confirm root <code>outputs.tf</code> exists and references correct modules.</li> <li>SSH timeout \u2192 check <code>jenkins-sg</code> allows inbound port 22, and instance is in a public subnet with public IP.</li> </ul>"},{"location":"capstone/08_lab06/#deliverables","title":"Deliverables","text":"<ul> <li> <p>Repo files:</p> </li> <li> <p><code>infrastructure/jenkins/*</code></p> </li> <li>Updated <code>infrastructure/main.tf</code></li> <li>Updated <code>infrastructure/outputs.tf</code></li> <li>Public key <code>infrastructure/jenkins_id_rsa.pub</code></li> <li> <p>Screenshots:</p> </li> <li> <p>Terraform Cloud run with Outputs</p> </li> <li>AWS EC2 console with <code>jenkins-server</code></li> <li>Successful SSH login</li> </ul>"},{"location":"capstone/08_lab06/#reflection-question","title":"Reflection Question","text":"<p>Why is it critical to keep the private key (<code>id_rsa</code>) out of Git and only commit the public key? What security risks arise if the private key is leaked?</p> <p>\u2705 Lab 06 Complete</p>"},{"location":"capstone/09_lab07/","title":"Lab 07: Bootstrap Jenkins with Ansible","text":""},{"location":"capstone/09_lab07/#roles-responsible","title":"Role(s) Responsible","text":"<p>SysAdmin / Infra</p>"},{"location":"capstone/09_lab07/#objectives","title":"Objectives","text":"<ul> <li>Bootstrap a Jenkins server (install OpenJDK 17 + Jenkins) on the EC2 instance provisioned in Lab 06 using Ansible.</li> <li>Ensure Jenkins starts (Java 17), and show the <code>initialAdminPassword</code> so an operator can unlock the UI.</li> <li>Install required plugin on Jenkins server</li> </ul>"},{"location":"capstone/09_lab07/#pre-requisites","title":"Pre-requisites","text":"<ul> <li>Lab 06 completed: Jenkins EC2 created and <code>jenkins_public_ip</code> exposed at root outputs in Terraform.</li> <li><code>terraform</code> CLI configured to the same backend (or access to Terraform Cloud workspace runs).</li> <li>SSH private key used when provisioning (<code>infrastructure/id_rsa</code>) available locally (never commit private key).</li> <li><code>ansible</code> installed on control host (Lab 01).</li> <li>Git access to team repo.</li> <li>Internet outbound from the Jenkins VM (for GUI/CLI plugin installs). If air-gapped, follow the offline plugin instructions below.</li> </ul>"},{"location":"capstone/09_lab07/#quick-theory-recap","title":"Quick theory recap","text":"<p>Ansible connects over SSH to the target node (<code>ubuntu</code> user on our Ubuntu AMI), installs Java 17 and Jenkins package, ensures Jenkins is running, and then reads the unlock password at <code>/var/lib/jenkins/secrets/initialAdminPassword</code>. We intentionally stop short of auto-installing plugins via init scripts because plugin bootstrapping can fail during first-run; instead we expose the password so a human can complete the GUI unlock and install plugins </p>"},{"location":"capstone/09_lab07/#files-youll-add-edit-in-the-repo","title":"Files you'll add / edit in the repo","text":"<ul> <li><code>ansible/playbooks/jenkins_install_and_show_password.yml</code> (main playbook \u2014 provided below).</li> <li><code>ansible/inventories/jenkins.ini</code> (inventory \u2014 created during the lab; uses Terraform output to populate IP).</li> <li>(Optional) <code>ansible/playbooks/plugins_install_cli.yml</code> \u2014 helper playbook that runs plugin installs via CLI after admin user exists (optional, provided below).</li> <li>Do NOT commit any private keys. Commit only public key if used for <code>aws_key_pair</code>.</li> </ul>"},{"location":"capstone/09_lab07/#step-by-step-instructions","title":"Step-by-step instructions","text":"<p>These steps assume the student running this lab might be different from the person who ran earlier labs. Use your team GitHub account/SSH key.</p>"},{"location":"capstone/09_lab07/#0-clone-or-update-the-repo","title":"0. Clone or update the repo","text":"<p>If you don't have the repo locally:</p> <pre><code>git clone git@github.com:&lt;org&gt;/&lt;techops-capstone-teamX&gt;.git\ncd techops-capstone-teamX\n</code></pre> <p>If you already have the repo:</p> <pre><code>cd path/to/techops-capstone-teamX\ngit checkout main\ngit pull origin main\n</code></pre> <p>Create a feature branch for your work:</p> <pre><code>git checkout -b ansible-jenkins-setup\n</code></pre>"},{"location":"capstone/09_lab07/#1-get-jenkins-public-ip-from-your-sysadminiam-engineerproduct-owner","title":"1. Get Jenkins public IP from your SysAdmin/IAM Engineer/Product Owner","text":"<p>Option A \u2014 Terraform Cloud web UI:</p> <ul> <li>Go to Terraform Cloud \u2192 Organization \u2192 Workspace <code>capstone-infra</code> \u2192 Runs \u2192 latest run \u2192 Outputs \u2192 copy <code>jenkins_public_ip</code>.</li> </ul> <p>Put that IP into the inventory in next step.</p>"},{"location":"capstone/09_lab07/#2-ensure-your-private-key-and-permissions-are-correct","title":"2. Ensure your private key and permissions are correct","text":"<ul> <li>Your private key (generated earlier in Lab 06) must be present locally (example path used below is <code>infrastructure/id_rsa</code>).</li> <li>Permissions:</li> </ul> <pre><code>chmod 600 infrastructure/id_rsa\n</code></pre> <ul> <li>Confirm you can SSH (use correct user for Ubuntu AMI: <code>ubuntu</code>):</li> </ul> <p><pre><code>ssh -i infrastructure/id_rsa ubuntu@&lt;jenkins_public_ip&gt;\n# if successful, exit with `exit`\n</code></pre> * If you do not have the private key ask the user who ran the Lab06 to give you, put that key in your repo under <code>&lt;your-repo&gt;/infrastructure/id_rsa</code></p>"},{"location":"capstone/09_lab07/#3-create-ansible-inventory","title":"3. Create Ansible inventory","text":"<p>Create file <code>ansible/inventories/jenkins.ini</code> (relative paths shown assume running from repo root):</p> <pre><code>[jenkins]\n&lt;jenkins_public_ip&gt; ansible_user=ubuntu ansible_ssh_private_key_file=.../&lt;full_path_to&gt;/infrastructure/id_rsa\n</code></pre> <p>Replace <code>&lt;jenkins_public_ip&gt;</code> with the IP you got from Terraform.</p>"},{"location":"capstone/09_lab07/#4-add-the-playbook-to-install-jenkins-and-display-the-unlock-password","title":"4. Add the playbook to install Jenkins and display the unlock password","text":"<p>Create <code>ansible/playbooks/jenkins_install_and_show_password.yml</code> with the exact content below (copy-paste):</p> <pre><code>---\n- name: Install Jenkins and display initial admin password\n  hosts: jenkins\n  become: yes\n  vars:\n    jenkins_home: /var/lib/jenkins\n    java_home_path: \"/usr/lib/jvm/java-17-openjdk-amd64\"\n    jenkins_cli_path: /tmp/jenkins-cli.jar\n    jenkins_url_local: \"http://localhost:8080\"\n\n  tasks:\n    - name: Update apt cache\n      apt:\n        update_cache: yes\n        cache_valid_time: 3600\n\n    - name: Install packages required for apt over https and utils\n      apt:\n        name:\n          - apt-transport-https\n          - ca-certificates\n          - curl\n          - gnupg\n          - lsb-release\n          - software-properties-common\n        state: present\n        update_cache: yes\n\n    - name: Install OpenJDK 17\n      apt:\n        name: openjdk-17-jdk\n        state: present\n\n    - name: Ensure JAVA_HOME is set for Jenkins\n      lineinfile:\n        path: /etc/default/jenkins\n        regexp: '^JAVA_HOME='\n        line: 'JAVA_HOME=\"{{ java_home_path }}\"'\n        create: yes\n      notify: Restart Jenkins\n\n    - name: Add Jenkins apt key\n      apt_key:\n        url: https://pkg.jenkins.io/debian-stable/jenkins.io-2023.key\n        state: present\n\n    - name: Add Jenkins apt repository\n      apt_repository:\n        repo: 'deb https://pkg.jenkins.io/debian-stable binary/'\n        state: present\n\n    - name: Update apt after adding jenkins repo\n      apt:\n        update_cache: yes\n\n    - name: Install Jenkins package\n      apt:\n        name: jenkins\n        state: present\n\n    - name: Ensure jenkins home ownership and perms\n      file:\n        path: \"{{ jenkins_home }}\"\n        state: directory\n        owner: jenkins\n        group: jenkins\n        recurse: yes\n\n    - name: Ensure Jenkins service is started &amp; enabled\n      service:\n        name: jenkins\n        state: started\n        enabled: yes\n\n    - name: Wait for Jenkins HTTP to be available locally\n      wait_for:\n        host: 127.0.0.1\n        port: 8080\n        timeout: 300\n        state: started\n\n    - name: Give Jenkins a few extra seconds to initialize\n      pause:\n        seconds: 8\n\n    - name: Read initial admin password (if present)\n      command: cat {{ jenkins_home }}/secrets/initialAdminPassword\n      register: initial_pass_cmd\n      ignore_errors: yes\n      changed_when: false\n\n    - name: Show initial admin password (if found)\n      debug:\n        msg: |\n          === Jenkins initial admin password (if present) ===\n          {{ initial_pass_cmd.stdout | default(\"NOT FOUND: initialAdminPassword file missing or setup already completed\") }}\n      when: initial_pass_cmd is defined\n\n  handlers:\n    - name: Restart Jenkins\n      service:\n        name: jenkins\n        state: restarted\n</code></pre>"},{"location":"capstone/09_lab07/#5-run-the-playbook","title":"5. Run the playbook","text":"<p>From repo root:</p> <pre><code>ansible-playbook -i ansible/inventories/jenkins.ini ansible/playbooks/jenkins_install_and_show_password.yml\n</code></pre> <p>Look at the playbook output \u2014 you\u2019ll see a <code>debug</code> message with the <code>initialAdminPassword</code> or a message that it\u2019s not found (setup already completed or an init Groovy created admin earlier).</p>"},{"location":"capstone/09_lab07/#6-unlock-jenkins-via-ui-create-admin","title":"6. Unlock Jenkins via UI &amp; create admin","text":"<ol> <li>Open <code>http://&lt;jenkins_public_ip&gt;:8080</code> in your browser.</li> <li>Paste the <code>initialAdminPassword</code> from the playbook output and proceed.</li> <li>Choose \u201cInstall suggested plugins\u201d (quick).</li> <li>Create the admin account when prompted and save credentials.</li> </ol>"},{"location":"capstone/09_lab07/#7-install-plugins","title":"7. Install plugins","text":""},{"location":"capstone/09_lab07/#manual-via-jenkins-ui-recommended-for-first-run","title":"Manual via Jenkins UI (recommended for first-run)","text":"<ul> <li>Manage Jenkins \u2192 Manage Plugins \u2192 Available \u2192 search &amp; install required plugins (Git, Pipeline, Docker, Blue Ocean, Ansible, Credentials Binding, etc.)</li> <li>After installing, perform Safe Restart if prompted.</li> </ul>"},{"location":"capstone/09_lab07/#8-prepare-the-jenkins-node","title":"8. Prepare the Jenkins Node","text":"<ol> <li>Create a new playbook <code>ansible/playbooks/prepare_jenkins_node.yml</code></li> <li>Copy &amp; Paste below playbook which will bootstrap the node and install all dependencies on Jenkins</li> </ol> <p><pre><code>---\n # ansible/playbooks/jenkins_prepare_node.yml\n # Idempotent playbook to prepare a Jenkins EC2 node with Docker, AWS CLI, and common tools.\n # Supports Debian/Ubuntu, RHEL/CentOS, and Amazon Linux.\n #\n # Usage:\n # ansible-playbook -i ansible/inventories/jenkins.ini ansible/playbooks/jenkins_prepare_node.yml\n\n - name: Prepare Jenkins node (Docker, AWS CLI, common tools)\n hosts: jenkins\n vars:\n     awscli_version: \"latest\"  # Use latest to avoid version mismatch\n     docker_ce_version: \"24.0.7\"  # Base Docker version (will append distribution suffix for Debian/Ubuntu)\n     docker_compose_plugin: true\n     jenkins_user: \"jenkins\"\n     jenkins_service_name: \"jenkins\"\n     arch_map:\n     x86_64: amd64\n     aarch64: arm64\n     docker_compose_arch_map:\n     x86_64: x86_64\n     aarch64: aarch64\n     awscli_zip_url: \"https://awscli.amazonaws.com/awscli-exe-linux-{{ docker_compose_arch_map[ansible_architecture] | default(ansible_architecture) }}.zip\"\n     docker_compose_url: \"https://github.com/docker/compose/releases/latest/download/docker-compose-Linux-{{ docker_compose_arch_map[ansible_architecture] | default(ansible_architecture) }}\"\n\n pre_tasks:\n     - name: Gather minimal facts\n     ansible.builtin.setup:\n         gather_subset:\n         - '!all'\n         - 'min'\n     changed_when: false\n     become: no\n\n tasks:\n     # -----------------------\n     # Common Packages\n     # -----------------------\n     - name: Install common packages (Debian/Ubuntu)\n     when: ansible_os_family == 'Debian'\n     apt:\n         name:\n         - apt-transport-https\n         - ca-certificates\n         - curl\n         - gnupg\n         - lsb-release\n         - unzip\n         - git\n         - jq\n         - build-essential\n         update_cache: yes\n         state: present\n     become: yes\n\n     - name: Install common packages (RHEL/CentOS)\n     when: ansible_os_family == 'RedHat' and ansible_distribution != 'Amazon'\n     yum:\n         name:\n         - curl\n         - unzip\n         - git\n         - jq\n         - python3\n         - gcc\n         - make\n         state: present\n     become: yes\n\n     - name: Install common packages (Amazon Linux)\n     when: ansible_distribution == 'Amazon'\n     yum:\n         name:\n         - curl\n         - unzip\n         - git\n         - jq\n         - python3\n         - gcc\n         - make\n         state: present\n     become: yes\n\n     # -----------------------\n     # Docker repo + engine\n     # -----------------------\n     - name: Ensure docker GPG key and keyring (Debian)\n     when: ansible_os_family == 'Debian'\n     block:\n         - name: Create /usr/share/keyrings if missing\n         file:\n             path: /usr/share/keyrings\n             state: directory\n             mode: '0755'\n         become: yes\n\n         - name: Download Docker GPG and create keyring\n         command: &gt;\n             bash -lc \"curl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg\"\n         args:\n             creates: /usr/share/keyrings/docker-archive-keyring.gpg\n         become: yes\n\n         - name: Add Docker apt repo\n         apt_repository:\n             repo: \"deb [arch={{ arch_map[ansible_architecture] | default(ansible_architecture) }} signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu {{ ansible_distribution_release }} stable\"\n             filename: docker\n             state: present\n         notify: apt_update\n         become: yes\n\n     - name: Update apt cache (Debian)\n     when: ansible_os_family == 'Debian'\n     apt:\n         update_cache: yes\n     become: yes\n\n     - name: Get available Docker versions (Debian)\n     when: ansible_os_family == 'Debian'\n     shell: apt-cache madison docker-ce | awk '{print $3}' | grep \"{{ docker_ce_version }}\"\n     register: docker_version_check\n     changed_when: false\n     failed_when: false\n     become: yes\n\n     - name: Set Docker version with distribution suffix (Debian)\n     set_fact:\n         effective_docker_version: \"{{ (docker_version_check.stdout_lines | select('match', '^5:' + docker_ce_version + '-1~ubuntu\\\\.' + ansible_distribution_version + '~' + ansible_distribution_release + '$') | first) | default('latest') }}\"\n     when: ansible_os_family == 'Debian'\n\n     - name: Warn if falling back to latest Docker version\n     debug:\n         msg: \"Desired Docker version {{ docker_ce_version }} not found for {{ ansible_distribution }} {{ ansible_distribution_version }}. Falling back to latest.\"\n     when: ansible_os_family == 'Debian' and effective_docker_version == 'latest'\n\n     - name: Add Docker repo (RHEL/CentOS)\n     when: ansible_os_family == 'RedHat' and ansible_distribution != 'Amazon'\n     yum_repository:\n         name: docker-ce-stable\n         description: Docker CE Stable - $basearch\n         baseurl: \"https://download.docker.com/linux/centos/{{ ansible_distribution_major_version }}/{{ arch_map[ansible_architecture] | default(ansible_architecture) }}/stable\"\n         gpgcheck: yes\n         gpgkey: https://download.docker.com/linux/centos/gpg\n         enabled: yes\n     become: yes\n\n     - name: Enable Docker in amazon-linux-extras (Amazon Linux)\n     when: ansible_distribution == 'Amazon'\n     command: amazon-linux-extras install docker -y\n     args:\n         creates: /usr/bin/docker\n     become: yes\n\n     - name: Install Docker engine (Debian)\n     when: ansible_os_family == 'Debian'\n     apt:\n         name:\n         - docker-ce={{ effective_docker_version | default('latest') }}\n         - docker-ce-cli={{ effective_docker_version | default('latest') }}\n         - containerd.io\n         state: present\n     register: docker_install_debian\n     notify: restart docker\n     become: yes\n\n     - name: Install Docker engine (RHEL/CentOS)\n     when: ansible_os_family == 'RedHat' and ansible_distribution != 'Amazon'\n     yum:\n         name:\n         - docker-ce={{ docker_ce_version }}\n         - docker-ce-cli={{ docker_ce_version }}\n         - containerd.io\n         state: present\n     register: docker_install_rhel\n     notify: restart docker\n     become: yes\n\n     - name: Ensure docker service is enabled and started\n     service:\n         name: docker\n         state: started\n         enabled: yes\n     become: yes\n\n     - name: Try to install docker-compose plugin (Debian)\n     when: ansible_os_family == 'Debian' and docker_compose_plugin\n     apt:\n         name: docker-compose-plugin\n         state: present\n     register: docker_compose_pkg\n     failed_when: false\n     become: yes\n\n     - name: Try to install docker-compose plugin (RHEL/CentOS)\n     when: ansible_os_family == 'RedHat' and ansible_distribution != 'Amazon' and docker_compose_plugin\n     yum:\n         name: docker-compose-plugin\n         state: present\n     register: docker_compose_pkg\n     failed_when: false\n     become: yes\n\n     - name: Fallback - install docker-compose binary if plugin not available\n     when: docker_compose_plugin and (docker_compose_pkg is failed or docker_compose_pkg is skipped)\n     block:\n         - name: Check if docker-compose binary exists\n         stat:\n             path: /usr/local/bin/docker-compose\n         register: docker_compose_binary\n         become: yes\n\n         - name: Download docker-compose binary (fallback)\n         get_url:\n             url: \"{{ docker_compose_url }}\"\n             dest: /usr/local/bin/docker-compose\n             mode: '0755'\n         when: not docker_compose_binary.stat.exists\n         become: yes\n\n         - name: Ensure docker-compose is executable\n         file:\n             path: /usr/local/bin/docker-compose\n             mode: '0755'\n         become: yes\n\n     - name: Ensure jenkins user exists\n     user:\n         name: \"{{ jenkins_user }}\"\n         state: present\n         create_home: yes\n         shell: /bin/bash\n     become: yes\n\n     - name: Check if jenkins user exists\n     getent:\n         database: passwd\n         key: \"{{ jenkins_user }}\"\n     register: jenkins_user_check\n     failed_when: false\n     become: no\n\n     - name: Add jenkins user to docker group\n     when: jenkins_user_check.getent_passwd is defined\n     user:\n         name: \"{{ jenkins_user }}\"\n         groups: docker\n         append: yes\n     notify: restart jenkins\n     become: yes\n\n     - name: Ensure AWS CLI is executable by all\n     file:\n         path: /usr/local/bin/aws\n         mode: '0755'\n     become: yes\n\n     # -----------------------\n     # AWS CLI v2\n     # -----------------------\n     - name: Check installed AWS CLI version\n     command: /usr/local/bin/aws --version\n     register: aws_ver_check\n     changed_when: false\n     failed_when: false\n     become: no\n\n     - name: Download AWS CLI v2 installer zip\n     when: aws_ver_check.rc != 0 or awscli_version not in aws_ver_check.stdout\n     get_url:\n         url: \"{{ awscli_zip_url }}\"\n         dest: \"/home/{{ ansible_user }}/awscliv2.zip\"\n         mode: '0644'\n     become: no\n\n     - name: Unzip AWS CLI installer\n     when: aws_ver_check.rc != 0 or awscli_version not in aws_ver_check.stdout\n     unarchive:\n         src: \"/home/{{ ansible_user }}/awscliv2.zip\"\n         dest: \"/home/{{ ansible_user }}\"\n         remote_src: yes\n     become: no\n\n     - name: Install AWS CLI v2\n     when: aws_ver_check.rc != 0 or awscli_version not in aws_ver_check.stdout\n     command: \"/home/{{ ansible_user }}/aws/install\"\n     args:\n         creates: /usr/local/bin/aws\n     become: yes\n\n     - name: Clean up AWS CLI installer files\n     when: aws_ver_check.rc == 0 and awscli_version in aws_ver_check.stdout\n     file:\n         path: \"{{ item }}\"\n         state: absent\n     loop:\n         - \"/home/{{ ansible_user }}/awscliv2.zip\"\n         - \"/home/{{ ansible_user }}/aws\"\n     become: no\n\n     - name: Verify aws is executable\n     command: /usr/local/bin/aws --version\n     register: aws_ver\n     changed_when: false\n     failed_when: aws_ver.rc != 0\n     become: no\n\n     - name: Debug aws verification failure\n     debug:\n         msg: \"Failed to verify aws cli: {{ aws_ver.stderr | default('No stderr available') }}\"\n     when: aws_ver.rc != 0\n     become: no\n\n     # -----------------------\n     # Final sanity checks as jenkins user\n     # -----------------------\n     - name: Verify docker command as jenkins user\n     become_user: \"{{ jenkins_user }}\"\n     command: docker --version\n     register: docker_ver\n     changed_when: false\n     failed_when: false\n     when: jenkins_user_check.getent_passwd is defined\n     become: yes\n\n     - name: Debug docker verification failure as jenkins user\n     debug:\n         msg: \"Failed to verify docker as {{ jenkins_user }}: {{ docker_ver.stderr | default('No stderr available') }}\"\n     when: jenkins_user_check.getent_passwd is defined and docker_ver is defined and docker_ver.rc != 0\n     become: no\n\n     - name: Verify aws cli as jenkins user\n     become_user: \"{{ jenkins_user }}\"\n     command: /usr/local/bin/aws --version\n     register: aws_j_ver\n     changed_when: false\n     failed_when: false\n     when: jenkins_user_check.getent_passwd is defined\n     become: yes\n\n     - name: Debug aws cli verification failure as jenkins user\n     debug:\n         msg: \"Failed to verify aws cli as {{ jenkins_user }}: {{ aws_j_ver.stderr | default('No stderr available') }}\"\n     when: jenkins_user_check.getent_passwd is defined and aws_j_ver is defined and aws_j_ver.rc != 0\n     become: no\n\n handlers:\n     - name: apt_update\n     apt:\n         update_cache: yes\n     become: yes\n\n     - name: restart docker\n     service:\n         name: docker\n         state: started\n     when: docker_install_debian.changed or docker_install_rhel.changed\n     become: yes\n\n     - name: restart jenkins\n     service:\n         name: \"{{ jenkins_service_name }}\"\n         state: restarted\n     become: yes\n</code></pre> 3. Runt the playbook     <pre><code>ansible-playbook -i ansible/inventories/jenkins.ini ansible/playbooks/jenkins_prepare_node.yml\n</code></pre></p>"},{"location":"capstone/09_lab07/#8-commit-push-to-github","title":"8. Commit &amp; Push to Github","text":"<pre><code>git add ansible/*\ngit commit -m \"Jenkins Installed via Ansible &amp; Configured\"\ngit push origin ansible-jenkins-setup\n</code></pre>"},{"location":"capstone/09_lab07/#9-pr-merge","title":"9. PR &amp; Merge","text":"<ul> <li>Open PR \u2192 Title: <code>Jenkins Installed via Ansible &amp; Configured</code></li> <li>Request review, approve, merge into <code>main</code>.</li> </ul>"},{"location":"capstone/09_lab07/#checkpoint-validation","title":"Checkpoint / Validation","text":"<ul> <li>Playbook run completed and printed the <code>initialAdminPassword</code> (or indicated password already set).</li> <li>You can access Jenkins UI at <code>http://&lt;jenkins_public_ip&gt;:8080</code>.</li> <li>You were able to unlock Jenkins with the printed password and create the admin user.</li> <li>Plugins installed (either via UI or CLI) and Jenkins restarted successfully.</li> </ul>"},{"location":"capstone/09_lab07/#troubleshooting-tips","title":"Troubleshooting Tips","text":"<ul> <li><code>initialAdminPassword</code> not found \u2192 either setup already completed (admin user exists) or <code>init.groovy.d</code> created an account. If setup already completed, log in with the created admin credentials.</li> <li>Jenkins fails to start \u2192 check <code>sudo journalctl -u jenkins -b --no-pager -n 200</code> for errors. Common causes: wrong Java version (need Java 17/21), broken Groovy init scripts, ownership issues.</li> <li>Java error: ensure <code>openjdk-17-jdk</code> installed and <code>/etc/default/jenkins</code> has <code>JAVA_HOME=\"/usr/lib/jvm/java-17-openjdk-amd64\"</code>.</li> <li>SSH auth errors: ensure private key has <code>chmod 600</code> and inventory uses <code>ansible_user=ubuntu</code>.</li> <li>Plugin install fails due to network/timeouts: use server-local CLI or offline <code>.hpi</code> uploads.</li> </ul>"},{"location":"capstone/09_lab07/#deliverables-what-to-commit-submit","title":"Deliverables (what to commit / submit)","text":"<ul> <li><code>ansible/playbooks/jenkins_install_and_show_password.yml</code> (playbook).</li> <li><code>ansible/inventories/jenkins.ini</code> (careful \u2014 does not contain secrets).</li> <li>(Optional) <code>ansible/playbooks/plugins_install_cli.yml</code> if you used it.</li> <li>Do not commit any private keys or passwords. Commit only the public key if used by Terraform (<code>infrastructure/jenkins_id_rsa.pub</code>).</li> <li>Screenshots / evidence: playbook run showing <code>initialAdminPassword</code>, Jenkins UI unlocked, list of installed plugins (Manage Plugins).</li> </ul>"},{"location":"capstone/09_lab07/#reflection-question","title":"Reflection Question","text":"<p>Why did we decide to show the <code>initialAdminPassword</code> and complete the plugin installation manually (or with CLI after admin exists) rather than fully automating plugin installs on the very first boot? What are the trade-offs (stability, security, repeatability)?</p> <p>\u2705 Lab 07 - complete \u2014 Jenkins is installed, unlocked, and ready to be configured by the team.</p>"},{"location":"capstone/10_lab08/","title":"Lab 08 \u2014 Jenkins Credentials Setup","text":"<p>Role(s) Responsible IAM Engineer</p> <p>Objectives</p> <ul> <li>Add the required credentials to Jenkins Credentials store (System scope) using only the Jenkins Web UI.</li> <li>Use the same credential IDs used by pipelines: <code>github-token</code>, <code>dockerhub-token</code>, <code>terraform-token</code>, <code>aws-jenkins-access</code>, <code>ssh-jenkins</code>.</li> <li>Validate credentials appear in Jenkins UI and are consumable by pipelines.</li> </ul> <p>Pre-reqs</p> <ul> <li>Jenkins EC2 already created and accessible (from earlier labs).</li> <li>You have Jenkins admin username &amp; password (created in Lab 07).</li> <li>Access to the accounts used for tokens: GitHub, Docker Hub, Terraform Cloud, AWS Console.</li> <li>SSH private key available locally if you choose to upload SSH credentials.</li> </ul>"},{"location":"capstone/10_lab08/#high-level-flow-one-line","title":"High-level flow (one-line)","text":"<ol> <li>Retrieve/generate tokens and keys from provider UIs (GitHub, DockerHub, Terraform Cloud, AWS).</li> <li>Login to Jenkins Web UI as admin.</li> <li>For each credential type, add a new credential under Manage Jenkins \u2192 Manage Credentials \u2192 System \u2192 Global with the exact ID that pipelines expect.</li> <li>Validate via Jenkins UI and run a simple pipeline that references the credentials.</li> </ol> <p>Important: Use the same credential IDs listed below \u2014 pipelines reference these IDs exactly.</p>"},{"location":"capstone/10_lab08/#credentials-ids-same-ids-as-original-playbook","title":"Credentials &amp; IDs (same IDs as original playbook)","text":"<ul> <li><code>github-token</code> \u2192 GitHub Personal Access Token (PAT)</li> <li><code>dockerhub-token</code> \u2192 Docker Hub Access Token (username+token)</li> <li><code>terraform-token</code> \u2192 Terraform Cloud API token (workspace/organization API token)</li> <li><code>aws-jenkins-access</code> \u2192 AWS Access Key ID / Secret (optional; prefer instance profile if available)</li> <li><code>ssh-jenkins</code> \u2192 SSH private key credential for pipelines (optional)</li> </ul>"},{"location":"capstone/10_lab08/#1-retrieve-generate-tokens-keys-from-provider-uis","title":"1) Retrieve / generate tokens &amp; keys from provider UIs","text":""},{"location":"capstone/10_lab08/#a-github-personal-access-token-classic-or-fine-grained-pat","title":"A \u2014 GitHub Personal Access Token (classic or fine-grained PAT)","text":"<ol> <li>Sign into GitHub (https://github.com).</li> <li>Click your avatar \u2192 Settings \u2192 Developer settings \u2192 Personal access tokens \u2192 Tokens (classic) (or Fine-grained tokens if your org allows).</li> <li>Click Generate new token \u2192 give a descriptive name (e.g., <code>jenkins-lab-08</code>) and set expiration (choose short-lived for labs, e.g., 7 days).</li> <li> <p>Select scopes:</p> <ul> <li>For classic: check all the boxes (Note: This is only for demo, in enterprise you will neeed to select granular access)</li> </ul> </li> <li> <p>Click Generate token and copy the token immediately (GitHub shows it only once).</p> </li> <li>Save the token securely locally (we\u2019ll paste it into Jenkins next).</li> </ol> <p>Value to use in Jenkins: paste as Secret Text and set credential ID = <code>github-token</code>.</p>"},{"location":"capstone/10_lab08/#b-docker-hub-access-token","title":"B \u2014 Docker Hub Access Token","text":"<ol> <li>Sign into Docker Hub (https://hub.docker.com).</li> <li>Click your profile \u2192 Account Settings \u2192 Security \u2192 Personal Access Tokens (or directly Personal Access Tokens).</li> <li>Click Create Access Token \u2192 name it <code>jenkins-lab-08</code> \u2192 Access Permission: <code>Read,Write, Delete</code> \u2192 click Generate.</li> <li>Copy the token string shown (this is only shown once).</li> <li>Note your DockerHub username.</li> </ol> <p>Value to use in Jenkins: add credential type Username with password:</p> <ul> <li>Username = your DockerHub username</li> <li>Password = Docker Hub Access Token</li> <li>Credential ID = <code>dockerhub-token</code></li> </ul>"},{"location":"capstone/10_lab08/#c-terraform-cloud-api-token","title":"C \u2014 Terraform Cloud API Token","text":"<ol> <li>Login to Terraform Cloud (https://app.terraform.io).</li> <li>Click your avatar \u2192 Account Settings \u2192 Tokens \u2192 Create an API token.</li> <li>Give it a name (e.g., <code>jenkins-lab-08</code>) and create.</li> <li>Copy token string (store it safely \u2014 it's shown only once).</li> </ol> <p>Value to use in Jenkins: add Secret Text credential:</p> <ul> <li>Secret = Terraform token</li> <li>ID = <code>terraform-token</code></li> </ul>"},{"location":"capstone/10_lab08/#2-add-credentials-to-jenkins-ui-steps-exact-clicks","title":"2) Add credentials to Jenkins (UI steps, exact clicks)","text":"<ol> <li>Open Jenkins UI: <code>http://&lt;JENKINS_PUBLIC_IP&gt;:8080</code> \u2192 login as admin.</li> <li>From the left menu click Manage Jenkins.</li> <li> <p>Click Manage Credentials or Credentials.</p> </li> <li> <p>If you have multiple domains, choose (global) or System \u2192 Global credentials (unrestricted) (varies by Jenkins version).</p> </li> <li>Click Add Credentials (left or drop-down).</li> <li>For each credential type below, fill the Kind, Scope, ID, Description, Secret/Username/Password/Key, then OK.</li> </ol>"},{"location":"capstone/10_lab08/#add-github-pat","title":"Add GitHub PAT","text":"<ul> <li>Kind: Secret text</li> <li>Secret: paste GitHub PAT</li> <li>ID: <code>github-token</code></li> <li>Description: <code>GitHub PAT for IAM Engineer - Lab 08</code></li> <li>Scope: Global/System \u2192 OK</li> </ul>"},{"location":"capstone/10_lab08/#add-docker-hub-usernametoken","title":"Add Docker Hub username+token","text":"<ul> <li>Kind: Username with password</li> <li>Username: your DockerHub username</li> <li>Password: Docker Hub access token (not your account password)</li> <li>ID: <code>dockerhub-token</code></li> <li>Description: <code>Docker Hub creds for pushing images</code> \u2192 OK</li> </ul>"},{"location":"capstone/10_lab08/#add-terraform-cloud-token","title":"Add Terraform Cloud token","text":"<ul> <li>Kind: Secret text</li> <li>Secret: Terraform token</li> <li>ID: <code>terraform-token</code></li> <li>Description: <code>Terraform Cloud API token for workspace</code> \u2192 OK</li> </ul>"},{"location":"capstone/10_lab08/#3-verify-credentials-in-jenkins-ui","title":"3) Verify credentials in Jenkins UI","text":"<ol> <li> <p>Manage Jenkins \u2192 Manage Credentials \u2192 System \u2192 Global.</p> </li> <li> <p>Verify each credential ID appears:</p> </li> <li> <p><code>github-token</code></p> </li> <li><code>dockerhub-token</code></li> <li> <p><code>terraform-token</code></p> </li> <li> <p>Click a credential and verify description/metadata (you cannot view secret values \u2014 only that it exists).</p> </li> </ol>"},{"location":"capstone/10_lab08/#4-test-credentials-by-creating-a-quick-pipeline-ui-only","title":"4) Test credentials by creating a quick pipeline (UI-only)","text":"<p>Create a simple Declarative Pipeline in Jenkins UI that references the IDs; this proves the credentials are usable.</p>"},{"location":"capstone/10_lab08/#steps-ui","title":"Steps (UI)","text":"<ol> <li>Jenkins Dashboard \u2192 New Item \u2192 name: <code>lab08-test-credentials</code> \u2192 Pipeline \u2192 OK.</li> <li>Under Pipeline definition, choose Pipeline script and paste the snippet below.</li> <li>Click Save \u2192 click Build Now \u2192 review console output.</li> </ol>"},{"location":"capstone/10_lab08/#pipeline-test-snippet-declarative","title":"Pipeline test snippet (Declarative)","text":"<pre><code>pipeline {\n  agent any\n  parameters {\n    choice(name: 'USE_AWS_KEYS', choices: ['no', 'yes'], description: 'Set to yes to test AWS using stored aws-jenkins-access credentials instead of instance profile')\n  }\n  environment {\n    AWS_REGION = 'ap-south-1'\n  }\n\n  stages {\n    stage('Prepare') {\n      steps {\n        echo \"Running on: ${env.NODE_NAME}\"\n        sh 'echo \"Workspace: $WORKSPACE\"'\n      }\n    }\n\n    stage('Test GitHub PAT (authenticated user)') {\n      steps {\n        withCredentials([string(credentialsId: 'github-token', variable: 'GHTOKEN')]) {\n          sh '''#!/bin/bash\nset -euo pipefail\necho \"GitHub token length: $(echo -n \"$GHTOKEN\" | wc -c)\"\n\nHTTP_CODE=$(curl -s -o /tmp/gh_user.json -w \"%{http_code}\" -H \"Authorization: token ${GHTOKEN}\" https://api.github.com/user || true)\necho \"GitHub API HTTP status: $HTTP_CODE\"\nif [ \"$HTTP_CODE\" -ne 200 ]; then\n  echo \"Returned JSON:\"\n  cat /tmp/gh_user.json || true\n  echo \"GitHub token test failed (HTTP $HTTP_CODE)\"\n  exit 2\nfi\n\nif command -v jq &gt;/dev/null 2&gt;&amp;1; then\n  echo \"Authenticated GitHub login: $(jq -r '.login' /tmp/gh_user.json || echo '&lt;no-jq-present&gt;')\"\nelse\n  echo \"jq not present \u2014 printing raw login field with grep/sed:\"\n  grep -o '\"login\":[^,]*' /tmp/gh_user.json || true\nfi\n'''\n        }\n      }\n    }\n\n    stage('Test DockerHub creds &amp; Docker access') {\n      steps {\n        withCredentials([usernamePassword(credentialsId: 'dockerhub-token', usernameVariable: 'DH_USER', passwordVariable: 'DH_PASS')]) {\n          sh '''#!/bin/bash\nset -euo pipefail\necho \"Docker CLI version:\"\ndocker --version || true\n\necho \"Testing docker socket access (docker ps):\"\ndocker ps --format 'table {{.Names}}\\t{{.Status}}' || true\n\necho \"Attempting docker login (password masked):\"\necho \"$DH_PASS\" | docker login -u \"$DH_USER\" --password-stdin\n\necho \"docker login finished (if no errors above, login succeeded)\"\ndocker logout || true\n'''\n        }\n      }\n    }\n\n    stage('Test AWS (instance profile or stored keys)') {\n      steps {\n        script {\n          if (params.USE_AWS_KEYS == 'yes') {\n            echo \"Using stored AWS keys (aws-jenkins-access) for test\"\n            withCredentials([usernamePassword(credentialsId: 'aws-jenkins-access', usernameVariable: 'AWS_ID', passwordVariable: 'AWS_SECRET')]) {\n              sh '''#!/bin/bash\nset -euo pipefail\nexport AWS_ACCESS_KEY_ID=\"$AWS_ID\"\nexport AWS_SECRET_ACCESS_KEY=\"$AWS_SECRET\"\naws sts get-caller-identity --region ${AWS_REGION}\n'''\n            }\n          } else {\n            echo \"Using instance profile / role for AWS test (no stored keys)\"\n            sh '''#!/bin/bash\nset -euo pipefail\naws sts get-caller-identity --region ${AWS_REGION}\n'''\n          }\n        }\n      }\n    }\n  } // stages\n\n  post {\n    success {\n      echo \"All tests completed successfully.\"\n    }\n    failure {\n      echo \"At least one test failed \u2014 check console output for details.\"\n    }\n    always {\n      sh 'rm -f /tmp/gh_user.json || true'\n    }\n  }\n}\n</code></pre> <p>Notes:</p> <ul> <li>The pipeline uses <code>withCredentials</code> so secrets remain masked in logs.</li> <li>The <code>curl</code> and <code>docker login</code> operations demonstrate that tokens are valid (make sure <code>docker</code> and <code>aws</code> CLI are installed on the Jenkins agent if you run those stages).</li> <li>If your Jenkins agents do not have <code>docker</code> or <code>aws</code> CLI, run just the token-length checks or install required tools on the agent node.</li> </ul>"},{"location":"capstone/10_lab08/#5-deliverables-what-to-hand-in","title":"5) Deliverables \u2014 what to hand in","text":"<ol> <li> <p>Short report (1 page) confirming:</p> </li> <li> <p>You logged in as admin and added the credentials via Jenkins UI.</p> </li> <li>Which personal accounts were used (GitHub/Docker/Terraform/AWS) \u2014 say \u201cpersonal accounts\u201d (no sensitive values).</li> <li> <p>Screenshot(s):</p> </li> <li> <p>Jenkins Manage Credentials \u2192 Global showing the list with IDs visible (IDs and descriptions should be visible).</p> </li> <li>Pipeline console output showing masked secrets and successful API calls / login attempts (masking visible).</li> <li>Jenkins pipeline name: <code>lab08-test-credentials</code> (or name you used).</li> <li>Confirmation whether AWS keys were used, or instance role was preferred instead.</li> </ol>"},{"location":"capstone/10_lab08/#6-troubleshooting-ui-focused","title":"6) Troubleshooting (UI-focused)","text":"<ul> <li>Credential not visible: Ensure you added under System \u2192 Global scope and that you\u2019re viewing the same domain (Global domain). Jenkins has folder-scoped credentials \u2014 add at system/global level.</li> <li>Pipeline cannot find credential by ID: Confirm the exact ID string (IDs are case-sensitive) and that job has permission to access system/global credentials (usually default).</li> <li><code>docker login</code> fails: Ensure Jenkins agent has network access to Docker Hub and Docker CLI installed. Use token as password.</li> <li><code>curl</code> API returns 401: Token may be expired or scopes insufficient \u2014 regenerate token with required scopes.</li> <li>AWS CLI <code>sts get-caller-identity</code> fails: Ensure the AWS keys are valid and have minimal required permissions; rotate keys if accidentally committed.</li> <li>You accidentally committed a token file: Rotate the token immediately and, if needed, follow org policy for secret exposure.</li> </ul>"},{"location":"capstone/10_lab08/#7-optional-secure-practices-notes-for-instructors","title":"7) Optional \u2014 secure practices &amp; notes for instructors","text":"<ul> <li>Encourage students to create short-lived tokens (expiration 7\u201314 days) for labs and rotate them after the lab.</li> <li>Prefer instance profiles / IAM role for EC2-hosted Jenkins agents instead of long-lived AWS keys. If using instance profile, do not add <code>aws-jenkins-access</code>; pipelines can use instance-role automatically if running on the EC2 node. Add a note that pipeline code expecting <code>aws-jenkins-access</code> must be adjusted accordingly.</li> <li>Remove test credentials after the lab, or set them to expire.</li> <li>Students should never commit tokens to Git. If they do, rotate immediately.</li> </ul>"},{"location":"capstone/10_lab08/#8-quick-checklist-for-iam-engineer-copyable","title":"8) Quick checklist for IAM Engineer (copyable)","text":"<ul> <li> Generate GitHub PAT \u2192 saved locally</li> <li> Generate DockerHub access token \u2192 saved locally</li> <li> Generate Terraform Cloud API token \u2192 saved locally</li> <li> (Optional) Create AWS user + access keys (or confirm instance profile)</li> <li> (Optional) Generate SSH keypair for pipelines</li> <li> Login to Jenkins admin UI</li> <li> Add credentials (IDs exactly: <code>github-token</code>, <code>dockerhub-token</code>, <code>terraform-token</code>, <code>aws-jenkins-access</code>, <code>ssh-jenkins</code>)</li> <li> Create <code>lab08-test-credentials</code> pipeline and run tests</li> <li> Capture screenshots + short report</li> </ul>"},{"location":"capstone/11_lab09/","title":"Lab 09: Build Sample App &amp; Dockerize","text":"<p>Filename: <code>lab09.md</code> Role(s) Responsible: Developers</p>"},{"location":"capstone/11_lab09/#objectives","title":"Objectives","text":"<ul> <li>Clone the sample Flask app from the team repo and run it locally.</li> <li>Verify endpoints and create a simple unit test.</li> <li>Write a production-ready <code>Dockerfile</code>.</li> <li>Build and run the Docker image locally and validate the containerized app.</li> <li>Prepare required artifacts for Lab 10 (push to Docker Hub).</li> </ul>"},{"location":"capstone/11_lab09/#pre-requisites-exact-commands-steps","title":"Pre-requisites (exact commands / steps)","text":"<ol> <li>Local machine (Linux / macOS recommended; Windows WSL acceptable).</li> <li> <p>Git, Python 3.11+ (or 3.10), Docker (Engine + CLI) installed and running.</p> </li> <li> <p>Install checks:</p> <pre><code>git --version\npython3 --version\ndocker --version\ndocker compose version || true\n</code></pre> </li> </ol>"},{"location":"capstone/11_lab09/#theory-recap-34-sentences","title":"Theory Recap (3\u20134 sentences)","text":"<p>Dockerizing the app packages runtime, dependencies and the application into an immutable image so deployments are consistent across environments. Running the app locally first ensures functionality before containerizing. Using a small base image (e.g., <code>python:3.11-slim</code>) plus a production WSGI server (e.g., <code>gunicorn</code>) yields a stable container suitable for CI/CD. Tests give confidence for the build pipeline.</p>"},{"location":"capstone/11_lab09/#step-by-step-instructions-copy-paste-ready","title":"Step-by-Step Instructions (copy-paste-ready)","text":""},{"location":"capstone/11_lab09/#a-inspect-repo-run-the-app-locally","title":"A. Inspect repo &amp; run the app locally","text":"<ol> <li>Clone &amp; change dir:</li> </ol> <pre><code>git clone https://github.com/Sid-Trainings/flask-sample-webapp.git\ncd flask-sample-webapp\n</code></pre> <ol> <li>Look for the entrypoint (common filenames):</li> </ol> <pre><code>ls -la\n# Look for app.py, run.py, wsgi.py or a package folder with __init__.py\n</code></pre> <ol> <li>If there is a <code>requirements.txt</code>, install deps:</li> </ol> <pre><code>python3 -m venv .venv\nsource .venv/bin/activate\npip install --upgrade pip\npip install -r requirements.txt\n</code></pre> <ol> <li> <p>Run the app:</p> <pre><code>export FLASK_APP=app.py\nflask run --host=0.0.0.0 --port=5000\n</code></pre> </li> <li> <p>Test endpoint(s) locally:</p> </li> </ol> <p>If you are running from your laptop: In your browser open http://127.0.0.1:5000/</p> <p>OR</p> <p>If you are running on VM without desktop:</p> <pre><code>```bash\n# from the same machine\ncurl -i http://127.0.0.1:5000/\n# or a specific endpoint\ncurl -i http://127.0.0.1:5000/health\n```\n</code></pre> <p>Expected: HTTP/1.1 200 OK and an HTML or JSON payload representing the index/health page.</p>"},{"location":"capstone/11_lab09/#b-create-a-production-ready-dockerfile","title":"B. Create a production-ready Dockerfile","text":"<p>Create <code>Dockerfile</code> at repo root:</p> <pre><code># Dockerfile (production-ish)\nFROM python:3.11-slim\n\n# OS deps for some Python packages (if needed)\nRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \\\n    build-essential gcc libpq-dev \\\n &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Create app user\nRUN useradd --create-home appuser\nWORKDIR /app\n\n# Copy requirements first for Docker layer caching\nCOPY requirements.txt /app/requirements.txt\nRUN pip install --no-cache-dir -r /app/requirements.txt\n\n# Copy app source\nCOPY . /app\n\n# Ensure non-root\nUSER appuser\n\n# Expose port used by the app\nEXPOSE 5000\n\n# Default command: use gunicorn if app exposes 'app' WSGI callable.\n# Replace 'app:app' with '&lt;module&gt;:&lt;callable&gt;' if different.\nCMD [\"gunicorn\", \"--workers\", \"3\", \"--bind\", \"0.0.0.0:5000\", \"app:app\"]\n</code></pre>"},{"location":"capstone/11_lab09/#c-build-and-run-the-docker-image-locally","title":"C. Build and run the Docker image locally","text":"<ol> <li>Build:</li> </ol> <p><pre><code>docker build -t techops/flask-sample:lab09 .\n</code></pre> 2. Run:</p> <p><pre><code>docker run --rm -p 5000:5000 --name flask-lab09 techops/flask-sample:lab09\n</code></pre> 3. Validate:</p> <pre><code>curl -i http://127.0.0.1:5000/\n</code></pre> <p>Expected: HTTP 200 and page content. Also <code>docker ps</code> should show the running container.</p> <p>Here\u2019s the corrected and polished section with the fixed <code>cp -r</code> command and a ready-to-use <code>.dockerignore</code> template.</p>"},{"location":"capstone/11_lab09/#d-move-your-app-into-your-teams-repository","title":"D. Move Your App into Your Team\u2019s Repository","text":"<p>Delete <code>.git</code> foler</p> <p>Inside your cloned <code>flask-sample-webapp</code> folder, remove the <code>.git</code> history so it becomes a plain app folder:</p> <p><pre><code>rm -rf .git\n</code></pre> (On Windows, just delete the <code>.git</code> folder manually.)</p> <p>Create Temporary Directory and Clone your team's Repo</p> <p>Create a temporary directory somewhere outside of <code>flask-sample-webapp</code> (e.g., <code>~/temp_repo</code>). 1. From inside <code>temp_repo</code>, clone your team repository (replace <code>&lt;your-org&gt;</code> and <code>teamX</code> with your actual details):</p> <p><pre><code>git clone git@github.com:&lt;your-org&gt;/techops-capstone-teamX.git\n</code></pre> 2. Enter the cloned team repo folder:</p> <p><pre><code>cd techops-capstone-teamX\n</code></pre> 3. Remove any placeholder app folders if they exist:</p> <p><pre><code>rm -rf apps/frontend/\nrm -rf apps/backend/\n</code></pre> 4. Copy your Flask app into the <code>apps/</code> folder of your team repo:</p> WindowsLinux/macOS <p>Copy the entire <code>flask-sample-webapp</code> folder into your team repo.</p> <p>Example: If your Flask app is at <code>C:/Users/YourUserName/Documents/Code/flask-sample-webapp</code></p> <p>and your team repo is at <code>C:/Users/YourUserName/Documents/Capstone/techops-capstone-teamX</code></p> <p>\u2192 Copy <code>flask-sample-webapp</code> into: <code>C:/Users/YourUserName/Documents/Capstone/techops-capstone-teamX/apps/</code></p> <p>Use the <code>cp -r</code> command (note the -r to copy the folder and preserve structure):</p> <pre><code>cp -r /path/to/flask-sample-webapp /path/to/techops-capstone-teamX/apps/\n</code></pre> <p>After this step, your repo should look like:</p> <pre><code>techops-capstone-teamX/\n\u2514\u2500\u2500 apps/\n    \u2514\u2500\u2500 flask-sample-webapp/\n        \u251c\u2500\u2500 app.py\n        \u251c\u2500\u2500 requirements.txt\n        \u251c\u2500\u2500 Dockerfile\n        \u2514\u2500\u2500 ...\n</code></pre> <p>Create <code>.dockerignore</code> file:</p> <ol> <li>Inside <code>apps/flask-sample-webapp</code>, create a <code>.dockerignore</code> file to avoid copying unnecessary files into Docker images:</li> </ol> <pre><code>cat &gt; apps/flask-sample-webapp/.dockerignore &lt;&lt;EOF\n.venv\n__pycache__/\n*.pyc\n*.pyo\n*.pyd\n.git\n.gitignore\ntests/\nnode_modules/\n*.log\nEOF\n</code></pre> <p>Commit &amp; Push to yoru Team's Repo</p> <ol> <li>Stage, commit, and push the new app to your team repo:</li> </ol> <pre><code>git checkout -b feature/lab09-add-flask-app\ngit add apps/flask-sample-webapp\ngit commit -m \"Lab09: add flask-sample-webapp under apps/ with Dockerfile and .dockerignore\"\ngit push -u origin feature/lab09-add-flask-app\n</code></pre> <p>Merge the Pull Request</p> <p>On GitHub, open a Pull Request from your branch (<code>feature/lab09-add-flask-app</code>) into <code>main</code>. Approve &amp; Merge!</p>"},{"location":"capstone/11_lab09/#troubleshooting-tips-common-errors-fixes","title":"Troubleshooting Tips (common errors &amp; fixes)","text":"<ul> <li>Error: <code>requirements.txt</code> missing   Fix: Inspect <code>pyproject.toml</code> or <code>Pipfile</code>. If dependencies unknown, create minimal <code>requirements.txt</code> (e.g., <code>Flask</code>, <code>gunicorn</code>) and iterate:</li> </ul> <p><pre><code>Flask&gt;=2.0\ngunicorn\n</code></pre> * <code>FLASK_APP</code> not set / ModuleNotFoundError for app   Find the module with <code>app = Flask(__name__)</code> or a factory <code>create_app()</code>. Update <code>FLASK_APP</code> or <code>CMD</code> in Dockerfile accordingly. * Port 5000 already in use   Stop other service or map to another port: <code>docker run -p 8080:5000 ...</code> then test <code>http://localhost:8080</code>. * gunicorn import error: cannot import name 'app'   Either point gunicorn to correct WSGI callable (<code>module:callable</code>) or add a <code>wsgi.py</code> wrapper that exposes the <code>application</code>. * Build fails with missing dev headers (e.g., for psycopg2)   Add required OS packages in Dockerfile (e.g., <code>libpq-dev</code>) and rebuild. * Image too large   Use <code>python:3.11-slim</code>, remove apt caches (<code>rm -rf /var/lib/apt/lists/*</code>), and add <code>.dockerignore</code> (exclude <code>.venv</code>, <code>tests</code>, <code>.git</code>).</p>"},{"location":"capstone/11_lab09/#deliverables-what-to-commitpush-for-evaluation","title":"Deliverables (what to commit/push for evaluation)","text":"<ol> <li><code>Dockerfile</code> in repo root.</li> <li><code>tests/test_app.py</code> (or similar) with passing tests.</li> <li>README section: \u201cRun locally\u201d and \u201cRun with Docker\u201d with exact commands used.</li> <li>One screenshot or paste of <code>curl -i http://127.0.0.1:5000/</code> showing HTTP 200.</li> <li><code>docker images</code> output showing <code>techops/flask-sample:lab09</code> image ID and size.</li> <li>Commit sha / PR URL if you created a branch/PR.</li> </ol>"},{"location":"capstone/11_lab09/#reflection-question","title":"Reflection Question","text":"<p>What was the single change you had to make to the upstream repo (entrypoint, dependency, or config) to make the app run inside Docker \u2014 and why was that change necessary?</p>"},{"location":"capstone/12_lab10/","title":"Lab 10: Push Images to Docker Hub","text":"<p>Roles Responsible: Developers</p>"},{"location":"capstone/12_lab10/#objectives","title":"Objectives","text":"<ul> <li>Log in to your personal Docker Hub account.</li> <li>Tag and push the Flask app Docker image to your personal Docker Hub repo.</li> <li>Update <code>README.md</code> with pull/run instructions from Docker Hub.</li> <li>Commit the changes into the team GitHub repo via a feature branch and PR.</li> </ul>"},{"location":"capstone/12_lab10/#pre-requisites","title":"Pre-requisites","text":"<ol> <li>Docker Installed &amp; Running (already covered in Lab 09).</li> <li>Personal Docker Hub Account (sign up at hub.docker.com if you don\u2019t have one).</li> <li> <p>Lab 09 completed successfully:</p> </li> <li> <p><code>apps/flask-sample-webapp/Dockerfile</code> present.</p> </li> <li>Local image built (e.g., <code>techops/flask-sample:lab09</code>).</li> </ol>"},{"location":"capstone/12_lab10/#theory-recap","title":"Theory Recap","text":"<p>Docker Hub lets individual developers store and distribute container images. By pushing your local build, you ensure the image can be pulled anywhere (including Jenkins or EC2 in future labs). Each developer will use their personal Docker Hub username as the namespace.</p>"},{"location":"capstone/12_lab10/#step-by-step-instructions","title":"Step-by-Step Instructions","text":""},{"location":"capstone/12_lab10/#a-create-docker-hub-repository","title":"A. Create Docker Hub Repository","text":"<ol> <li>Log into Docker Hub.</li> <li>In your local terminal run <code>docker login</code></li> <li> <p>Go to Repositories \u2192 Create Repository.</p> </li> <li> <p>Name: <code>flask-sample-webapp</code></p> </li> <li>Visibility: Public (preferred for this lab).</li> <li>Namespace: Your Docker Hub username (e.g., <code>your-username/flask-sample-webapp</code>).</li> </ol>"},{"location":"capstone/12_lab10/#b-tag-the-local-image","title":"B. Tag the Local Image","text":"<p>Check your local image:</p> <pre><code>docker images | grep flask-sample\n</code></pre> <p>Re-tag it with your personal Docker Hub username:</p> <pre><code>docker tag techops/flask-sample:lab09 &lt;your-dockerhub-username&gt;/flask-sample-webapp:lab10\ndocker tag techops/flask-sample:lab09 &lt;your-dockerhub-username&gt;/flask-sample-webapp:latest\n</code></pre>"},{"location":"capstone/12_lab10/#c-push-to-docker-hub","title":"C. Push to Docker Hub","text":"<pre><code>docker push &lt;your-dockerhub-username&gt;/flask-sample-webapp:lab10\ndocker push &lt;your-dockerhub-username&gt;/flask-sample-webapp:latest\n</code></pre> <p>Check on Docker Hub that both tags appear under your repo.</p>"},{"location":"capstone/12_lab10/#d-test-pull-run-from-docker-hub","title":"D. Test Pull &amp; Run from Docker Hub","text":"<p>From any machine with Docker:</p> <pre><code>docker pull &lt;your-dockerhub-username&gt;/flask-sample-webapp:lab10\ndocker run --rm -p 5000:5000 &lt;your-dockerhub-username&gt;/flask-sample-webapp:lab10\n</code></pre> <p>Validate with:</p> <pre><code>curl -i http://127.0.0.1:5000/\n</code></pre>"},{"location":"capstone/12_lab10/#e-update-readmemd-in-team-repo","title":"E. Update README.md in Team Repo","text":"<p>In <code>apps/flask-sample-webapp/README.md</code>, add:</p> <pre><code>## Run from Docker Hub\n\nTo pull and run the app directly from Docker Hub:\n\n\n```bash\ndocker pull &lt;your-dockerhub-username&gt;/flask-sample-webapp:latest\ndocker run --rm -p 5000:5000 &lt;your-dockerhub-username&gt;/flask-sample-webapp:latest\n```\n</code></pre>"},{"location":"capstone/12_lab10/#f-commit-push-changes-to-team-repo","title":"F. Commit &amp; Push Changes to Team Repo","text":"<p>From inside your team repo (<code>techops-capstone-teamX</code>):  </p> <pre><code>git checkout -b feature/lab10-dockerhub\ngit add .\ngit commit -m \"Lab10: update README with Docker Hub image info\"\ngit push -u origin feature/lab10-dockerhub\n</code></pre> <p>Create a Pull Request \u2192 get it reviewed \u2192 merge into <code>main</code>.</p>"},{"location":"capstone/12_lab10/#checkpoint-validation","title":"Checkpoint / Validation","text":"<ul> <li>Personal Docker Hub repo exists (<code>your-username/flask-sample-webapp</code>).</li> <li>Image pushed with tags <code>lab10</code> and <code>latest</code>.</li> <li><code>docker pull</code> and <code>docker run</code> work on another machine.</li> <li>README updated in team repo with Docker Hub instructions.</li> <li>PR merged successfully.</li> </ul>"},{"location":"capstone/12_lab10/#troubleshooting-tips","title":"Troubleshooting Tips","text":"<ul> <li><code>denied: requested access to the resource is denied</code>     \u2192 Run <code>docker login</code> and make sure you use your personal username.</li> <li><code>manifest unknown</code>     \u2192 Tag mismatch. Double-check with <code>docker images</code>.</li> <li>Push to wrong namespace   \u2192 Always tag with your Docker Hub username (<code>docker tag ... your-username/...</code>).</li> </ul>"},{"location":"capstone/12_lab10/#deliverables","title":"Deliverables","text":"<ol> <li>Screenshot of <code>docker push</code> output.</li> <li>Screenshot of successful <code>docker run</code> from Docker Hub image.</li> <li>Updated <code>README.md</code> in team repo.</li> <li>PR link merged into <code>main</code>.</li> </ol>"},{"location":"capstone/12_lab10/#reflection-question","title":"Reflection Question","text":"<p>If every developer pushes to their own personal Docker Hub repo, what challenges could arise when DevOps later automates deployment using Jenkins?</p>"},{"location":"capstone/13_lab11/","title":"Lab 11: Jenkins Pipeline Setup (CI) \u2014 Full Guide","text":"<p>Role(s) Responsible: DevOps (with help from Developers for creating the <code>Jenkinsfile</code>)</p>"},{"location":"capstone/13_lab11/#objectives","title":"Objectives","text":"<ul> <li>Add a <code>Jenkinsfile</code> to the team repo (created by Developers / DevOps).</li> <li>Configure Jenkins to run a pipeline that: checks out code, runs tests, builds Docker image and pushes to the developer\u2019s Docker Hub repo using credentials from Lab 08.</li> <li>Ensure pipeline: runs only on <code>main</code> and only when <code>apps/flask-sample-webapp/**</code> files changed.</li> <li>Configure GitHub webhook so pushes/PR merges trigger Jenkins builds (no polling).</li> </ul>"},{"location":"capstone/13_lab11/#pre-requisites-exact-checklist-commands","title":"Pre-requisites (exact checklist &amp; commands)","text":"<ol> <li>Jenkins server provisioned and reachable (from Lab 06/07).</li> <li>Jenkins host has Docker available and Jenkins user can run Docker:</li> </ol> <p><pre><code># on Jenkins host\ndocker --version\nsudo usermod -aG docker jenkins   # if permission issues; then restart jenkins\nsudo systemctl restart jenkins\n</code></pre> 3. Plugins installed on Jenkins:</p> <ul> <li>GitHub Branch Source (for multibranch pipelines/webhooks)</li> <li>Pipeline (workflow-aggregator)</li> <li>Credentials Plugin</li> <li>Docker Pipeline (optional/helpful)</li> <li> <p>Docker Hub credential already present from Lab 08 \u2014 note the Credential ID (e.g., <code>dockerhub-token</code> or <code>dockerhub-credentials</code>). You will use this ID in the Jenkinsfile.</p> </li> <li> <p>To find it: Jenkins \u2192 Credentials \u2192 System \u2192 Global credentials (unrestricted) \u2192 note the ID column.</p> </li> <li>Team GitHub repo cloned locally (or access to edit). We will place the <code>Jenkinsfile</code> in the repo before configuring Jenkins. Recommended location: at <code>apps/flask-sample-webapp/Jenkinsfile</code> (makes multibranch scanning straightforward).</li> </ul> <p><pre><code>git clone git@github.com:&lt;your-org-or-team-repo&gt;.git\ncd &lt;repo&gt;\n</code></pre> 6. Developers have pushed the Dockerized app (Lab 09) and updated <code>apps/flask-sample-webapp</code> with <code>Dockerfile</code>, tests, etc.</p>"},{"location":"capstone/13_lab11/#jenkinsfile-what-to-add-to-the-repo","title":"Jenkinsfile \u2014 what to add to the repo","text":"<p>Important: Devs / DevOps must create and commit a <code>Jenkinsfile</code> into the repo before creating the Jenkins job. Place it at <code>apps/flask-sample-webapp/Jenkinsfile</code> or root and point the job to that path.</p> <p>Below is a robust Declarative Jenkinsfile that:</p> <ul> <li>checks branch is <code>main</code>,</li> <li>inspects the commit changeSets and runs only if something under <code>apps/flask-sample-webapp/</code> changed,</li> <li>runs tests, builds the Docker image and pushes to Docker Hub using the credential created in Lab 08.</li> </ul> <p>Replace <code>YOUR_DOCKERHUB_CRED_ID</code> and your <code>your_dockerhub_username</code> with the actual credential ID created in Lab 08 and username on which the image is pushed at DockerHub.</p> <pre><code>// apps/flask-sample-webapp/Jenkinsfile\npipeline {\n  agent any\n\n  parameters {\n    // Set this to the credential ID you created in Lab 08 (or let DevOps set it via Job defaults)\n    string(name: 'DOCKERHUB_CRED_ID', defaultValue: 'YOUR_DOCKERHUB_CRED_ID', description: 'Jenkins credential ID for Docker Hub (username+token)')\n    string(name: 'DOCKERHUB_USER', defaultValue: 'your_dockerhub_username', description: 'Docker Hub username/namespace (developer should set their username)')\n    string(name: 'IMAGE_NAME', defaultValue: 'flask-sample-webapp', description: 'Image name')\n    string(name: 'IMAGE_TAG', defaultValue: \"lab11-${env.BUILD_ID}\", description: 'Image tag (auto default)')\n  }\n\n  environment {\n    APP_PATH = \"apps/flask-sample-webapp\"\n    IMAGE = \"${params.DOCKERHUB_USER}/${params.IMAGE_NAME}:${params.IMAGE_TAG}\"\n    IMAGE_LATEST = \"${params.DOCKERHUB_USER}/${params.IMAGE_NAME}:latest\"\n  }\n\n  stages {\n    stage('Should we run?') {\n      steps {\n        script {\n          // Fail fast if not on main branch\n          if (!env.BRANCH_NAME) {\n            // For single pipeline jobs, BRANCH_NAME may not be set; try GIT_BRANCH\n            env.BRANCH_NAME = env.GIT_BRANCH ?: env.BRANCH_NAME\n          }\n          if (env.BRANCH_NAME == null) {\n            echo \"BRANCH_NAME not set \u2014 continuing (job may be configured as single-branch pipeline).\"\n          } else {\n            echo \"Branch: ${env.BRANCH_NAME}\"\n            if (env.BRANCH_NAME != 'main') {\n              echo \"Not main branch (${env.BRANCH_NAME}) \u2014 skipping remaining stages.\"\n              currentBuild.result = 'NOT_BUILT'\n              error(\"Stopping pipeline: not main branch\")\n            }\n          }\n\n          // Determine whether files under APP_PATH changed in this build.\n          boolean pathChanged = false\n          for (changeSet in currentBuild.changeSets) {\n            for (entry in changeSet.items) {\n              for (file in entry.affectedFiles) {\n                if (file.path.startsWith(\"${APP_PATH}/\")) {\n                  pathChanged = true\n                  break\n                }\n              }\n              if (pathChanged) break\n            }\n            if (pathChanged) break\n          }\n          if (!pathChanged) {\n            echo \"No changes under ${APP_PATH} detected in this build. Exiting.\"\n            currentBuild.result = 'NOT_BUILT'\n            error(\"No relevant changes\")\n          } else {\n            echo \"Changes detected under ${APP_PATH} \u2014 continuing pipeline.\"\n          }\n        }\n      }\n    }\n\n    stage('Checkout') {\n      steps {\n        // Checkout the commit that triggered the build\n        checkout scm\n      }\n    }\n\n    stage('Unit Tests') {\n      steps {\n        dir(\"${APP_PATH}\") {\n          sh '''\n            set -e\n            python3 -m venv .venv || true\n            . .venv/bin/activate\n            pip install --upgrade pip\n            pip install -r requirements.txt || true\n            pytest -q || true\n          '''\n        }\n      }\n      // Do not fail the whole build on flaky tests by default; you can alter to fail\n      post {\n        unsuccessful { echo \"Unit tests stage reported issues (see logs).\" }\n      }\n    }\n\n    stage('Build Docker Image') {\n      steps {\n        dir(\"${APP_PATH}\") {\n          sh '''\n            docker build -t \"${IMAGE}\" .\n          '''\n        }\n      }\n    }\n\n    stage('Docker Login &amp; Push') {\n      steps {\n        // Use credential added in Lab 08. DevOps/Students must replace DOCKERHUB_CRED_ID or set it in job parameters\n        withCredentials([usernamePassword(credentialsId: params.DOCKERHUB_CRED_ID, usernameVariable: 'DOCKER_USER', passwordVariable: 'DOCKER_PASS')]) {\n          sh '''\n            echo \"$DOCKER_PASS\" | docker login --username \"$DOCKER_USER\" --password-stdin\n            docker tag \"${IMAGE}\" \"${IMAGE_LATEST}\" || true\n            docker push \"${IMAGE}\"\n            docker push \"${IMAGE_LATEST}\"\n            docker logout\n          '''\n        }\n      }\n    }\n\n    stage('Cleanup') {\n      steps {\n        sh 'docker image prune -f || true'\n      }\n    }\n  } // stages\n\n  post {\n    success {\n      echo \"Pipeline completed successfully. Image pushed: ${IMAGE}\"\n    }\n    failure {\n      echo \"Pipeline failed. Check console output for errors.\"\n    }\n    always {\n      // optional: collect junit/test reports if produced\n      echo \"Build finished: ${currentBuild.currentResult}\"\n    }\n  }\n}\n</code></pre>"},{"location":"capstone/13_lab11/#steps-create-commit-jenkinsfile-studentdevops","title":"Steps: create / commit Jenkinsfile (student/devops)","text":"<ol> <li>Create the <code>Jenkinsfile</code> locally (path recommended: <code>apps/flask-sample-webapp/Jenkinsfile</code>) and paste the content above (update default parameters).    Example:</li> </ol> <pre><code>cd /path/to/your/local/repo\nmkdir -p apps/flask-sample-webapp\ncat &gt; apps/flask-sample-webapp/Jenkinsfile &lt;&lt;'JENK'\n&lt;paste Jenkinsfile content here&gt;\nJENK\n</code></pre> <ol> <li> <p>Update placeholders:</p> </li> <li> <p>Replace <code>YOUR_DOCKERHUB_CRED_ID</code> with the Jenkins credential ID created in Lab 08 (or leave as-is if job will set parameter defaults).</p> </li> <li> <p>Set <code>DOCKERHUB_USER</code> to your Docker Hub username (or leave as parameter to set at job-level).</p> </li> <li> <p>Commit &amp; push:</p> </li> </ol> <pre><code>git checkout -b feature/add-jenkinsfile\ngit add apps/flask-sample-webapp/Jenkinsfile\ngit commit -m \"Lab11: add Jenkinsfile for CI (build &amp; push Docker image)\"\ngit push -u origin feature/add-jenkinsfile\n# Create a PR and merge into main (since pipeline only runs on main)\n</code></pre> <p>Important: merge the PR into <code>main</code> so Jenkins multibranch or webhook-triggered job can see the <code>Jenkinsfile</code> on <code>main</code>.</p>"},{"location":"capstone/13_lab11/#configure-jenkins-job-devops","title":"Configure Jenkins Job (DevOps)","text":"<ol> <li>Jenkins \u2192 New Item \u2192 give a name (e.g., <code>techops-flask-multibranch</code>) \u2192 Multibranch Pipeline \u2192 OK.</li> <li> <p>Under Branch Sources \u2192 Add \u2192 Git (or GitHub if plugin installed).</p> </li> <li> <p>Repository: <code>git@github.com:&lt;org-or-team&gt;/&lt;repo&gt;.git</code> (or HTTPS)</p> </li> <li>Add credentials if necessary for Jenkins to read the repo.</li> <li>Under Build Configuration set Script Path to:</li> </ol> <pre><code>apps/flask-sample-webapp/Jenkinsfile\n</code></pre> <p>(This makes multibranch create jobs for branches that have that Jenkinsfile in that path.) 4. Save.</p> <p>We will not rely on interval scanning \u2014 webhooks will trigger indexing/builds (see webhook steps below).</p>"},{"location":"capstone/13_lab11/#setup-github-webhook-no-polling","title":"Setup GitHub Webhook (no polling)","text":"<ol> <li>In GitHub: go to the team repo \u2192 Settings \u2192 Webhooks \u2192 Add webhook.</li> <li>Payload URL:</li> </ol> <pre><code>https://&lt;your-jenkins-public-url&gt;/github-webhook/\n</code></pre> <p>(If Jenkins is behind auth or firewall, ensure GitHub can reach it \u2014 you may need to use a public IP / DNS or a tunneling service during lab.) 3. Content type: <code>application/json</code> 4. Secret: optional (if you configure secret on Jenkins side; can be left empty for classroom). 5. Which events would you like to trigger this webhook? \u2192 Choose Let me select individual events \u2192 check Push and Pull request. 6. Add webhook. 7. In Jenkins, ensure GitHub plugin/webhook handling is enabled: Manage Jenkins \u2192 Configure Global Security / or check GitHub webhook logs.</p> <p>Test: Merge the PR with <code>Jenkinsfile</code> into <code>main</code> (or push a change to <code>main</code> under <code>apps/flask-sample-webapp/</code>) \u2014 GitHub webhook should POST to Jenkins and Jenkins should trigger a build. Verify webhook delivery status in GitHub UI (should show 200 response).</p>"},{"location":"capstone/13_lab11/#checkpoint-validation-what-students-should-provide","title":"Checkpoint / Validation (what students should provide)","text":"<ol> <li>Jenkinsfile exists and was merged into <code>main</code> at <code>apps/flask-sample-webapp/Jenkinsfile</code>. (PR link + commit sha)</li> <li>Jenkins job created (multibranch/pipeline) and configured <code>Script Path</code> as <code>apps/flask-sample-webapp/Jenkinsfile</code>. (screenshot)</li> <li>Jenkins Credentials (from Lab 08) are visible and you used that credential ID in the job or Jenkinsfile. (screenshot of credentials list showing the credential ID)</li> <li>GitHub webhook created and shows successful recent deliveries (screenshot).</li> <li>A merge/commit to <code>main</code> that changed files under <code>apps/flask-sample-webapp/</code> has triggered Jenkins and resulted in console logs showing: checkout \u2192 tests \u2192 docker build \u2192 docker push (copy of log lines showing <code>docker push</code>).</li> <li>Docker Hub shows the pushed tag (screenshot of your Docker Hub repo with <code>lab11-&lt;buildId&gt;</code> and <code>latest</code>).</li> </ol>"},{"location":"capstone/13_lab11/#troubleshooting-common-errors-fixes","title":"Troubleshooting (common errors &amp; fixes)","text":"<ul> <li> <p>Webhook not triggering / 404 / 403 responses</p> </li> <li> <p>Ensure Jenkins is reachable from the public internet (GitHub must reach it). If Jenkins is internal, use a public tunneling service (e.g., ngrok) for the lab or configure GitHub App. Check firewall/security group on Jenkins host.</p> </li> <li>Verify webhook payload URL ends with <code>/github-webhook/</code>.</li> <li> <p>Check GitHub webhook delivery logs for response codes.</p> </li> <li> <p><code>BRANCH_NAME</code> or <code>currentBuild.changeSets</code> empty</p> </li> <li> <p>For some job types (single pipeline) environment variables differ \u2014 the Jenkinsfile handles common variants but if changeSets are empty, the pipeline may not detect changes. In that case, as a fallback run tests/build only when you cannot inspect changeSets (or set up job to run on PR merges only). Multibranch pipeline tends to populate these.</p> </li> <li> <p><code>denied: requested access to the resource is denied</code> (docker push)</p> </li> <li> <p>Ensure Jenkins Credential corresponds to the Docker namespace you are pushing to (i.e., the credential username must match <code>DOCKERHUB_USER</code> in the Jenkinsfile). Use tokens not passwords when possible. Confirm the credential ID in the Jenkinsfile matches the one created in Lab 08.</p> </li> <li> <p>Permissions to run Docker on Jenkins host</p> </li> <li> <p><code>sudo usermod -aG docker jenkins</code> and restart Jenkins. Ensure the Jenkins process is restarted and has group membership.</p> </li> <li> <p>Tests failing in Jenkins but pass locally</p> </li> <li> <p>Ensure Jenkins workspace uses same Python version and installs dependencies. Cache discrepancies or network issues can cause failure. Collect logs, run same commands locally in a clean venv to reproduce.</p> </li> </ul>"},{"location":"capstone/13_lab11/#deliverables-what-to-submit-for-evaluation","title":"Deliverables (what to submit for evaluation)","text":"<ol> <li>PR link for <code>Jenkinsfile</code> merged to <code>main</code>.</li> <li>Screenshots: Jenkins job config (script path), Jenkins credentials list (showing credential ID), GitHub webhook config (showing successful deliveries).</li> <li>Console log excerpt showing <code>docker build</code> and <code>docker push</code>.</li> <li>Docker Hub screenshot showing pushed image tag.</li> <li>Short explanation (1\u20132 lines) of how you verified the pipeline only ran for <code>main</code> and only when <code>apps/flask-sample-webapp/</code> changed.</li> </ol> <p>Rubric:</p> <ul> <li>Jenkinsfile present &amp; merged before job creation (20%)</li> <li>Webhook configured and triggering builds (25%)</li> <li>Build runs tests and pushes image using Lab08 credentials (40%)</li> <li>Pipeline only runs for main + path filter logic works (15%)</li> </ul>"},{"location":"capstone/13_lab11/#reflection-question","title":"Reflection Question","text":"<p>Explain how the <code>changeSets</code> check in the Jenkinsfile prevents unnecessary CI usage and why this matters in shared monorepos.</p>"},{"location":"capstone/13_lab11/#quick-tips-for-instructors-devops","title":"Quick tips for instructors / DevOps","text":"<ul> <li>Teach students to merge the <code>Jenkinsfile</code> to <code>main</code> first; otherwise multibranch jobs might not discover the script.</li> <li>If some students\u2019 Docker Hub usernames differ from the credential username, make sure <code>DOCKERHUB_USER</code> parameter is set to match the credential username (or DevOps creates a per-developer credential with a matching username).</li> <li>Encourage use of Docker Hub tokens and to rotate them frequently; store tokens in Jenkins credentials (username = docker username, password = token).</li> </ul> <p>If you want, I can now:</p> <ul> <li>Produce a short shell script developers can use to create and push the <code>Jenkinsfile</code> (automates the <code>git</code> steps), or</li> <li>Produce a one-page student checklist (PDF/markdown) summarizing exactly what screenshots/links they must submit for grading.</li> </ul> <p>Which of those should I produce next?</p>"},{"location":"phase-0/01_overview/","title":"Session 0 \u2014 Agile Foundations &amp; Tool Setup (Slack + Jira + GitHub)","text":"<p>Format</p> <p>2h theory + 2h lab</p> <ul> <li>Team size: 10 (each team = a mini\u2011company inside TechOps Inc.)  </li> <li>Tools: Slack, Jira, GitHub</li> <li>Output: Working Slack workspace + Jira project + Sprint\u20111 plan</li> </ul>"},{"location":"phase-0/01_overview/#objectives","title":"Objectives","text":"<ul> <li>Explain Agile values &amp; principles, and the differences between Scrum and Kanban in the context of IT Infrastructure &amp; DevOps.</li> <li>Set up team collaboration tools: Slack (ChatOps) and Jira (Agile project management).</li> <li>Create a syllabus\u2011mapped backlog and plan Sprint 1</li> <li>Establish working agreements, roles, and a definition of done (DoD) for the team.</li> <li>Prepare a GitHub team repo structure that will be used throughout the course.</li> </ul>"},{"location":"phase-0/01_overview/#summary-agile-for-infra-devops","title":"Summary (Agile for Infra &amp; DevOps)","text":"<p>Agile emerged to counter rigid, plan\u2011heavy delivery models that struggled with uncertainty. In Dev and Ops contexts, Agile is less about speed for its own sake and more about short feedback loops, visibility, and continuous improvement. We\u2019ll use Agile to coordinate complex work across infrastructure, cloud, and DevOps pipelines.</p> <p>Agile values emphasize individuals &amp; interactions, working solutions, customer collaboration, and responsiveness to change. In our setting, \u201ccustomer\u201d = your stakeholders: internal teams, instructors, and demo audiences. Principles like frequent delivery, technical excellence, and sustainable pace map well to infrastructure work: small increments (e.g., baseline VM image), validated frequently (checkpoints), and continuously improved (automation).</p> <p>Scrum fits when you have a well\u2011defined increment and cadence: plan a sprint (2\u20133 weeks), hold a daily stand\u2011up (async in Slack), and aim for a potentially shippable increment (e.g., Infra Blueprint by Session 9). Roles are flexible here: a Project Lead plays Scrum Master\u2011like facilitation; the Instructor is close to Product Owner; the team is the cross\u2011functional developers (DevOps, Cloud, Security, Monitoring, Storage/Network).</p> <p>Kanban suits ongoing ops (tickets, incidents, enhancements). You\u2019ll use Kanban columns (To Do \u2192 In Progress \u2192 Review \u2192 Done) with WIP limits to prevent overload while doing labs and hardening.</p> <p>In DevOps culture, ChatOps (tooling + conversation) turns Slack into the central nervous system: GitHub PRs, Jenkins builds, monitoring alerts, and Jira updates surface in channels so decision\u2011making is transparent and fast. Jira anchors planning and tracking: epics for phases (Infra, Cloud, DevOps, CI/CD, Security/HA), stories for sessions, and tasks for lab steps. Your Definition of Done ensures quality (docs/screenshots/automation checked in, peer review done, Jira story moved to Done, Slack summary posted).</p> <p>Key benefits you\u2019ll feel immediately: - Visibility: everyone sees who\u2019s doing what, what\u2019s blocked, and what\u2019s next. - Traceability: each lab deliverable ties to a Jira story and a GitHub PR. - Incremental progress: you\u2019ll produce checkpoints that layer into the final demo.</p>"},{"location":"phase-0/01_overview/#practical-application-techops-inc-simulation","title":"Practical Application (TechOps Inc. Simulation)","text":"<p>Scenario: You\u2019ve just joined TechOps Inc. as a 10\u2011person platform team. You have two weeks to deliver the project Infra Blueprint. Today you will create your communication hub, project board, repo, and a working plan for Sprint\u20111.</p>"},{"location":"phase-0/01_overview/#lab-guide-2h","title":"Lab Guide (2h)","text":""},{"location":"phase-0/01_overview/#a-slack-workspace-chatops-25-min","title":"A. Slack Workspace (ChatOps) \u2014 25 min","text":"<ol> <li>Create or join the course Slack workspace.  </li> <li>Create channels:</li> <li><code>#announcements</code> (read\u2011only for instructors)</li> <li><code>#helpdesk</code> (Q&amp;A with instructors)</li> <li><code>#team-&lt;company-name&gt;</code> (private team channel)</li> <li>Optional cross\u2011team: <code>#devops</code>, <code>#cloud</code>, <code>#storage</code>, <code>#monitoring</code></li> <li>Add integrations (you can wire these fully in later sessions):</li> <li>GitHub: repo notifications to <code>#team-&lt;company-name&gt;</code></li> <li>Jira: story updates \u2192 <code>#team-&lt;company-name&gt;</code></li> <li>Pin a Team Charter (copy, edit, and post):</li> <li>Team name, members &amp; roles (Cloud Architect, SysAdmin, DevOps x2, Developers x2, Security, Monitoring, Storage/Network, Project Lead)</li> <li>Working hours, response times</li> <li>Stand\u2011up time (async template: Yesterday / Today / Blockers)</li> <li>Definition of Done (see template below)</li> </ol> <p>DoD template (pin this): - Code/config committed with README and comments - Steps reproducible; credentials redacted; screenshots added - PR raised &amp; reviewed by \u22651 peer - Jira story moved to Done with link to PR and short summary - Slack update posted (<code>#team-...</code>): what changed, who reviews, where to test</p>"},{"location":"phase-0/01_overview/#b-jira-project-35-min","title":"B. Jira Project \u2014 35 min","text":"<ol> <li>Create a Jira project: TechOps Inc. \u2013 Company  <li>Create Epics (map to course phases):</li> <li>Infra Foundations (S6\u2013S9)</li> <li>Virtualization &amp; Cloud (S10\u2013S13)</li> <li>DevOps Foundations (S14\u2013S17)</li> <li>CI/CD &amp; Monitoring (S18\u2013S20)</li> <li>Security &amp; HA (S21\u2013S23)</li> <li>Create User Stories for Sprint\u20111 (Sessions 6\u20139). Suggested set:</li> <li>S6: Baseline VM image (Linux/Windows), snapshot strategy</li> <li>S7: Data center layout &amp; constraints doc</li> <li>S8: NAS (TrueNAS CORE) for team file sharing</li> <li>S9: SAN (iSCSI) for VM cluster</li> <li>Break stories into Tasks (examples):</li> <li>Download Ubuntu LTS ISO; create VM (2 vCPU/4GB/40GB)</li> <li>Install base packages + updates; create <code>baseline-v1</code> snapshot</li> <li>Deploy TrueNAS VM; configure share; test from team VM</li> <li>Configure iSCSI target; connect initiator; validate block storage</li> <li>Add Definition of Done at project level (and link to the Slack post).</li> <li>Set Sprint\u20111 dates (cover S6\u2013S9 timeline); assign story owners; estimate points.</li> <p>(Optional) CSV import: you can prepare a CSV of stories/tasks to import into Jira if you prefer. Keep a copy in <code>docs/assets/Jira-backlog/</code>.</p>"},{"location":"phase-0/01_overview/#c-github-team-repo-35-min","title":"C. GitHub Team Repo \u2014 35 min","text":"<ol> <li>Create a repo (private or internal): <code>techops-&lt;company-name&gt;</code>.</li> <li>Add this starter structure: <pre><code>\u251c\u2500\u2500 infra/\n\u2502 \u251c\u2500\u2500 vm-baseline/\n\u2502 \u251c\u2500\u2500 nas-truenas/\n\u2502 \u2514\u2500\u2500 san-iscsi/\n\u251c\u2500\u2500 cloud/\n\u251c\u2500\u2500 app/\n\u251c\u2500\u2500 cicd/\n\u251c\u2500\u2500 monitoring/\n\u251c\u2500\u2500 security/\n\u2514\u2500\u2500 docs/\n\u251c\u2500\u2500 lab-notes/\n\u2514\u2500\u2500 diagrams/\n</code></pre></li> <li>Add a root README.md with:</li> <li>Team roster &amp; roles</li> <li>How to clone &amp; run labs</li> <li>Links to Slack channel &amp; Jira board</li> <li>Create a <code>docs/lab-notes/session-06.md</code> file and add checklists for VM setup.</li> <li>Set up branch protection (require PR review by at least one teammate).</li> <li>Connect GitHub \u2192 Slack notifications to your team channel.</li> </ol>"},{"location":"phase-0/01_overview/#d-sprint-planning-25-min","title":"D. Sprint Planning \u2014 25 min","text":"<ol> <li>Capacity: note each member\u2019s realistic hours for the sprint.</li> <li>Prioritize stories for S6\u2013S9; split if too big (aim for 1\u20133 days per story).</li> <li>Assign owners; confirm acceptance criteria align with DoD.</li> <li>Add risk/assumption notes: ISO availability, network limits, hardware quotas.</li> <li>Post the Sprint plan summary in Slack and pin it.</li> </ol>"},{"location":"phase-0/01_overview/#checkpoints-end-of-session","title":"Checkpoints (end of session)","text":"<ul> <li> Slack workspace &amp; team channel ready; Team Charter pinned  </li> <li> Jira project created with Epics, Stories (S6\u2013S9), Tasks, Sprint\u20111 dates  </li> <li> GitHub repo created with agreed folder structure + initial README  </li> <li> Definition of Done documented and referenced in both Slack &amp; Jira  </li> <li> Sprint\u20111 plan posted in Slack (owner per story + acceptance criteria)</li> </ul>"},{"location":"phase-0/01_overview/#quick-quiz-knowledge-check","title":"Quick Quiz (knowledge check)","text":"Which Agile practice best ensures visibility of daily progress and blockers? <ul> <li> Daily stand\u2011ups (async in Slack)</li> <li> Quarterly release planning</li> <li> Post\u2011mortems only after failures</li> <li> Annual performance reviews</li> </ul> In this course, who is closest to the Product Owner role? <ul> <li> Instructor (defining outcomes &amp; acceptance)</li> <li> Security Engineer</li> <li> Project Lead</li> <li> Cloud Architect</li> </ul> What belongs in our Definition of Done (pick all that apply)? <ul> <li> Reproducible steps &amp; docs in repo</li> <li> PR reviewed by a teammate</li> <li> Jira story moved to Done with links</li> <li> Only a verbal confirmation in class</li> </ul>"},{"location":"phase-0/01_overview/#deliverables-to-be-graded","title":"Deliverables (to be graded)","text":"<ol> <li>Slack: Link to team channel + pinned Team Charter &amp; DoD  </li> <li>Jira: Project URL + screenshot of Sprint\u20111 board  </li> <li>GitHub: Repo URL + screenshot of repo structure  </li> <li>Sprint\u20111 plan: Short note in Slack with owners &amp; dates</li> </ol>"},{"location":"phase-0/01_overview/#referencesself-study-youtube-slides","title":"References/Self Study (YouTube / Slides)","text":"<p>You can drop these into this page later:</p>"},{"location":"phase-0/02_agile/","title":"Agile","text":""},{"location":"phase-0/02_agile/#so-what-is-agile","title":"So What is Agile?","text":""},{"location":"phase-0/02_agile/#agile_1","title":"Agile","text":"<p>Agile is a way of working that delivers value in small, useful slices, learning from feedback quickly, and adapting plans as we go. Instead of locking a big plan for months, Agile asks: \u201cWhat\u2019s the next most valuable thing we can deliver in the next short cycle?\u201d</p> <p>Core ideas - Deliver in small batches (1\u20132 week cycles). - Focus on customer/stakeholder value. - Gather fast feedback and adapt. - Encourage collaboration across teams. - Respond to change instead of resisting it.</p> <p>Everyday Example</p> <p>You\u2019re building a college fest website. - Week 1: deliver the schedule page. - Week 2: add speaker bios. - Week 3: add ticketing. After week 1, you learn most users are on mobile, so you adjust next week\u2019s plan to improve mobile experience. \u2192 That\u2019s Agile: deliver \u2192 learn \u2192 adjust.</p> <p></p>"},{"location":"phase-0/02_agile/#principles-of-agile-manifesto","title":"Principles of Agile Manifesto","text":"<p>12 Principles of Agile Manifesto</p> <ol> <li>The top priority is customer satisfaction</li> <li>Changing requirements are welcome</li> <li>Frequent delivery of software</li> <li>Cooperation of business people and developers on a daily basis</li> <li>Build projects around motivated people</li> <li>A face-to-face conversation is the best</li> <li>Progress is measured by working software</li> <li>Sustainable development pace</li> <li>Attention to technical excellence</li> <li>Simplicity</li> <li>Self-organizing teams</li> <li>Regular reflection and adaptation</li> </ol>"},{"location":"phase-0/03_agile-methodologies/","title":"Agile Methodologioes","text":""},{"location":"phase-0/03_agile-methodologies/#agile-methodologies-scrum-and-kanban","title":"Agile Methodologies: Scrum and Kanban","text":"<p>Agile is the philosophy. Scrum and Kanban are two popular ways to implement it.</p>"},{"location":"phase-0/03_agile-methodologies/#scrum-time-boxed-approach","title":"Scrum (time-boxed approach)","text":"<ul> <li> <p>Sprints: Short, fixed-length cycles (1\u20133 weeks).</p> </li> <li> <p>Roles: </p> <ul> <li>Product Owner (sets priorities)  </li> <li>Scrum Master (facilitates, removes blockers)  </li> <li>Development Team (does the work)</li> </ul> </li> <li> <p>Events: Sprint Planning, Daily Stand-ups, Sprint Review, Retrospective.</p> </li> <li>Artifacts: Product Backlog, Sprint Backlog, Increment.</li> </ul> <p>Scrum Example</p> <p>A team promises: \u201cIn 2 weeks, we\u2019ll deliver a baseline VM image.\u201d - They sync daily for 15 min. - At sprint end, they demo the VM and get feedback: \u201cplease add curl and htop.\u201d - Next sprint, they adjust accordingly.</p>"},{"location":"phase-0/03_agile-methodologies/#kanban-flow-based-approach","title":"Kanban (flow-based approach)","text":"<ul> <li>Visualize work on a board (To Do \u2192 In Progress \u2192 Done).</li> <li>Limit Work-In-Progress (WIP) to avoid multitasking chaos.</li> <li>Measure flow: cycle time (start to finish), throughput (items/week).</li> </ul> <p>Kanban Example</p> <p>An ops team gets requests: create users, patch servers, rotate keys.  </p> <ul> <li>They allow only 3 tasks max \u201cIn Progress\u201d.  </li> <li>When one finishes, they pull the next.   \u2192 Result: fewer half-done tasks, faster average completion.</li> </ul>"},{"location":"phase-0/03_agile-methodologies/#scrum-vs-kanban-at-a-glance","title":"Scrum vs Kanban (at a glance)","text":"Scrum Kanban Works in fixed sprints Works in continuous flow Team commits to a sprint goal Team pulls tasks as capacity frees Best for project-style work Best for ongoing ops/support"},{"location":"phase-0/04_lean/","title":"Lean in DevOps","text":""},{"location":"phase-0/04_lean/#lean","title":"Lean","text":"<p>Lean focuses on maximizing value while eliminating waste. Originating in Toyota\u2019s production system, it maps perfectly to IT and DevOps.</p> <p>Three enemies in Lean</p> <ul> <li>Muda (Waste): unnecessary work, delays, rework.</li> <li>Mura (Unevenness): workload peaks/valleys causing churn.</li> <li>Muri (Overburden): overloading people/systems.</li> </ul> <p>Five Lean Principles</p> <ol> <li>Specify value (from customer\u2019s viewpoint).  </li> <li>Map the value stream (all steps from request \u2192 delivery).  </li> <li>Create flow (remove bottlenecks and stops).  </li> <li>Establish pull (work only when demand exists).  </li> <li>Seek perfection (continuous improvement).</li> </ol> <p>Common wastes in IT/DevOps</p> <ul> <li>Waiting (e.g., PR sits 3 days unreviewed).  </li> <li>Rework (build breaks due to inconsistent environments).  </li> <li>Overprocessing (writing 30-page docs no one reads).  </li> <li>Overproduction (building features/scripts nobody uses).  </li> <li>Inventory/WIP (10 half-done tasks, nothing delivered).  </li> <li>Motion/context switching (jumping across 6 tools).  </li> <li>Unused talent (infra engineers excluded from design).</li> </ul>"},{"location":"phase-0/04_lean/#implementation-of-lean-devops-context","title":"Implementation of Lean (DevOps context)","text":"<ol> <li>Define value clearly (e.g., \u201ca secure, ready-to-use VM by Friday\u201d).</li> <li>Map the value stream (all steps request \u2192 running system).</li> <li>Measure baseline (lead time, cycle time, MTTR).</li> <li>Remove waste (standard templates, automation, smaller batches).</li> <li>Introduce pull (WIP limits, visualize queues).</li> <li>Make problems visible (dashboards, blocked items).</li> <li>Continuous improvement (small retrospectives after each delivery).</li> </ol> <p>Mini Case</p> <p>Goal: Deliver a sandbox VM in 48 hours. - Old: approval wait 2 days + manual provisioning \u2192 often rework. - Lean: pre-approved hardened template + self-service request. \u2192 Delivery in hours, fewer defects, happier devs.</p>"},{"location":"phase-0/04_lean/#lean-and-agile-in-devops","title":"Lean and Agile in DevOps","text":"<ul> <li>Agile = what to build next (short cycles, priorities).  </li> <li>Lean = how to deliver efficiently (cut waste, improve flow).  </li> <li>DevOps = culture + automation bridging Dev &amp; Ops.</li> </ul> <p>Practical intersections</p> <ul> <li>Agile sprints + Lean small batches \u2192 CI/CD pipelines.  </li> <li>Lean \u201creduce handoffs\u201d + Agile \u201ccross-functional teams\u201d \u2192 fewer silos.  </li> <li>Limit WIP + short sprints \u2192 steadier throughput.  </li> <li>Retrospectives (Agile) + Kaizen (Lean) \u2192 continuous improvement.</li> </ul> <p>DevOps practices showing Lean + Agile</p> <ul> <li>Small PRs + trunk-based development.  </li> <li>Automated testing &amp; deployments.  </li> <li>Infrastructure as Code (standardization).  </li> <li>Feature flags (safe incremental releases).  </li> <li>Observability (metrics, logs, traces \u2192 faster recovery).  </li> </ul> <p>Real-world Outcome</p> <p>A team moves from monthly deployments to twice a week by: - Using Agile sprints (1 feature/week). - Applying Lean (limit WIP, automate tests). Result: smaller, safer deployments, faster recovery, less stress.</p>"},{"location":"phase-0/04_lean/#key-takeaways","title":"Key Takeaways","text":"<ul> <li>Agile = deliver value in small increments, adapt quickly.  </li> <li>Scrum = structured sprints, Kanban = continuous flow.  </li> <li>Lean = maximize value, eliminate waste.  </li> <li>Lean + Agile = DevOps culture, powered by automation and feedback.  </li> </ul>"},{"location":"phase-0/knowledge-check/","title":"Phase 0 - Agile Mindset Knowledge Check","text":"<p>It's time to assess your understanding of the topics covered in Phase 0: Agile Mindset and ChatOps. Please follow the steps below to take the exam:</p> <ol> <li>Scan the provided QR code or visit the designated link to register for the exam (if you haven't already).</li> <li>Locate the exam titled \"Phase 0 - Checkpoint\".</li> <li>The exam will be unlocked by the instructor once all students are ready.</li> </ol> <p>QR Code for Exam System:</p> <p></p> <p>Link for Exam System:</p> <p>Exam System </p> <p>Ensure you are prepared to demonstrate your knowledge. Good luck!</p>"},{"location":"phase-0/lab00/","title":"Understanding Labs","text":""},{"location":"phase-0/lab00/#labs-intro","title":"Labs Intro","text":"<p>We will now go into your first lab of the course, but before we do, let's understand how will these labs work.</p> <p>See the Labs Intro to understand how we will work.</p>"},{"location":"phase-0/lab01/","title":"Lab 01 \u2014 ChatOps with Slack","text":"<p>Format</p> <p>Duration: 1 hours (guided lab) Objective: Get every student onboarded to Slack, organized into teams, and familiar with ChatOps basics. Tools: Slack (web or desktop app), MS Forms (for team registration). Pre-requisites: None. This is your first hands-on lab.</p>"},{"location":"phase-0/lab01/#objectives","title":"Objectives","text":"<p>By the end of this lab, you will: - Join the course Slack workspace. - Understand Slack\u2019s structure: workspaces, channels, and direct messages. - Work inside your team\u2019s private channel. - Explore public channels (<code>#announcements</code>, <code>#q-and-a</code>, etc.). - Practice 1-on-1 and group chats. - Learn how Slack will integrate with project tools (Jira, GitHub, Jenkins) in future labs.  </p>"},{"location":"phase-0/lab01/#step-1-register-your-team","title":"Step 1 \u2014 Register your team","text":"<ol> <li>Your instructor will share a Microsoft Forms link.  </li> <li> <p>Fill in:</p> <ul> <li>Full name  </li> <li>Email ID (use the same one you\u2019ll use for Slack)  </li> <li>Assigned team name (Company A, B, C\u2026 as given)  </li> </ul> </li> <li> <p>Submit the form and wait for confirmation.</p> </li> <li> <p>This ensures you are properly placed into your company team of 8\u201310 members.</p> </li> </ol>"},{"location":"phase-0/lab01/#step-2-install-or-open-slack","title":"Step 2 \u2014 Install or open Slack","text":"<ol> <li>Go to: https://slack.com/downloads </li> <li> <p>Choose:</p> <ul> <li>Desktop app (Windows/Mac/Linux) \u2192 recommended </li> <li>Mobile app (optional, good for notifications)  </li> <li>Web version (via browser, but limited offline features)  </li> <li>Install and open Slack.  </li> <li>Sign in using the invite link your instructor provides.  </li> </ul> </li> </ol> <p>Invite Link: https://join.slack.com/t/ditiss2025/shared_invite/zt-3f29pl275-qgUA67iSVLSHi9Q5o3BPZw</p> <p>QR Code: </p> <p></p>"},{"location":"phase-0/lab01/#step-3-join-the-workspace","title":"Step 3 \u2014 Join the workspace","text":"<ol> <li>Click the invite link \u2192 accept.  </li> <li>Enter your full name (first + last).  </li> <li>Upload a profile picture (optional but recommended for team recognition).  </li> <li>You are now inside the course Slack workspace.  </li> </ol>"},{"location":"phase-0/lab01/#step-4-explore-slack-interface","title":"Step 4 \u2014 Explore Slack interface","text":"<p>Take a few minutes to look around: - Left sidebar: Channels, DMs, Apps. - Top search bar: Search across messages, files, people. - Message box: Write messages, attach files, add emojis. - Threads: Reply in context to keep conversations organized.  </p>"},{"location":"phase-0/lab01/#step-5-join-your-team-channel","title":"Step 5 \u2014 Join your team channel","text":"<ol> <li>Your instructor will create a private team channel for each company (e.g., <code>#team-alpha</code>, <code>#team-beta</code>).  </li> <li>Navigate to the left sidebar \u2192 \u201cChannels\u201d \u2192 join your team\u2019s channel.  </li> <li>Post a short intro message:    <pre><code>Hi team, I\u2019m &lt;Your Name&gt;. Excited to start!\n</code></pre></li> <li>Pin a message with your team name, members list, and roles (assigned later).</li> </ol>"},{"location":"phase-0/lab01/#step-6-explore-public-channels","title":"Step 6 \u2014 Explore public channels","text":"<ul> <li><code>#announcements</code>: For course-wide updates (read-only).  </li> <li><code>#q-and-a</code>: Ask course-related questions.  </li> <li><code>#helpdesk</code>: Report issues during labs.  </li> <li><code>#general</code>: Open discussion, not specific to any team.  </li> </ul> <p>Post a short message in <code>#q-and-a</code> like: <pre><code>Test message: Hello everyone, I can post here!\n</code></pre></p>"},{"location":"phase-0/lab01/#step-7-practice-1-on-1-group-chat","title":"Step 7 \u2014 Practice 1-on-1 &amp; group chat","text":"<ol> <li>Click Direct Messages (DMs) in the left sidebar.  </li> <li>Start a DM with one teammate:  </li> <li>\u201cHi , testing 1-on-1 chat!\u201d   <li>Start a group DM with 2\u20133 teammates.  </li>"},{"location":"phase-0/lab01/#step-8-explore-slack-features","title":"Step 8 \u2014 Explore Slack features","text":"<ul> <li>Reactions: Add emoji to messages (\ud83d\udc4d, \u2705, \ud83d\ude80).  </li> <li>Threads: Reply inside a message thread to keep discussions neat.  </li> <li>Files: Upload a screenshot or a PDF into your team channel.  </li> <li>Search: Try searching for your own message with a keyword.  </li> <li>Pinning: Pin an important message in your team channel (like \u201cTeam Charter\u201d).  </li> </ul>"},{"location":"phase-0/lab01/#step-9-post-your-first-lab-update","title":"Step 9 \u2014 Post your first Lab update","text":"<p>In your team channel, post a short lab update using this format:</p> <pre><code>Lab 01 completed \u2705\n- Joined workspace\n- Introduced myself\n- Tested 1:1 chat\n- Posted in #q-and-a\n</code></pre> <p>This format will be used in every lab going forward (mini status update = part of DevOps culture).</p>"},{"location":"phase-0/lab01/#deliverables","title":"Deliverables","text":"<ul> <li>Successfully joined Slack workspace.  </li> <li>Posted intro in team channel.  </li> <li>Posted test message in #q-and-a.  </li> <li>Sent at least one DM to a teammate.  </li> <li>Posted first Lab 01 update in team channel.  </li> </ul>"},{"location":"phase-0/lab01/#key-takeaways","title":"\u2705 Key Takeaways","text":"<ul> <li>Slack = your company\u2019s communication hub.  </li> <li>Public channels for common info; private team channels for company work.  </li> <li>DMs for private conversations, but most discussions should stay in channels.  </li> <li>Every lab will end with a Slack lab update in your team channel.  </li> </ul> <p>\u2705 This lab sets up the ChatOps foundation \u2014 from here, all teamwork will flow through Slack.  </p>"},{"location":"phase-0/lab02/","title":"Lab 02 \u2014 Agile Project Management with Jira","text":"<p>Format</p> <p>Duration: 2 hours (guided lab) Objective: Onboard into Jira, explore Scrum vs Kanban boards, and create first tickets for upcoming labs. Tools: Jira Cloud (web app), Instructor\u2019s demo board. Pre-requisites: Slack workspace (Lab 01).</p>"},{"location":"phase-0/lab02/#objectives","title":"Objectives","text":"<p>By the end of this lab, you will: - Join your team\u2019s Jira project. - Understand Jira\u2019s structure: Epics, Stories, Sub-tasks. - Differentiate between Scrum boards and Kanban boards. - Explore the backlog and active sprint. - Create and move your own tickets.  </p>"},{"location":"phase-0/lab02/#step-1-instructor-demo-the-master-board","title":"Step 1 \u2014 Instructor Demo: The Master Board","text":"<p>Your instructor will show a Jira board for the entire course:</p> <ul> <li>Epic: DITISS Course August 2025 </li> <li> <p>Features (per phase): </p> <ul> <li>Phase 1: Infrastructure Foundations (S6\u2013S9)  </li> <li>Phase 2: Virtualization &amp; Cloud (S10\u2013S13)  </li> <li>Phase 3: DevOps Foundations (S14\u2013S17)  </li> <li>Phase 4: CI/CD &amp; Monitoring (S18\u2013S20)  </li> <li>Phase 5: Security &amp; HA (S21\u2013S23)  </li> </ul> </li> <li> <p>Stories: Individual lab items (e.g., Install Ubuntu VM, Configure SAN, Build Docker image).  </p> </li> </ul> <p>This shows how the course itself is a project, with sprints, backlog, and tracking.</p>"},{"location":"phase-0/lab02/#step-2-join-your-teams-jira-project","title":"Step 2 \u2014 Join Your Team\u2019s Jira Project","text":"<ol> <li>Check your email invite from Jira.  </li> <li>Click the link \u2192 accept invitation.  </li> <li>If prompted, create a Jira account (free, using your email ID).  </li> <li>Once inside, you\u2019ll see your team\u2019s project (e.g., Company Alpha Project).  </li> </ol>"},{"location":"phase-0/lab02/#step-3-explore-the-scrum-board","title":"Step 3 \u2014 Explore the Scrum Board","text":"<ol> <li>On the left menu, click \u201cActive Sprints\u201d.  </li> <li> <p>You\u2019ll see:</p> <ul> <li>Sprint name (e.g., Sprint 1: Sessions 6\u20139).  </li> <li>Sprint board with columns: To Do \u2192 In Progress \u2192 Done.  </li> <li>Cards (stories) representing tasks.  </li> </ul> </li> <li> <p>Click a card to open its details. Look for:  </p> <ul> <li>Summary (title)  </li> <li>Description (instructions)  </li> <li>Assignee (who\u2019s doing it)  </li> <li>Status (To Do, In Progress, Done)  </li> </ul> </li> </ol>"},{"location":"phase-0/lab02/#step-4-explore-the-kanban-board","title":"Step 4 \u2014 Explore the Kanban Board","text":"<ol> <li>On the left menu, click \u201cKanban Board\u201d (sometimes named \u201cBoard\u201d or \u201cWorkflow\u201d).  </li> <li>You\u2019ll see a continuous flow of tasks across columns: To Do \u2192 In Progress \u2192 Review \u2192 Done.  </li> <li>Unlike Scrum, Kanban has no fixed sprint; work flows continuously.  </li> </ol>"},{"location":"phase-0/lab02/#step-5-explore-the-backlog","title":"Step 5 \u2014 Explore the Backlog","text":"<ol> <li>Click Backlog in the left menu.  </li> <li> <p>You\u2019ll see:</p> <ul> <li>Epics (big themes).  </li> <li>Stories (lab tasks).  </li> <li>Sprint 1 already created by instructor.  </li> </ul> </li> <li> <p>Scroll through items in Sprint 1 backlog. These are the labs you\u2019ll do next.  </p> </li> </ol>"},{"location":"phase-0/lab02/#step-6-create-your-own-ticket","title":"Step 6 \u2014 Create Your Own Ticket","text":"<ol> <li>In the backlog, click \u201cCreate Issue\u201d.  </li> <li> <p>Fill in:</p> <ul> <li>Summary: \u201cInstall Ubuntu VM (my personal lab)\u201d  </li> <li>Description: Write steps briefly (download ISO, create VM, snapshot).  </li> <li>Issue Type: Story  </li> <li>Epic Link: Phase 1 \u2192 Infrastructure Foundations  </li> <li>Sprint: Sprint 1  </li> <li>Assignee: Yourself  </li> </ul> </li> <li> <p>Click Create. Your ticket now appears in Sprint 1.  </p> </li> </ol>"},{"location":"phase-0/lab02/#step-7-work-with-your-ticket","title":"Step 7 \u2014 Work with Your Ticket","text":"<ol> <li>Drag your ticket from To Do \u2192 In Progress (start work).  </li> <li>Once finished, drag it to Done.  </li> <li>Add a comment on the ticket: <pre><code>Lab 02 test completed \u2705\n</code></pre></li> <li>Add a reaction emoji on someone else\u2019s ticket for practice.  </li> </ol>"},{"location":"phase-0/lab02/#step-8-team-activity","title":"Step 8 \u2014 Team Activity","text":"<ul> <li>Each student creates 1\u20132 tickets under Sprint 1.  </li> <li>Team Lead (Scrum Master) ensures all tickets are distributed across members.  </li> <li> <p>Discuss as a team:  </p> <ul> <li>Which tasks feel like Scrum work (time-boxed, labs)?  </li> <li>Which feel like Kanban work (ongoing, support)?  </li> </ul> </li> </ul>"},{"location":"phase-0/lab02/#deliverables","title":"Deliverables","text":"<ul> <li>Successfully joined Jira project.  </li> <li>Viewed Scrum board, Kanban board, and backlog.  </li> <li>Created at least one ticket under Sprint 1.  </li> <li>Moved your ticket across columns (To Do \u2192 In Progress \u2192 Done).  </li> <li>Added a comment and interacted with another ticket.  </li> </ul>"},{"location":"phase-0/lab02/#reflection-write-in-lab-notebook","title":"Reflection (write in lab notebook)","text":"<p>Answer briefly: 1. What\u2019s the main difference between Scrum and Kanban boards? 2. Which Jira feature do you think will be most useful in managing your labs? 3. Was ticket creation and assignment straightforward?  </p>"},{"location":"phase-0/lab02/#key-takeaways","title":"\u2705 Key Takeaways","text":"<ul> <li>Jira = project management hub for your team.  </li> <li>Scrum board = sprint planning &amp; delivery.  </li> <li>Kanban board = continuous flow.  </li> <li>Tickets = represent lab tasks you\u2019ll work on.  </li> <li>Jira + Slack + GitHub = the core DevOps collaboration stack you\u2019ll use all semester.  </li> </ul>"},{"location":"phase-1/dc-arch/","title":"Architecture","text":""},{"location":"phase-1/dc-arch/#data-center-architecture-requirements-prerequisites","title":"Data Center Architecture, Requirements &amp; Prerequisites","text":""},{"location":"phase-1/dc-arch/#what-is-it","title":"What is it?","text":"<p>The blueprint and essential conditions required to establish a functional and reliable data center.</p>"},{"location":"phase-1/dc-arch/#theoretical-definition","title":"Theoretical Definition","text":"<p>Data center architecture defines the physical and logical layout of servers, storage, networking, power, cooling, and security systems that support business applications and services.</p>"},{"location":"phase-1/dc-arch/#why-is-it-important","title":"Why is it Important?","text":"<ul> <li>Provides structure for building and scaling.  </li> <li>Ensures availability, scalability, and security.  </li> <li>A poor design can cause bottlenecks, downtime, and inefficiency.</li> </ul>"},{"location":"phase-1/dc-arch/#how-is-it-planned","title":"How is it Planned?","text":"<ul> <li>Define IT needs (compute, storage, network).  </li> <li>Allocate supporting infra (power, cooling, space).  </li> <li>Plan redundancy (no single point of failure).  </li> <li>Consider modular growth.  </li> </ul>"},{"location":"phase-1/dc-arch/#how-can-it-impact-down-the-line","title":"How Can it Impact Down the Line?","text":"<ul> <li>Well-architected = efficient, scalable, secure. </li> <li>Poorly architected = outages, costly retrofits.</li> </ul>"},{"location":"phase-1/dc-arch/#real-world-example","title":"Real World Example","text":"<p>AWS data centers are built in Availability Zones. Each zone is independent but interconnected for redundancy. This architecture lets AWS guarantee high availability.</p>"},{"location":"phase-1/dc-budget/","title":"Budget","text":""},{"location":"phase-1/dc-budget/#budget-constraints","title":"Budget Constraints","text":""},{"location":"phase-1/dc-budget/#what-is-it","title":"What is it?","text":"<p>The financial limits for building and operating a data center.</p>"},{"location":"phase-1/dc-budget/#theoretical-definition","title":"Theoretical Definition","text":"<p>Capital expenditure (CAPEX) for construction and Operational expenditure (OPEX) for ongoing running costs.</p>"},{"location":"phase-1/dc-budget/#why-is-it-important","title":"Why is it Important?","text":"<ul> <li>Budget dictates design choices.  </li> <li>Poor budgeting leads to cut corners (security/power risks).  </li> </ul>"},{"location":"phase-1/dc-budget/#how-is-it-planned","title":"How is it Planned?","text":"<ul> <li>Estimate upfront build costs + yearly OPEX.  </li> <li>Balance on-prem, colocation, or cloud models.  </li> </ul>"},{"location":"phase-1/dc-budget/#impact-down-the-line","title":"Impact Down the Line","text":"<p>Overbudget = project fails. Underbudget = unreliable DC.</p>"},{"location":"phase-1/dc-budget/#real-world-example","title":"Real World Example","text":"<p>A hyperscale DC may cost &gt;$500M, while a mid-size enterprise DC ~ $5\u201310M.</p>"},{"location":"phase-1/dc-cooling/","title":"Cooling","text":""},{"location":"phase-1/dc-cooling/#required-cooling-hvac","title":"Required Cooling &amp; HVAC","text":""},{"location":"phase-1/dc-cooling/#what-is-it","title":"What is it?","text":"<p>The system that removes heat generated by IT equipment.</p>"},{"location":"phase-1/dc-cooling/#theoretical-definition","title":"Theoretical Definition","text":"<p>HVAC (Heating, Ventilation, Air Conditioning) systems maintain optimal temperature and humidity in data centers.</p>"},{"location":"phase-1/dc-cooling/#why-is-it-important","title":"Why is it Important?","text":"<ul> <li>Prevents overheating and hardware damage.  </li> <li>Stabilizes environment for performance.  </li> <li>Energy efficiency driver (cooling can consume ~40% of DC power).  </li> </ul>"},{"location":"phase-1/dc-cooling/#how-is-it-planned","title":"How is it Planned?","text":"<ul> <li>Hot aisle/cold aisle containment.  </li> <li>Raised floor airflow or overhead ducts.  </li> <li>Liquid cooling for dense racks.  </li> </ul>"},{"location":"phase-1/dc-cooling/#impact-down-the-line","title":"Impact Down the Line","text":"<p>Poor cooling = outages, hardware failures. Overcooling = wasted energy costs.</p>"},{"location":"phase-1/dc-cooling/#real-world-example","title":"Real World Example","text":"<p>Google pioneered liquid cooling for AI workloads (&gt;10 kW per rack) to manage extreme heat.</p>"},{"location":"phase-1/dc-design/","title":"Good Design","text":""},{"location":"phase-1/dc-design/#characteristics-of-an-outstanding-design","title":"Characteristics of an Outstanding Design","text":""},{"location":"phase-1/dc-design/#what-is-it","title":"What is it?","text":"<p>Features that distinguish a world-class DC.</p>"},{"location":"phase-1/dc-design/#theoretical-definition","title":"Theoretical Definition","text":"<p>Outstanding designs balance scalability, redundancy, efficiency, and sustainability.</p>"},{"location":"phase-1/dc-design/#why-is-it-important","title":"Why is it Important?","text":"<ul> <li>Reduces long-term OPEX.  </li> <li>Increases availability and customer trust.  </li> </ul>"},{"location":"phase-1/dc-design/#how-is-it-planned","title":"How is it Planned?","text":"<ul> <li>Modular growth (pods).  </li> <li>Redundant systems.  </li> <li>Energy-efficient cooling and renewable integration.  </li> </ul>"},{"location":"phase-1/dc-design/#impact-down-the-line","title":"Impact Down the Line","text":"<p>Poor design = retrofits. Great design = cost-effective for decades.</p>"},{"location":"phase-1/dc-design/#real-world-example","title":"Real World Example","text":"<p>Google\u2019s PUE (Power Usage Effectiveness) averages &lt;1.1 in many facilities, setting efficiency benchmarks.</p>"},{"location":"phase-1/dc-design/#guidelines-for-planning-a-data-center","title":"Guidelines for Planning a Data Center","text":""},{"location":"phase-1/dc-design/#what-is-it_1","title":"What is it?","text":"<p>Best practices to design and plan a DC.</p>"},{"location":"phase-1/dc-design/#theoretical-definition_1","title":"Theoretical Definition","text":"<p>Systematic methodology to ensure reliability and efficiency in DC design.</p>"},{"location":"phase-1/dc-design/#why-is-it-important_1","title":"Why is it Important?","text":"<ul> <li>Prevents costly errors.  </li> <li>Ensures compliance with standards.  </li> </ul>"},{"location":"phase-1/dc-design/#how-is-it-planned_1","title":"How is it Planned?","text":"<ul> <li>Define capacity.  </li> <li>Modular phases.  </li> <li>Redundancy built-in.  </li> <li>Disaster recovery drills.  </li> </ul>"},{"location":"phase-1/dc-design/#impact-down-the-line_1","title":"Impact Down the Line","text":"<p>Poor planning = frequent failures. Good planning = smooth scalability.</p>"},{"location":"phase-1/dc-design/#real-world-example_1","title":"Real World Example","text":"<p>Uptime Institute\u2019s Tier standards are global guidelines for DC design.</p>"},{"location":"phase-1/dc-design/#data-center-structures","title":"Data Center Structures","text":""},{"location":"phase-1/dc-design/#what-is-it_2","title":"What is it?","text":"<p>Different models and reliability tiers of data centers.</p>"},{"location":"phase-1/dc-design/#theoretical-definition_2","title":"Theoretical Definition","text":"<p>Tier-based classification (I\u2013IV) that defines redundancy and uptime.</p>"},{"location":"phase-1/dc-design/#why-is-it-important_2","title":"Why is it Important?","text":"<ul> <li>Defines customer expectations.  </li> <li>Higher tiers = higher cost + reliability.  </li> </ul>"},{"location":"phase-1/dc-design/#how-is-it-planned_2","title":"How is it Planned?","text":"<ul> <li>Match business needs to Tier level.  </li> <li>Build redundancy accordingly.  </li> </ul>"},{"location":"phase-1/dc-design/#impact-down-the-line_2","title":"Impact Down the Line","text":"<p>Choosing too low = downtime risk. Too high = unnecessary costs.</p>"},{"location":"phase-1/dc-design/#real-world-example_2","title":"Real World Example","text":"<p>Tier IV DCs guarantee 99.995% uptime with full fault tolerance.</p>"},{"location":"phase-1/dc-design/#raised-floor-design-deployment","title":"Raised Floor Design &amp; Deployment","text":""},{"location":"phase-1/dc-design/#what-is-it_3","title":"What is it?","text":"<p>A flooring method where tiles are elevated for airflow and cabling.</p>"},{"location":"phase-1/dc-design/#theoretical-definition_3","title":"Theoretical Definition","text":"<p>Raised floors (12\u201324 inches high) allow underfloor cabling and cooling air distribution.</p>"},{"location":"phase-1/dc-design/#why-is-it-important_3","title":"Why is it Important?","text":"<ul> <li>Simplifies cabling.  </li> <li>Improves cooling efficiency.  </li> </ul>"},{"location":"phase-1/dc-design/#how-is-it-planned_3","title":"How is it Planned?","text":"<ul> <li>Install floor grid with tiles.  </li> <li>Plan hot/cold aisle layout.  </li> </ul>"},{"location":"phase-1/dc-design/#impact-down-the-line_3","title":"Impact Down the Line","text":"<p>Old trend but still useful for small DCs. Hyperscale DCs use overhead cabling.</p>"},{"location":"phase-1/dc-design/#real-world-example_3","title":"Real World Example","text":"<p>Legacy enterprise DCs used raised floors, but hyperscalers (AWS, Google) moved to overhead containment.</p>"},{"location":"phase-1/dc-design/#design-plan-against-vandalism","title":"Design &amp; Plan Against Vandalism","text":""},{"location":"phase-1/dc-design/#what-is-it_4","title":"What is it?","text":"<p>Physical protection against human threats.</p>"},{"location":"phase-1/dc-design/#theoretical-definition_4","title":"Theoretical Definition","text":"<p>Measures to prevent unauthorized physical access or damage.</p>"},{"location":"phase-1/dc-design/#why-is-it-important_4","title":"Why is it Important?","text":"<ul> <li>Data theft or sabotage = reputational &amp; financial damage.  </li> </ul>"},{"location":"phase-1/dc-design/#how-is-it-planned_4","title":"How is it Planned?","text":"<ul> <li>Multi-layered security: fences, guards, biometrics.  </li> <li>Mantraps, CCTV.  </li> </ul>"},{"location":"phase-1/dc-design/#impact-down-the-line_4","title":"Impact Down the Line","text":"<p>Weak security = insider threats, breaches.</p>"},{"location":"phase-1/dc-design/#real-world-example_4","title":"Real World Example","text":"<p>Financial DCs implement mantraps \u2014 double-door systems allowing only one person at a time.</p>"},{"location":"phase-1/dc-design/#final-takeaways","title":"\u2705 Final Takeaways","text":"<ul> <li>Data centers require balance between power, cooling, network, and security.  </li> <li>Each design decision impacts cost, scalability, and resilience.  </li> <li>Strong planning ensures efficiency, availability, and trust for decades.  </li> </ul>"},{"location":"phase-1/dc-geo-location/","title":"Geo-Location","text":""},{"location":"phase-1/dc-geo-location/#selecting-a-geographic-location","title":"Selecting a Geographic Location","text":""},{"location":"phase-1/dc-geo-location/#what-is-it","title":"What is it?","text":"<p>The physical site where the data center is built.</p>"},{"location":"phase-1/dc-geo-location/#theoretical-definition","title":"Theoretical Definition","text":"<p>Strategic placement of DCs based on latency, utilities, and disaster risk.</p>"},{"location":"phase-1/dc-geo-location/#why-is-it-important","title":"Why is it Important?","text":"<ul> <li>Impacts latency, cost, and availability.  </li> <li>Wrong location = constant outages or high costs.  </li> </ul>"},{"location":"phase-1/dc-geo-location/#how-is-it-planned","title":"How is it Planned?","text":"<ul> <li>Proximity to users.  </li> <li>Safe zone (no floods/earthquakes).  </li> <li>Nearby utilities + political stability.  </li> </ul>"},{"location":"phase-1/dc-geo-location/#impact-down-the-line","title":"Impact Down the Line","text":"<p>Wrong choice = business disruption, higher OPEX.</p>"},{"location":"phase-1/dc-geo-location/#real-world-example","title":"Real World Example","text":"<p>Facebook chose Sweden for cold climate \u2192 reduced cooling costs drastically.</p>"},{"location":"phase-1/dc-geo-location/#safe-from-natural-hazards-manmade-disasters","title":"Safe from Natural Hazards &amp; Manmade Disasters","text":""},{"location":"phase-1/dc-geo-location/#what-is-it_1","title":"What is it?","text":"<p>Ensuring DC is resilient against natural and human risks.</p>"},{"location":"phase-1/dc-geo-location/#theoretical-definition_1","title":"Theoretical Definition","text":"<p>Designing with disaster-avoidance and mitigation in mind (earthquake, flood, fire, sabotage).</p>"},{"location":"phase-1/dc-geo-location/#why-is-it-important_1","title":"Why is it Important?","text":"<ul> <li>Protects business continuity.  </li> <li>Avoids catastrophic downtime.  </li> </ul>"},{"location":"phase-1/dc-geo-location/#how-is-it-planned_1","title":"How is it Planned?","text":"<ul> <li>Choose safe locations.  </li> <li>Fire suppression (FM200 gas).  </li> <li>Earthquake-resistant design.  </li> </ul>"},{"location":"phase-1/dc-geo-location/#impact-down-the-line_1","title":"Impact Down the Line","text":"<p>Ignoring this = catastrophic outages, massive losses.</p>"},{"location":"phase-1/dc-geo-location/#real-world-example_1","title":"Real World Example","text":"<p>Hurricane Sandy (2012) flooded several NYC DCs, halting trading and services.</p>"},{"location":"phase-1/dc-geo-location/#availability-of-local-technical-talent","title":"Availability of Local Technical Talent","text":""},{"location":"phase-1/dc-geo-location/#what-is-it_2","title":"What is it?","text":"<p>Skilled workforce near the DC site.</p>"},{"location":"phase-1/dc-geo-location/#theoretical-definition_2","title":"Theoretical Definition","text":"<p>Access to trained IT, HVAC, and electrical staff for smooth operation.</p>"},{"location":"phase-1/dc-geo-location/#why-is-it-important_2","title":"Why is it Important?","text":"<ul> <li>Skilled staff reduce downtime.  </li> <li>Easier hiring = lower costs.  </li> </ul>"},{"location":"phase-1/dc-geo-location/#how-is-it-planned_2","title":"How is it Planned?","text":"<ul> <li>Build near metro hubs/university towns.  </li> <li>Offer competitive salaries.  </li> </ul>"},{"location":"phase-1/dc-geo-location/#impact-down-the-line_2","title":"Impact Down the Line","text":"<p>No skilled staff = long downtime, slow fixes.</p>"},{"location":"phase-1/dc-geo-location/#real-world-example_2","title":"Real World Example","text":"<p>Northern Virginia is a DC hub partly due to a rich pool of skilled engineers.</p>"},{"location":"phase-1/dc-geo-location/#abundant-inexpensive-utilities","title":"Abundant &amp; Inexpensive Utilities","text":""},{"location":"phase-1/dc-geo-location/#what-is-it_3","title":"What is it?","text":"<p>Access to reliable and cost-effective electricity and water.</p>"},{"location":"phase-1/dc-geo-location/#theoretical-definition_3","title":"Theoretical Definition","text":"<p>Utility availability ensures continuous power and cooling resources.</p>"},{"location":"phase-1/dc-geo-location/#why-is-it-important_3","title":"Why is it Important?","text":"<ul> <li>Energy = biggest OPEX factor.  </li> <li>Water = needed for cooling.  </li> </ul>"},{"location":"phase-1/dc-geo-location/#how-is-it-planned_3","title":"How is it Planned?","text":"<ul> <li>Partner with utility providers.  </li> <li>Use renewable energy for cost savings.  </li> </ul>"},{"location":"phase-1/dc-geo-location/#impact-down-the-line_3","title":"Impact Down the Line","text":"<p>Utility shortages = downtime. Expensive power = unsustainable OPEX.</p>"},{"location":"phase-1/dc-geo-location/#real-world-example_3","title":"Real World Example","text":"<p>Google DCs run partially on renewable energy contracts to reduce dependency and costs.</p>"},{"location":"phase-1/dc-geo-location/#selecting-an-existing-building","title":"Selecting an Existing Building","text":""},{"location":"phase-1/dc-geo-location/#what-is-it_4","title":"What is it?","text":"<p>Reusing a current structure for data center use.</p>"},{"location":"phase-1/dc-geo-location/#theoretical-definition_4","title":"Theoretical Definition","text":"<p>Retrofit of commercial/industrial buildings into DC facilities.</p>"},{"location":"phase-1/dc-geo-location/#why-is-it-important_4","title":"Why is it Important?","text":"<ul> <li>Can save CAPEX.  </li> <li>But may limit scalability.  </li> </ul>"},{"location":"phase-1/dc-geo-location/#how-is-it-planned_4","title":"How is it Planned?","text":"<ul> <li>Assess structural capacity, cooling, and power.  </li> <li>Renovate accordingly.  </li> </ul>"},{"location":"phase-1/dc-geo-location/#impact-down-the-line_4","title":"Impact Down the Line","text":"<p>Mismatched retrofits = costly operational issues.</p>"},{"location":"phase-1/dc-geo-location/#real-world-example_4","title":"Real World Example","text":"<p>Many banks retrofit old office spaces into secure private DCs.</p>"},{"location":"phase-1/dc-networks/","title":"Networks","text":""},{"location":"phase-1/dc-networks/#required-network-bandwidth","title":"Required Network Bandwidth","text":""},{"location":"phase-1/dc-networks/#what-is-it","title":"What is it?","text":"<p>The amount of network capacity needed for data transfer.</p>"},{"location":"phase-1/dc-networks/#theoretical-definition","title":"Theoretical Definition","text":"<p>Network bandwidth = maximum rate of data transfer between servers and the internet/backbone.</p>"},{"location":"phase-1/dc-networks/#why-is-it-important","title":"Why is it Important?","text":"<ul> <li>High-speed links ensure low latency.  </li> <li>Redundancy prevents outages.  </li> <li>Drives application performance.  </li> </ul>"},{"location":"phase-1/dc-networks/#how-is-it-planned","title":"How is it Planned?","text":"<ul> <li>Estimate workload traffic.  </li> <li>Enterprise: 10\u201340 Gbps. Hyperscale: 100\u2013400 Gbps.  </li> <li>Use multiple ISPs for redundancy.  </li> </ul>"},{"location":"phase-1/dc-networks/#impact-down-the-line","title":"Impact Down the Line","text":"<p>Under-provisioned = latency, downtime. Over-provisioned = unnecessary cost.</p>"},{"location":"phase-1/dc-networks/#real-world-example","title":"Real World Example","text":"<p>Banks often contract with two ISPs for redundant connections to ensure 24/7 services.</p>"},{"location":"phase-1/dc-physical-area/","title":"Physical Area","text":""},{"location":"phase-1/dc-physical-area/#required-physical-area","title":"Required Physical Area","text":""},{"location":"phase-1/dc-physical-area/#what-is-it","title":"What is it?","text":"<p>The space needed to host IT equipment, infrastructure, and personnel.</p>"},{"location":"phase-1/dc-physical-area/#theoretical-definition","title":"Theoretical Definition","text":"<p>The required floor space (measured in square feet or meters) necessary for racks, cooling units, cabling, and clearance zones.</p>"},{"location":"phase-1/dc-physical-area/#why-is-it-important","title":"Why is it Important?","text":"<ul> <li>Determines capacity of the data center.  </li> <li>Inadequate space \u2192 growth limitations.  </li> <li>Impacts cooling and airflow.  </li> </ul>"},{"location":"phase-1/dc-physical-area/#how-is-it-planned","title":"How is it Planned?","text":"<ul> <li>Calculate rack count + clearance.  </li> <li>Reserve 20\u201330% for growth.  </li> <li>Plan zones (server halls, NOC, staging).  </li> </ul>"},{"location":"phase-1/dc-physical-area/#impact-down-the-line","title":"Impact Down the Line","text":"<p>Too small = frequent migrations. Too large = high cost for unused space.</p>"},{"location":"phase-1/dc-physical-area/#real-world-example","title":"Real World Example","text":"<p>A mid-size enterprise DC (50 racks) may require ~5,000 sq. ft. of raised floor.</p>"},{"location":"phase-1/dc-power/","title":"Power","text":""},{"location":"phase-1/dc-power/#required-power","title":"Required Power","text":""},{"location":"phase-1/dc-power/#what-is-it","title":"What is it?","text":"<p>The electricity needed to operate all IT and supporting equipment.</p>"},{"location":"phase-1/dc-power/#theoretical-definition","title":"Theoretical Definition","text":"<p>The total electrical load required for IT hardware + support systems, including redundancy (UPS, generators).</p>"},{"location":"phase-1/dc-power/#why-is-it-important","title":"Why is it Important?","text":"<ul> <li>Downtime risk: Power loss = service outage.  </li> <li>Redundant power ensures business continuity.  </li> <li>Major cost factor in OPEX.  </li> </ul>"},{"location":"phase-1/dc-power/#how-is-it-planned","title":"How is it Planned?","text":"<ul> <li>Estimate rack power (3\u20135 kW typical, 10+ kW high density).  </li> <li>Deploy UPS, generators (N+1, 2N redundancy).  </li> <li>Use PDUs for safe distribution.  </li> </ul>"},{"location":"phase-1/dc-power/#impact-down-the-line","title":"Impact Down the Line","text":"<p>Under-provisioning = outages; over-provisioning = wasted CAPEX. High consumption = poor efficiency (high PUE).</p>"},{"location":"phase-1/dc-power/#real-world-example","title":"Real World Example","text":"<p>In 2017, British Airways lost ~$100M after a power surge crippled its data center, halting flights worldwide.</p>"},{"location":"phase-1/dc-ratings/","title":"Data Center Ratings &amp; Classifications","text":""},{"location":"phase-1/dc-ratings/#what-is-it","title":"What is it?","text":"<p>Data centers are classified by tiers and standards to define their reliability, redundancy, and uptime guarantees. These ratings help organizations decide what level of infrastructure they need based on cost vs reliability.</p>"},{"location":"phase-1/dc-ratings/#theoretical-definition","title":"Theoretical Definition","text":"<p>The Uptime Institute Tier Classification and TIA-942 Standard are globally recognized frameworks: - They measure availability, redundancy, and fault tolerance. - Higher tiers = more resilient, but also more expensive.  </p>"},{"location":"phase-1/dc-ratings/#why-is-it-important","title":"Why is it Important?","text":"<ul> <li>Businesses must match IT criticality with the right data center tier.  </li> <li>Banks, healthcare, and cloud providers need higher tiers (near 100% uptime).  </li> <li>Small companies may balance costs with lower tiers.  </li> </ul>"},{"location":"phase-1/dc-ratings/#classifications-uptime-institute-tiers","title":"Classifications (Uptime Institute Tiers)","text":""},{"location":"phase-1/dc-ratings/#tier-i-basic-capacity","title":"Tier I \u2014 Basic Capacity","text":"<ul> <li>Definition: Non-redundant capacity components (single path for power/cooling).  </li> <li>Uptime: 99.671% (~28.8 hours downtime/year).  </li> <li>Use Case: Small businesses, test environments.  </li> <li>Example: A startup hosting dev servers with minimal redundancy.</li> </ul>"},{"location":"phase-1/dc-ratings/#tier-ii-redundant-capacity","title":"Tier II \u2014 Redundant Capacity","text":"<ul> <li>Definition: Redundant components (N+1), but only one path for power/cooling.  </li> <li>Uptime: 99.741% (~22 hours downtime/year).  </li> <li>Use Case: SMEs needing some resilience.  </li> <li>Example: Regional data center with backup UPS and generators.</li> </ul>"},{"location":"phase-1/dc-ratings/#tier-iii-concurrently-maintainable","title":"Tier III \u2014 Concurrently Maintainable","text":"<ul> <li>Definition: Multiple power/cooling paths; only one active at a time; components can be maintained without downtime.  </li> <li>Uptime: 99.982% (~1.6 hours downtime/year).  </li> <li>Use Case: Enterprises, banks, e-commerce.  </li> <li>Example: Most colocation data centers.  </li> </ul>"},{"location":"phase-1/dc-ratings/#tier-iv-fault-tolerant","title":"Tier IV \u2014 Fault Tolerant","text":"<ul> <li>Definition: Multiple active power/cooling paths; redundant systems (2N+1); can sustain one failure without downtime.  </li> <li>Uptime: 99.995% (~26 minutes downtime/year).  </li> <li>Use Case: Mission-critical (stock exchanges, global cloud).  </li> <li>Example: Hyperscale providers (AWS, Google, Microsoft Azure).  </li> </ul>"},{"location":"phase-1/dc-ratings/#tia-942-classification","title":"TIA-942 Classification","text":"<p>The Telecommunications Infrastructure Standard for Data Centers (TIA-942) defines four Rating levels (similar to Uptime Tiers). It covers telecommunications, cabling, redundancy, and physical requirements.</p> <ul> <li>Rated 1: Basic site infrastructure, single path, non-redundant.  </li> <li>Rated 2: Redundant capacity components, single path.  </li> <li>Rated 3: Concurrently maintainable, multiple paths (one active).  </li> <li>Rated 4: Fault tolerant, multiple active paths, fully redundant.  </li> </ul>"},{"location":"phase-1/dc-ratings/#how-is-it-planned","title":"How is it Planned?","text":"<ul> <li>Assess business needs (cost of downtime, compliance).  </li> <li>Select tier/rating accordingly.  </li> <li>Design with required redundancy levels (power, cooling, network).  </li> <li>Certification by Uptime Institute or TIA-942 auditors.</li> </ul>"},{"location":"phase-1/dc-ratings/#how-can-it-impact-down-the-line","title":"How Can it Impact Down the Line?","text":"<ul> <li>Lower tier = cheaper but higher downtime risk.  </li> <li>Higher tier = resilient but higher CAPEX/OPEX.  </li> <li>Wrong choice \u2192 either wasted money or business outages.  </li> </ul>"},{"location":"phase-1/dc-ratings/#real-world-examples","title":"Real World Examples","text":"<ul> <li>Tier I: Small office server rooms.  </li> <li>Tier II: Local colocation providers in small cities.  </li> <li>Tier III: Equinix, Digital Realty enterprise-grade facilities.  </li> <li>Tier IV: Google, AWS, Microsoft Azure hyperscale facilities with global fault tolerance.</li> </ul>"},{"location":"phase-1/dc-ratings/#dc-ratings-in-nutshell","title":"DC Ratings in nutshell","text":""},{"location":"phase-1/dc-ratings/#key-takeaways","title":"\u2705 Key Takeaways","text":"<ul> <li>Data center ratings (Uptime Tiers &amp; TIA-942) define availability, redundancy, and resilience.  </li> <li>Businesses must align criticality vs cost when choosing a data center tier.  </li> <li>Tier III is common for enterprises; Tier IV is essential for hyperscale and mission-critical industries.</li> </ul>"},{"location":"phase-1/dc-weigth/","title":"Weigth","text":""},{"location":"phase-1/dc-weigth/#required-weight","title":"Required Weight","text":""},{"location":"phase-1/dc-weigth/#what-is-it","title":"What is it?","text":"<p>The structural load capacity required to support racks and equipment.</p>"},{"location":"phase-1/dc-weigth/#theoretical-definition","title":"Theoretical Definition","text":"<p>The maximum weight per rack/floor tile that the data center floor must withstand without sagging.</p>"},{"location":"phase-1/dc-weigth/#why-is-it-important","title":"Why is it Important?","text":"<ul> <li>Prevents floor collapse or structural failure.  </li> <li>Critical in retrofitting existing buildings.  </li> </ul>"},{"location":"phase-1/dc-weigth/#how-is-it-planned","title":"How is it Planned?","text":"<ul> <li>Calculate average rack weight (1,000\u20132,000 lbs).  </li> <li>Verify load-bearing capacity of raised floors.  </li> </ul>"},{"location":"phase-1/dc-weigth/#impact-down-the-line","title":"Impact Down the Line","text":"<p>Insufficient planning = structural damage, safety hazards.</p>"},{"location":"phase-1/dc-weigth/#real-world-example","title":"Real World Example","text":"<p>Modern DC designs use reinforced flooring capable of supporting high-density racks.</p>"},{"location":"phase-1/overview/","title":"Data Center Management","text":""},{"location":"phase-1/overview/#what-is-a-data-center","title":"What is a Data Center?","text":"<p>A data center is a facility that houses servers, storage, networking devices, and supporting infrastructure needed to deliver applications and services. It is the backbone of modern IT, powering everything from websites to banking systems to cloud platforms.</p>"},{"location":"phase-1/overview/#data-center-architecture","title":"Data Center Architecture","text":"<ul> <li>Core Components: Compute (servers), Storage (NAS/SAN), Networking (LAN/WAN), Power, Cooling, Security.  </li> <li>Support Systems: HVAC, UPS, backup generators, fire suppression, monitoring systems.  </li> <li>Design Approach: Built for availability, scalability, efficiency, and security.  </li> <li>Often structured in tiers (Tier I\u2013IV) to define reliability levels.</li> </ul>"},{"location":"phase-1/overview/#key-requirements","title":"Key Requirements","text":"<ol> <li>Physical space \u2013 racks, clearance, growth capacity.  </li> <li>Power \u2013 reliable supply, UPS, generators, redundancy.  </li> <li>Cooling (HVAC) \u2013 control temperature &amp; humidity, prevent overheating.  </li> <li>Network bandwidth \u2013 high-speed connectivity, redundancy (multiple ISPs).  </li> <li>Security \u2013 CCTV, biometrics, restricted access, fire safety.  </li> <li>Location factors \u2013 safe from natural/manmade hazards, close to talent and utilities.  </li> <li>Budget &amp; efficiency \u2013 build/operate within cost, aim for low PUE (Power Usage Effectiveness).</li> </ol>"},{"location":"phase-1/overview/#why-data-center-management-is-difficult","title":"Why Data Center Management is Difficult","text":"<ul> <li>Balancing performance vs cost (power, cooling, staffing are expensive).  </li> <li>Ensuring 99.9%+ uptime (no tolerance for downtime in banking, e-commerce, etc.).  </li> <li>Managing rapid growth in demand (scalability challenges).  </li> <li>Protecting against cyber threats + physical risks.  </li> <li>Maintaining compliance with regulations and standards.  </li> </ul>"},{"location":"phase-1/overview/#importance-of-data-center-management","title":"Importance of Data Center Management","text":"<ul> <li>Critical for business continuity \u2014 downtime can mean huge financial loss.  </li> <li>Impacts customer trust \u2014 users expect apps/services to be always available.  </li> <li>Drives digital transformation \u2014 enterprises rely on well-managed DCs or cloud.  </li> <li>A poorly managed data center = high costs, frequent outages, security risks.  </li> </ul>"},{"location":"phase-1/overview/#understanding-modern-data-centers-from-the-experts","title":"Understanding Modern Data Centers from \"The Experts\"","text":"<p>\u2705 In short: Data centers are complex ecosystems that require careful design, continuous monitoring, and expert management to ensure they remain secure, efficient, and always available.</p>"},{"location":"phase-1/ph1-quiz/","title":"Phase 1 - Data Center Management - Knowledge Check","text":"<p>It's time to assess your understanding of the topics covered in Phase 1: Data Center Management Please follow the steps below to take the exam:</p> <ol> <li>Scan the provided QR code or visit the designated link to register for the exam (if you haven't already).</li> <li>Locate the exam titled Phase 1: Data Center Management.</li> <li>The exam will be unlocked by the instructor once all students are ready.</li> </ol> <p>QR Code for Exam System:</p> <p></p> <p>Link for Exam System:</p> <p>Exam System </p> <p>Ensure you are prepared to demonstrate your knowledge. Good luck!</p>"},{"location":"phase-1/dc-infra/00_Overview/","title":"Infrastructure in a Data Center \u2014 Overview","text":""},{"location":"phase-1/dc-infra/00_Overview/#1-what-this-section-is-all-about","title":"1. What this section is all about","text":"<p>This session explores the core infrastructure of a modern data center, focusing on both the physical and logical aspects. Students will learn how cables, servers, monitoring systems, and security controls are planned, deployed, and maintained to ensure seamless IT operations. The session also covers disaster recovery, consolidation strategies, and system administration practices that directly impact business continuity and cost optimization.</p> <p>By the end of this session, students (acting as employees of TechOps Inc.) will be able to design, evaluate, and manage data center infrastructure that supports scalability, high availability, and security.</p>"},{"location":"phase-1/dc-infra/00_Overview/#2-summary-of-all-sub-topics","title":"2. Summary of all sub-topics","text":"<ul> <li>Modular Cabling Design  </li> <li>Points of Distribution  </li> <li>ISP Network Infrastructure and WAN Links  </li> <li>Network Operations Center and Monitoring  </li> <li>Data Center Physical Security, Logical Security, and Cleaning  </li> <li>Reasons for Data Center Consolidation  </li> <li>Consolidation Opportunities  </li> <li>Datacenter Servers  </li> <li>Server Capacity Planning  </li> <li>Disaster Recovery  </li> <li>Data Center Security Guidelines  </li> <li>Internet Security Guidelines  </li> <li>Internet Security  </li> <li>Source Security Issues  </li> <li>Best Practices for System Administration  </li> <li>System Administration Work Automation  </li> </ul>"},{"location":"phase-1/dc-infra/01_Modular_Cabling_Design/","title":"Modular Cabling Design","text":""},{"location":"phase-1/dc-infra/01_Modular_Cabling_Design/#1-what-is-it","title":"1. What is it?","text":"<p>Modular cabling design means organizing all the cables in a data center in a structured, repeatable way so that adding new servers or making changes doesn\u2019t create a tangled mess. It uses zones and standardized components so the system is neat, easy to expand, and easy to troubleshoot.</p>"},{"location":"phase-1/dc-infra/01_Modular_Cabling_Design/#2-theoretical-definition","title":"2. Theoretical Definition","text":"<p>Structured cabling is a standardized approach to data center cabling defined by TIA/EIA-568 standards. It divides the cabling system into zones and uses modular, interchangeable parts like patch panels, racks, and fiber optic modules to ensure scalability and flexibility.</p>"},{"location":"phase-1/dc-infra/01_Modular_Cabling_Design/#3-why-is-it-important","title":"3. Why is it important?","text":"<ul> <li>Reduces downtime (easy to replace or add connections).</li> <li>Makes troubleshooting simple (clear labeling and layout).</li> <li>Future-proofs the data center (easy to add faster connections like 40/100 Gbps fiber).</li> <li>Saves costs in the long run (less rework, less mess).</li> </ul>"},{"location":"phase-1/dc-infra/01_Modular_Cabling_Design/#4-how-is-it-planned","title":"4. How is it planned?","text":"<p>In structured cabling, the data center is divided into zones:</p> <ul> <li> <p>MDA (Main Distribution Area)</p> <ul> <li>Think of this as the \u201cnerve center\u201d of the data center.</li> <li>All core network equipment like main switches, routers, and backbone cables are located here.</li> <li>It connects to the outside world (ISP/WAN) and distributes traffic internally.</li> </ul> </li> <li> <p>HDA (Horizontal Distribution Area)</p> <ul> <li>Imagine this as the \u201cfloor manager\u201d.</li> <li>Located on each row or section of server racks.</li> <li>Contains switches and patch panels that connect to the servers in that area.</li> </ul> </li> <li> <p>ZDA (Zone Distribution Area)</p> <ul> <li>Acts like a \u201clocal breakout box\u201d.</li> <li>It\u2019s an optional area between HDA and the servers.</li> <li>Used when you need flexibility for frequent changes \u2014 for example, in cloud providers who add/remove servers all the time.</li> </ul> </li> <li> <p>Other components used:</p> <ul> <li>Patch Panels \u2192 Boards where multiple cables plug in; makes it easy to rearrange connections without touching the main cables.</li> <li>Fiber Optics \u2192 High-speed cables (instead of copper) used for backbone connections.</li> <li>Standardized Connectors \u2192 Like using the same type of plugs everywhere (RJ45, LC, SC) so you don\u2019t get compatibility issues.</li> </ul> </li> </ul> <p></p>"},{"location":"phase-1/dc-infra/01_Modular_Cabling_Design/#5-impact-if-not-done-correctly","title":"5. Impact if not done correctly","text":"<ul> <li>Cable clutter leading to accidental disconnections.</li> <li>Hard to track which server is connected where \u2192 longer downtime.</li> <li>Increased costs for upgrades or maintenance.</li> <li>Poor airflow because of messy cables \u2192 overheating issues.</li> </ul>"},{"location":"phase-1/dc-infra/01_Modular_Cabling_Design/#6-real-world-example","title":"6. Real World Example","text":"<p>At Facebook\u2019s Prineville Data Center (Oregon, USA), engineers use structured cabling zones so they can add thousands of new servers every year without interrupting existing operations. They rely heavily on fiber optics in the backbone (MDA) and patch panels in HDA to manage growth.</p>"},{"location":"phase-1/dc-infra/01_Modular_Cabling_Design/#examples-of-good-cabling","title":"Examples of Good Cabling","text":"<p>HDA Cabling:</p> <p></p> <p>Rack Cabling:</p> <p></p>"},{"location":"phase-1/dc-infra/02_Points_of_Distribution/","title":"Points of Distribution (PoD)","text":""},{"location":"phase-1/dc-infra/02_Points_of_Distribution/#1-what-is-it","title":"1. What is it?","text":"<p>In a data center, Points of Distribution (PoD) are the structured layers where network cabling and devices are logically grouped. Think of them as checkpoints or junctions where cables come together and are distributed to the next level. This design makes the network scalable, organized, and easier to manage.</p>"},{"location":"phase-1/dc-infra/02_Points_of_Distribution/#2-theoretical-definition","title":"2. Theoretical Definition","text":"<p>The Telecommunications Industry Association (TIA) defines distribution points in structured cabling standards. They divide the data center network into hierarchical layers that handle traffic at different scales:  </p> <ul> <li>MDA (Main Distribution Area) \u2192 The central hub where core routers, main switches, and backbone connections live.  </li> <li>IDA (Intermediate Distribution Area) \u2192 The middle layer (optional) that helps when the data center is very large.  </li> <li>HDA (Horizontal Distribution Area) \u2192 The distribution points closer to server racks; usually houses access switches.  </li> <li>EDA (Equipment Distribution Area) \u2192 The endpoints \u2014 where servers, storage, and user devices are connected.  </li> </ul>"},{"location":"phase-1/dc-infra/02_Points_of_Distribution/#3-why-is-it-important","title":"3. Why is it important?","text":"<ul> <li>Ensures data flows smoothly from core (MDA) to servers (EDA).  </li> <li>Reduces network congestion by spreading load across layers.  </li> <li>Makes troubleshooting easier (you know at which \u201clayer\u201d a problem exists).  </li> <li>Provides redundancy \u2014 if one path fails, another can take over.  </li> <li>Supports modular scaling: just add more PoDs when expanding.  </li> </ul>"},{"location":"phase-1/dc-infra/02_Points_of_Distribution/#4-how-is-it-planned","title":"4. How is it planned?","text":"<p>A simple way to understand the PoD hierarchy:  </p> <ul> <li> <p>Main Distribution Area (MDA) </p> <ul> <li>The \u201cbrain\u201d of the data center.  </li> <li>Contains the core routers, firewalls, and main patch panels.  </li> <li>Connects to external ISPs and WAN links.  </li> </ul> </li> <li> <p>Intermediate Distribution Area (IDA) (used in large data centers)  </p> <ul> <li>The \u201cregional office\u201d between the brain and the floor-level switches.  </li> <li>Helps reduce long cable runs by splitting traffic regionally.  </li> </ul> </li> <li> <p>Horizontal Distribution Area (HDA) </p> <ul> <li>The \u201cfloor manager\u201d for a row of server racks.  </li> <li>Contains access switches and patch panels that connect to equipment in that area.  </li> </ul> </li> <li> <p>Equipment Distribution Area (EDA) </p> <ul> <li>The \u201cend users\u201d of the system \u2014 servers, storage, and application hardware.  </li> <li>The final point where devices plug into the network.</li> </ul> </li> </ul> <p>\ud83d\udccc Design Tip</p> <p>In smaller data centers, IDA might be skipped, but MDA \u2192 HDA \u2192 EDA is always present.  </p>"},{"location":"phase-1/dc-infra/02_Points_of_Distribution/#5-impact-if-not-done-correctly","title":"5. Impact if not done correctly","text":"<ul> <li>Too many devices connected directly to core switches \u2192 bottlenecks and downtime.  </li> <li>Difficult to trace faults \u2192 longer MTTR (Mean Time to Repair).  </li> <li>Poor scalability \u2014 adding new racks means running new long cables instead of plugging into local HDAs.  </li> <li>Higher costs in cable management and cooling.  </li> </ul>"},{"location":"phase-1/dc-infra/02_Points_of_Distribution/#6-real-world-example","title":"6. Real World Example","text":"<p>At Equinix Data Centers, the Point of Distribution design is key to their colocation services. - MDA connects clients to global internet backbones. - HDA distributes connections to each customer\u2019s cage/rack. - EDA connects to client servers.  </p> <p>This modular design allows Equinix to onboard new clients quickly while keeping latency low and ensuring uptime.  </p> <p>\ud83d\udc49 Easy Analogy: - MDA = Airport hub (international flights). - IDA = Regional airports (optional). - HDA = City airports. - EDA = Your neighborhood taxi stand (final destination).  </p> <p></p>"},{"location":"phase-1/dc-infra/03_ISP_WAN_Links/","title":"ISP Network Infrastructure and WAN Links","text":""},{"location":"phase-1/dc-infra/03_ISP_WAN_Links/#1-what-is-it","title":"1. What is it?","text":"<p>This refers to the external connectivity of a data center \u2014 how it connects to the internet, other data centers, and remote branch offices. It is provided by Internet Service Providers (ISPs) through high-speed Wide Area Network (WAN) links. Without this, a data center would only be a local island, not accessible to users or other sites.</p>"},{"location":"phase-1/dc-infra/03_ISP_WAN_Links/#2-theoretical-definition","title":"2. Theoretical Definition","text":"<ul> <li>ISP Network Infrastructure \u2192 The collection of physical cables (fiber optic cables, undersea cables, satellite links), routers, and switches that deliver internet services.  </li> <li>WAN (Wide Area Network) Links \u2192 High-capacity connections (leased lines, MPLS, SD-WAN) that extend connectivity beyond the local data center to branch offices, cloud services, and end-users.  </li> </ul> <p>These links are designed for high availability, low latency, and redundancy.</p>"},{"location":"phase-1/dc-infra/03_ISP_WAN_Links/#3-why-is-it-important","title":"3. Why is it important?","text":"<ul> <li>Provides access to cloud platforms (AWS, Azure, Google Cloud).  </li> <li>Enables remote employees and branch offices to connect securely.  </li> <li>Supports business continuity by ensuring always-on connectivity.  </li> <li>Allows hosting of websites, apps, and services that are publicly reachable.  </li> <li>Critical for disaster recovery (DR) sites that must synchronize data across regions.  </li> </ul>"},{"location":"phase-1/dc-infra/03_ISP_WAN_Links/#4-how-is-it-planned","title":"4. How is it planned?","text":"<p>When planning ISP and WAN connectivity, data centers consider:  </p> <ul> <li>Redundancy \u2192 Using at least two ISPs with separate physical paths so one failure doesn\u2019t cause downtime.  </li> <li>Bandwidth \u2192 Calculated based on expected traffic (e.g., number of users, applications, backup requirements).  </li> <li> <p>Technology Choices:  </p> <ul> <li>Leased Lines \u2192 Dedicated fiber between the data center and ISP, guaranteed bandwidth.  </li> <li>MPLS (Multiprotocol Label Switching) \u2192 Secure private WAN service, often used by banks and enterprises.  </li> <li>SD-WAN (Software-Defined WAN) \u2192 Modern approach that uses internet connections intelligently to balance cost and performance.  </li> <li></li> <li>Service Level Agreements (SLAs) \u2192 ISPs guarantee uptime, latency, and support response times.  </li> <li>Security \u2192 Firewalls, VPNs, and DDoS protection at the ISP edge.  </li> </ul> </li> </ul>"},{"location":"phase-1/dc-infra/03_ISP_WAN_Links/#5-impact-if-not-done-correctly","title":"5. Impact if not done correctly","text":"<ul> <li>Single point of failure: If only one ISP is used, downtime could last hours or days.  </li> <li>Poor user experience: Slow applications and websites due to lack of bandwidth.  </li> <li>Business losses: E-commerce, financial services, and streaming platforms could lose millions during outages.  </li> <li>Security risks: Insecure WAN links could allow man-in-the-middle attacks or data leaks.  </li> </ul>"},{"location":"phase-1/dc-infra/03_ISP_WAN_Links/#6-real-world-example","title":"6. Real World Example","text":"<ul> <li>Amazon Web Services (AWS) builds redundant WAN links across regions to provide low-latency global services.  </li> <li>For example, AWS India (Mumbai region) connects via undersea fiber optic cables to Singapore and Europe.  </li> <li>Enterprises like banks often use MPLS WAN links for secure financial transactions, while startups may use SD-WAN for cost savings.  </li> </ul>"},{"location":"phase-1/dc-infra/03_ISP_WAN_Links/#7-live-sea-cable-map","title":"7. Live Sea Cable Map","text":"<p>Below is the screenshot showing current network of sea cables laied world wide. Click here to dig in more</p> <p></p> <p>\ud83d\udc49 Easy Analogy: - ISP = Highway system that connects your city (data center) to the rest of the world. - WAN Links = The express lanes (leased lines, MPLS, SD-WAN) that guarantee faster, more reliable travel than public roads. - Redundancy = Having two highways so even if one is blocked, traffic still flows.  </p>"},{"location":"phase-1/dc-infra/04_NOC/","title":"Network Operations Center (NOC) and Monitoring","text":""},{"location":"phase-1/dc-infra/04_NOC/#1-what-is-it","title":"1. What is it?","text":"<p>A Network Operations Center (NOC) is the command center of a data center or IT organization. It\u2019s a dedicated space (often a large room with screens and monitoring tools) where IT staff track the health of servers, networks, applications, and security in real-time.  </p> <p>Monitoring is the continuous process of collecting, analyzing, and acting on data about the infrastructure to ensure everything is running smoothly.</p>"},{"location":"phase-1/dc-infra/04_NOC/#2-theoretical-definition","title":"2. Theoretical Definition","text":"<ul> <li>NOC \u2192 A centralized facility where network engineers and administrators monitor and manage network traffic, server uptime, application performance, and security events.  </li> <li>Monitoring \u2192 The systematic use of tools and software (like Nagios, Prometheus, Zabbix, or SolarWinds) to detect problems before they impact end-users.  </li> </ul>"},{"location":"phase-1/dc-infra/04_NOC/#3-why-is-it-important","title":"3. Why is it important?","text":"<ul> <li>Ensures 24/7 availability of business-critical systems.  </li> <li>Detects outages or cyberattacks early (reducing downtime).  </li> <li>Improves performance by spotting bottlenecks before they affect users.  </li> <li>Provides centralized visibility across multiple data centers or offices.  </li> <li>Supports compliance with SLAs (Service Level Agreements).  </li> </ul>"},{"location":"phase-1/dc-infra/04_NOC/#4-how-is-it-planned","title":"4. How is it planned?","text":"<p>When setting up a NOC and monitoring strategy:  </p> <ul> <li> <p>Physical NOC Setup </p> <ul> <li>Large display walls showing dashboards (traffic load, alerts, security events).  </li> <li>Staffed by teams working in shifts to provide 24/7 coverage.  </li> </ul> </li> <li> <p>Monitoring Tools</p> <ul> <li>Infrastructure Monitoring \u2192 CPU, memory, disk usage, network throughput.  </li> <li>Application Monitoring \u2192 Response times, API failures, error rates.  </li> <li>Security Monitoring \u2192 Intrusion detection, firewall logs, suspicious traffic.  </li> <li>User Experience Monitoring \u2192 Simulating end-user actions to check service quality.  </li> </ul> </li> <li> <p>Alerting &amp; Escalation </p> <ul> <li>Automated alerts via email, SMS, or Slack when an issue occurs.  </li> <li>Escalation process (Level 1 \u2192 Level 2 \u2192 Level 3 engineers).  </li> </ul> </li> <li> <p>Redundancy </p> <ul> <li>Secondary NOC in another region (Global NOC) to continue operations in case the primary fails.  </li> </ul> </li> </ul>"},{"location":"phase-1/dc-infra/04_NOC/#5-impact-if-not-done-correctly","title":"5. Impact if not done correctly","text":"<ul> <li>Problems go unnoticed \u2192 extended downtime.  </li> <li>Customers may experience outages without IT knowing about it.  </li> <li>SLA violations leading to financial penalties.  </li> <li>Security breaches (like ransomware or DDoS attacks) might go undetected.  </li> <li>Loss of reputation and customer trust.  </li> </ul>"},{"location":"phase-1/dc-infra/04_NOC/#6-real-world-example","title":"6. Real World Example","text":"<ul> <li>Google\u2019s Site Reliability Engineering (SRE) teams act as a global NOC. They monitor millions of servers across continents using automation and dashboards.  </li> <li>Telecom companies (e.g., AT&amp;T, Reliance Jio) operate large NOCs to monitor internet backbone traffic, ensuring uninterrupted mobile and broadband services.  </li> <li>A bank might use a NOC to monitor ATM networks, online banking, and fraud detection systems in real-time.  </li> </ul> <p>\ud83d\udc49 Easy Analogy: - Think of a NOC like an airport control tower. - Controllers (NOC engineers) constantly watch planes (servers, apps, networks) to ensure smooth take-offs and landings (service delivery). - If one plane goes off course (a server fails), they act immediately to prevent accidents (outages).  </p>"},{"location":"phase-1/dc-infra/05_DataCenter_Physical_Logical_Security_and_Cleaning/","title":"Data Center Physical Security, Logical Security, and Cleaning","text":""},{"location":"phase-1/dc-infra/05_DataCenter_Physical_Logical_Security_and_Cleaning/#1-what-is-it","title":"1. What is it?","text":"<p>A data center is not only about servers and cables\u2014it\u2019s also about keeping them safe. Security in a data center has two main aspects:  </p> <ul> <li>Physical Security \u2192 Protecting the building and equipment from unauthorized entry, theft, or environmental hazards.  </li> <li>Logical Security \u2192 Protecting the data and systems from hackers, malware, or unauthorized digital access.  </li> <li>Cleaning &amp; Maintenance \u2192 Keeping the environment dust-free, controlled, and well-maintained to prevent hardware damage.  </li> </ul>"},{"location":"phase-1/dc-infra/05_DataCenter_Physical_Logical_Security_and_Cleaning/#2-theoretical-definition","title":"2. Theoretical Definition","text":"<ul> <li>Physical Security: Layered defenses including fencing, biometric access, CCTV surveillance, fire suppression, and climate control systems.  </li> <li>Logical Security: Cybersecurity practices like access controls, encryption, intrusion detection, and secure network design.  </li> <li>Cleaning &amp; Maintenance: Regular dust removal, airflow optimization (hot/cold aisles), and proper cable management to ensure longevity and uptime.  </li> </ul>"},{"location":"phase-1/dc-infra/05_DataCenter_Physical_Logical_Security_and_Cleaning/#3-why-is-it-important","title":"3. Why is it important?","text":"<ul> <li>Protects sensitive business and customer data.  </li> <li>Prevents outages due to equipment failures or environmental issues.  </li> <li>Ensures compliance with standards like ISO 27001, PCI-DSS, and HIPAA.  </li> <li>Builds customer trust by guaranteeing confidentiality, integrity, and availability of data.  </li> </ul>"},{"location":"phase-1/dc-infra/05_DataCenter_Physical_Logical_Security_and_Cleaning/#4-how-is-it-planned","title":"4. How is it planned?","text":"<ul> <li> <p>Physical Security Layers </p> <ul> <li>Perimeter fencing, guards, biometric access (fingerprint/iris scanners).  </li> <li>CCTV monitoring and motion detectors.  </li> <li>Locked server racks and cages.  </li> </ul> </li> <li> <p>Logical Security Measures </p> <ul> <li>Role-based access controls (only authorized personnel can access certain systems).  </li> <li>Firewalls, IDS/IPS (Intrusion Detection/Prevention Systems).  </li> <li>Multi-factor authentication (MFA) for admin access.  </li> <li>VPNs for secure remote connectivity.  </li> </ul> </li> <li> <p>Cleaning &amp; Maintenance Strategy </p> <ul> <li>Regular anti-static cleaning of server rooms and floors.  </li> <li>Monitoring HVAC (Heating, Ventilation, Air Conditioning) systems.  </li> <li>Proper hot aisle/cold aisle containment for airflow.  </li> <li>Cable management to avoid clutter and overheating.  </li> </ul> </li> </ul>"},{"location":"phase-1/dc-infra/05_DataCenter_Physical_Logical_Security_and_Cleaning/#5-impact-if-not-done-correctly","title":"5. Impact if not done correctly","text":"<ul> <li>Physical Security Lapses \u2192 Unauthorized entry leading to theft or sabotage.  </li> <li>Logical Security Weaknesses \u2192 Hackers gaining access to sensitive systems.  </li> <li>Poor Cleaning Practices \u2192 Dust clogging fans \u2192 overheating \u2192 downtime.  </li> <li>Regulatory Non-Compliance \u2192 Heavy fines and legal action.  </li> </ul>"},{"location":"phase-1/dc-infra/05_DataCenter_Physical_Logical_Security_and_Cleaning/#6-real-world-example","title":"6. Real World Example","text":"<ul> <li>Microsoft Azure Data Centers use multi-layer biometric authentication, CCTV, and secure cages.  </li> <li>A major bank in India faced a shutdown when dust clogged air filters, showing how poor cleaning can cause downtime.  </li> <li>The Equinix global data centers showcase physical + logical + environmental security in a single framework.  </li> </ul> <p>\ud83d\udc49 Easy Analogy: - Physical Security = Locks, guards, and CCTV for your home. - Logical Security = Passwords, firewalls, and antivirus on your Wi-Fi. - Cleaning = Regular dusting and AC maintenance to keep your electronics running smoothly.  </p>"},{"location":"phase-1/dc-infra/06_Reasons_for_Consolidation/","title":"Reasons for Data Center Consolidation","text":""},{"location":"phase-1/dc-infra/06_Reasons_for_Consolidation/#1-what-is-it","title":"1. What is it?","text":"<p>Data Center Consolidation means reducing the number of physical servers, applications, or even entire data centers by centralizing them into fewer, more efficient environments. It\u2019s like moving from several small, scattered storage rooms into one well-organized warehouse.  </p>"},{"location":"phase-1/dc-infra/06_Reasons_for_Consolidation/#2-theoretical-definition","title":"2. Theoretical Definition","text":"<p>Data center consolidation is the strategic process of combining and optimizing IT resources (servers, storage, networks, and facilities) to improve efficiency, reduce costs, and simplify management.  </p>"},{"location":"phase-1/dc-infra/06_Reasons_for_Consolidation/#3-why-is-it-important","title":"3. Why is it important?","text":"<ul> <li>Cost Savings \u2192 Fewer servers and facilities mean lower power, cooling, and maintenance costs.  </li> <li>Better Resource Utilization \u2192 Consolidation avoids servers running at only 10\u201320% capacity.  </li> <li>Simplified Management \u2192 Easier to monitor and maintain fewer data centers.  </li> <li>Environmental Impact \u2192 Reduces carbon footprint by consuming less energy.  </li> <li>Improved Reliability \u2192 Centralized systems are easier to secure and standardize.  </li> </ul>"},{"location":"phase-1/dc-infra/06_Reasons_for_Consolidation/#4-how-is-it-planned","title":"4. How is it planned?","text":"<ul> <li>Assessment Phase \u2192 Identify underutilized or redundant servers and applications.  </li> <li>Virtualization \u2192 Use VMware, Hyper-V, or KVM to run multiple workloads on fewer physical servers.  </li> <li>Cloud Adoption \u2192 Migrate some workloads to public or hybrid cloud platforms.  </li> <li>Data Migration Strategy \u2192 Plan how existing data and apps will move without downtime.  </li> <li>Redundancy and DR Planning \u2192 Ensure high availability during and after consolidation.  </li> </ul>"},{"location":"phase-1/dc-infra/06_Reasons_for_Consolidation/#5-impact-if-not-done-correctly","title":"5. Impact if not done correctly","text":"<ul> <li>Business disruption due to poorly planned migrations.  </li> <li>Risk of data loss if backups aren\u2019t in place.  </li> <li>Overloaded servers if capacity planning is ignored.  </li> <li>Increased complexity if some systems remain isolated.  </li> </ul>"},{"location":"phase-1/dc-infra/06_Reasons_for_Consolidation/#6-real-world-example","title":"6. Real World Example","text":"<ul> <li>HP (Hewlett-Packard) reduced 85 global data centers to 6, saving hundreds of millions annually.  </li> <li>U.S. Federal Government launched the Federal Data Center Consolidation Initiative (FDCCI) in 2010 to save billions by eliminating underutilized centers.  </li> </ul> <p>\ud83d\udc49 Easy Analogy: Imagine running 5 small shops across the city. Each has its own rent, staff, and bills. By consolidating them into 1 large supermarket, you save costs, manage inventory better, and serve more customers efficiently.  </p>"},{"location":"phase-1/dc-infra/07_Consolidation_Opportunities/","title":"Consolidation Opportunities","text":""},{"location":"phase-1/dc-infra/07_Consolidation_Opportunities/#1-what-is-it","title":"1. What is it?","text":"<p>Consolidation opportunities are the specific areas within a data center or IT environment where systems and processes can be merged or streamlined to save costs, reduce complexity, and improve efficiency. It\u2019s about identifying \u201cwhere can we combine resources without losing performance?\u201d</p>"},{"location":"phase-1/dc-infra/07_Consolidation_Opportunities/#2-theoretical-definition","title":"2. Theoretical Definition","text":"<p>Consolidation opportunities are the target points in infrastructure, applications, and operations that can be optimized or merged through techniques like virtualization, shared storage, cloud migration, or network simplification.  </p>"},{"location":"phase-1/dc-infra/07_Consolidation_Opportunities/#3-why-is-it-important","title":"3. Why is it important?","text":"<ul> <li>Cost Reduction \u2192 Fewer servers, licenses, and support costs.  </li> <li>Energy Savings \u2192 Less power and cooling required.  </li> <li>Simplified Operations \u2192 IT staff manage fewer systems with centralized tools.  </li> <li>Agility \u2192 Faster provisioning and scaling when infrastructure is streamlined.  </li> <li>Security and Compliance \u2192 Fewer systems = fewer attack surfaces and easier audits.  </li> </ul>"},{"location":"phase-1/dc-infra/07_Consolidation_Opportunities/#4-how-is-it-planned","title":"4. How is it planned?","text":"<p>Key areas to look for consolidation:  </p> <ul> <li> <p>Server Consolidation </p> <ul> <li>Virtualize workloads on fewer physical servers.  </li> <li>Example: 50 physical servers consolidated into 5 high-capacity hosts.  </li> </ul> </li> <li> <p>Storage Consolidation </p> <ul> <li>Replace scattered storage devices with centralized SAN (Storage Area Network) or NAS (Network Attached Storage) solutions.  </li> <li>Improves reliability and backup management.  </li> </ul> </li> <li> <p>Network Consolidation </p> <ul> <li>Simplify multiple switches and routers into fewer, high-capacity devices.  </li> <li>Implement SDN (Software-Defined Networking) for centralized management.  </li> </ul> </li> <li> <p>Application Consolidation </p> <ul> <li>Eliminate duplicate or redundant applications.  </li> <li>Use enterprise-wide platforms like ERP or CRM instead of multiple departmental tools.  </li> </ul> </li> <li> <p>Data Center Facility Consolidation </p> <ul> <li>Close smaller server rooms or local data centers, move workloads to a central facility or cloud.  </li> </ul> </li> </ul>"},{"location":"phase-1/dc-infra/07_Consolidation_Opportunities/#5-impact-if-not-done-correctly","title":"5. Impact if not done correctly","text":"<ul> <li>Overloading \u2192 Too many workloads on too few systems.  </li> <li>Single Point of Failure \u2192 If redundancy isn\u2019t designed in, one failure can take everything down.  </li> <li>Compatibility Issues \u2192 Applications may not work well when merged.  </li> <li>Hidden Costs \u2192 Migration costs can offset savings if not planned carefully.  </li> </ul>"},{"location":"phase-1/dc-infra/07_Consolidation_Opportunities/#6-real-world-example","title":"6. Real World Example","text":"<ul> <li>VMware customers have successfully consolidated hundreds of physical servers into a handful of virtualized hosts, reducing costs by up to 70%.  </li> <li>Netflix moved from physical data centers to AWS cloud infrastructure, consolidating IT resources globally.  </li> </ul> <p>\ud83d\udc49 Easy Analogy: Think of a household with 10 different refrigerators in separate rooms. Each consumes power but is half empty. By consolidating into one large refrigerator, you save electricity, manage food better, and free up space.  </p>"},{"location":"phase-1/dc-infra/08_Datacenter_Servers/","title":"Datacenter Servers","text":""},{"location":"phase-1/dc-infra/08_Datacenter_Servers/#1-what-is-it","title":"1. What is it?","text":"<p>Servers are the core computing machines inside a data center. They process data, run applications, host websites, and provide storage and network services. Without servers, a data center is just an empty building with cables.  </p>"},{"location":"phase-1/dc-infra/08_Datacenter_Servers/#2-theoretical-definition","title":"2. Theoretical Definition","text":"<p>A server is a specialized computer system designed to provide services, applications, or resources to other systems (clients) over a network. They are optimized for performance, reliability, and scalability, unlike personal desktops.  </p> <p>Types of servers commonly found in data centers: - Rack Servers \u2192 Standalone units mounted in racks (1U, 2U form factors). - Blade Servers \u2192 Slim modules that fit into a chassis, sharing power and cooling. - Tower Servers \u2192 Standalone cabinet-like servers (less common in large data centers). - Hyperconverged Servers \u2192 Combine compute + storage + networking in a single appliance.  </p>"},{"location":"phase-1/dc-infra/08_Datacenter_Servers/#3-why-is-it-important","title":"3. Why is it important?","text":"<ul> <li>Run Business-Critical Applications \u2192 Databases, ERP systems, web applications.  </li> <li>Store and Process Data \u2192 From customer records to analytics workloads.  </li> <li>Enable Virtualization \u2192 Multiple virtual machines (VMs) can run on one physical server.  </li> <li>Support Cloud Infrastructure \u2192 Cloud providers rely on large clusters of powerful servers.  </li> </ul>"},{"location":"phase-1/dc-infra/08_Datacenter_Servers/#4-how-is-it-planned","title":"4. How is it planned?","text":"<ul> <li>Server Form Factor \u2192 Decide whether to use rack, blade, or hyperconverged depending on density and workload.  </li> <li>Performance Requirements \u2192 CPU (cores, speed), RAM (capacity), and storage type (SSD/HDD).  </li> <li>Redundancy \u2192 N+1 design (extra server capacity to handle failures).  </li> <li>Cooling &amp; Power \u2192 Ensure sufficient power supply and airflow for high-density racks.  </li> <li>Scalability \u2192 Design clusters that can scale horizontally by adding more servers.  </li> </ul>"},{"location":"phase-1/dc-infra/08_Datacenter_Servers/#5-impact-if-not-done-correctly","title":"5. Impact if not done correctly","text":"<ul> <li>Underpowered Servers \u2192 Slow applications, poor user experience.  </li> <li>Overprovisioned Servers \u2192 Wasted costs on unused capacity.  </li> <li>Single Points of Failure \u2192 Outage if redundancy isn\u2019t planned.  </li> <li>Inefficient Layout \u2192 Poor cooling and higher electricity bills.  </li> </ul>"},{"location":"phase-1/dc-infra/08_Datacenter_Servers/#6-real-world-example","title":"6. Real World Example","text":"<ul> <li>Google designs custom servers optimized for performance and energy efficiency.  </li> <li>Facebook\u2019s Open Compute Project (OCP) builds open-standard servers for scalability and lower costs.  </li> <li>A bank\u2019s data center may use blade servers for transaction processing, while a cloud provider like AWS uses hyperconverged and rack servers in clusters.  </li> </ul> <p>\ud83d\udc49 Easy Analogy: Think of servers as the kitchen of a restaurant: - They prepare (process) and serve (deliver) food (data/applications). - The type of kitchen setup (rack, blade, hyperconverged) depends on the restaurant\u2019s size and demand.  </p>"},{"location":"phase-1/dc-infra/09_Server_Capacity_Planning/","title":"Server Capacity Planning","text":""},{"location":"phase-1/dc-infra/09_Server_Capacity_Planning/#1-what-is-it","title":"1. What is it?","text":"<p>Server Capacity Planning is the process of making sure your servers have the right amount of resources (CPU, memory, storage, and network bandwidth) to handle current workloads and future growth. It prevents both under-provisioning (not enough resources, causing downtime) and over-provisioning (too many resources, wasting money).  </p>"},{"location":"phase-1/dc-infra/09_Server_Capacity_Planning/#2-theoretical-definition","title":"2. Theoretical Definition","text":"<p>Capacity planning is a forecasting and resource management practice used to determine the IT infrastructure requirements needed to meet expected demand within defined service levels.  </p> <p>Key parameters include: - CPU &amp; Processing Power \u2192 Handles applications and users. - RAM (Memory) \u2192 Supports multitasking, virtualization, and performance. - Storage \u2192 Ensures enough space for data, backups, and future expansion. - Network Bandwidth \u2192 Handles incoming/outgoing data traffic.  </p>"},{"location":"phase-1/dc-infra/09_Server_Capacity_Planning/#3-why-is-it-important","title":"3. Why is it important?","text":"<ul> <li>Avoids Downtime \u2192 Ensures systems don\u2019t crash under peak load.  </li> <li>Optimizes Cost \u2192 Prevents buying more hardware than necessary.  </li> <li>Improves Performance \u2192 Applications run smoothly with right-sized resources.  </li> <li>Supports Scalability \u2192 Plans for business growth and seasonal traffic spikes.  </li> <li>Meets SLAs \u2192 Keeps response times and uptime commitments.  </li> </ul>"},{"location":"phase-1/dc-infra/09_Server_Capacity_Planning/#4-how-is-it-planned","title":"4. How is it planned?","text":"<p>Steps in server capacity planning:  </p> <ol> <li> <p>Measure Current Usage </p> <ul> <li>Collect utilization metrics (CPU %, memory usage, storage I/O).  </li> <li>Use monitoring tools like Nagios, Prometheus, or vCenter.  </li> </ul> </li> <li> <p>Forecast Future Needs </p> <ul> <li>Predict growth (new apps, more users, higher traffic).  </li> <li>Factor in peak usage patterns (e.g., end-of-month billing, holiday shopping).  </li> </ul> </li> <li> <p>Set Performance Targets </p> <ul> <li>Define acceptable latency, response times, and uptime goals.  </li> </ul> </li> <li> <p>Plan for Redundancy </p> <ul> <li>Use N+1 server design (one extra server for every N in production).  </li> </ul> </li> <li> <p>Implement and Review </p> <ul> <li>Deploy resources.  </li> <li>Continuously review and adjust capacity plans.  </li> </ul> </li> </ol>"},{"location":"phase-1/dc-infra/09_Server_Capacity_Planning/#5-impact-if-not-done-correctly","title":"5. Impact if not done correctly","text":"<ul> <li>Under-Provisioning \u2192 Servers crash during peak loads, leading to downtime.  </li> <li>Over-Provisioning \u2192 Wasted money on unused servers and electricity.  </li> <li>Inaccurate Forecasting \u2192 SLA violations and poor customer experience.  </li> <li>No Redundancy \u2192 A single server failure may bring down critical services.  </li> </ul>"},{"location":"phase-1/dc-infra/09_Server_Capacity_Planning/#6-real-world-example","title":"6. Real World Example","text":"<ul> <li>Netflix uses predictive analytics to scale servers ahead of peak streaming hours (like evenings and weekends).  </li> <li>E-commerce companies like Amazon add extra capacity during events like Black Friday sales.  </li> <li>A bank may forecast server needs for end-of-quarter financial reporting to handle huge transaction spikes.  </li> </ul> <p>\ud83d\udc49 Easy Analogy: Server capacity planning is like planning seats on an airplane: - Too few seats \u2192 passengers left behind (downtime). - Too many empty seats \u2192 wasted fuel and money (overprovisioning). The goal is to have the right number of seats for the expected passengers.  </p>"},{"location":"phase-1/dc-infra/10_Disaster_Recovery/","title":"Disaster Recovery (DR)","text":""},{"location":"phase-1/dc-infra/10_Disaster_Recovery/#1-what-is-it","title":"1. What is it?","text":"<p>Disaster Recovery (DR) is the set of strategies, tools, and processes that ensure IT systems and data can be restored quickly after a disaster\u2014whether it\u2019s a cyberattack, hardware failure, natural disaster, or human error. It\u2019s about getting business back online with minimal disruption.  </p>"},{"location":"phase-1/dc-infra/10_Disaster_Recovery/#2-theoretical-definition","title":"2. Theoretical Definition","text":"<p>Disaster Recovery is a subset of Business Continuity Planning (BCP) focused specifically on restoring IT systems and data.  </p> <p>Key terms: - RTO (Recovery Time Objective) \u2192 Maximum acceptable time to restore systems after a failure. - RPO (Recovery Point Objective) \u2192 Maximum acceptable amount of data loss measured in time (e.g., last 15 minutes).  </p>"},{"location":"phase-1/dc-infra/10_Disaster_Recovery/#3-why-is-it-important","title":"3. Why is it important?","text":"<ul> <li>Prevents extended business downtime.  </li> <li>Protects against catastrophic data loss.  </li> <li>Ensures compliance with industry standards (e.g., PCI-DSS, HIPAA).  </li> <li>Maintains customer trust and brand reputation.  </li> <li>Avoids financial penalties due to SLA violations.  </li> </ul>"},{"location":"phase-1/dc-infra/10_Disaster_Recovery/#4-how-is-it-planned","title":"4. How is it planned?","text":"<ul> <li>Risk Assessment </li> <li> <p>Identify possible threats: fire, flood, ransomware, hardware failure.  </p> </li> <li> <p>Define Critical Systems </p> </li> <li> <p>Prioritize applications and data that must be recovered first.  </p> </li> <li> <p>Backup &amp; Replication </p> </li> <li>On-site backups, off-site backups, and cloud-based replication.  </li> <li> <p>Use snapshots and continuous data replication for critical workloads.  </p> </li> <li> <p>Failover Strategies </p> </li> <li>Hot Site \u2192 Fully operational backup site, ready instantly.  </li> <li>Warm Site \u2192 Partially prepared site, takes hours to activate.  </li> <li> <p>Cold Site \u2192 Empty site with space/power, requires manual setup.  </p> </li> <li> <p>Testing &amp; Drills </p> </li> <li>Regularly simulate disasters to ensure recovery plans actually work.  </li> </ul> <p></p>"},{"location":"phase-1/dc-infra/10_Disaster_Recovery/#5-impact-if-not-done-correctly","title":"5. Impact if not done correctly","text":"<ul> <li>Extended downtime \u2192 business halts, lost revenue.  </li> <li>Permanent data loss if backups fail.  </li> <li>SLA violations and regulatory fines.  </li> <li>Loss of customer confidence and market share.  </li> </ul>"},{"location":"phase-1/dc-infra/10_Disaster_Recovery/#6-real-world-example","title":"6. Real World Example","text":"<ul> <li>Delta Airlines (2016) experienced a data center power failure, grounding flights worldwide for days, costing ~$150M.  </li> <li>Sony Pictures (2014) cyberattack caused massive data loss and system outages.  </li> <li>AWS provides customers with DR services using multiple regions and availability zones for failover.  </li> </ul> <p>\ud83d\udc49 Easy Analogy: Disaster Recovery is like having a spare tire in your car: - If you get a flat (server crash), the spare lets you keep going. - Without it, you\u2019re stranded until help arrives (business downtime).  </p>"},{"location":"phase-1/dc-infra/11_DataCenter_Security_Guidelines/","title":"Data Center Security Guidelines","text":""},{"location":"phase-1/dc-infra/11_DataCenter_Security_Guidelines/#1-what-is-it","title":"1. What is it?","text":"<p>Data Center Security Guidelines are a set of best practices, standards, and policies that ensure the physical and logical security of a data center. They provide a framework for protecting infrastructure, applications, and data from threats, breaches, and failures.  </p>"},{"location":"phase-1/dc-infra/11_DataCenter_Security_Guidelines/#2-theoretical-definition","title":"2. Theoretical Definition","text":"<p>Security guidelines are documented controls and procedures based on international standards such as: - ISO/IEC 27001 \u2013 Information Security Management. - NIST SP 800-53 \u2013 Security and Privacy Controls. - PCI-DSS \u2013 Payment Card Industry Data Security Standard.  </p> <p>They define how to protect physical facilities, IT systems, and sensitive data in a structured way.  </p>"},{"location":"phase-1/dc-infra/11_DataCenter_Security_Guidelines/#3-why-is-it-important","title":"3. Why is it important?","text":"<ul> <li>Ensures compliance with regulatory requirements.  </li> <li>Reduces risks of breaches, downtime, and insider threats.  </li> <li>Builds trust with customers by safeguarding data.  </li> <li>Creates a repeatable, auditable process for security operations.  </li> <li>Helps organizations pass third-party audits and certifications.  </li> </ul>"},{"location":"phase-1/dc-infra/11_DataCenter_Security_Guidelines/#4-how-is-it-planned","title":"4. How is it planned?","text":"<p>Security guidelines usually cover multiple layers:  </p> <ul> <li> <p>Physical Security </p> <ul> <li>Multi-layer access (perimeter \u2192 building \u2192 server room).  </li> <li>CCTV surveillance, biometric authentication, man-traps.  </li> <li>Fire detection and suppression systems.  </li> </ul> </li> <li> <p>Logical Security </p> <ul> <li>Role-Based Access Control (RBAC).  </li> <li>Multi-Factor Authentication (MFA).  </li> <li>Encryption (data at rest and in transit).  </li> <li>Secure network segmentation (DMZ, VLANs).  </li> </ul> </li> <li> <p>Operational Security </p> <ul> <li>Patch management and vulnerability scanning.  </li> <li>Logging and monitoring of user activities.  </li> <li>Regular penetration testing and audits.  </li> </ul> </li> <li> <p>Compliance and Policy Enforcement </p> <ul> <li>Documented policies for security training.  </li> <li>Incident response plans.  </li> <li>Vendor risk assessments.  </li> </ul> </li> </ul>"},{"location":"phase-1/dc-infra/11_DataCenter_Security_Guidelines/#5-impact-if-not-done-correctly","title":"5. Impact if not done correctly","text":"<ul> <li>Non-compliance \u2192 heavy regulatory fines.  </li> <li>Security breaches leading to data theft.  </li> <li>Extended downtime due to poor incident response.  </li> <li>Loss of business reputation and customer trust.  </li> </ul>"},{"location":"phase-1/dc-infra/11_DataCenter_Security_Guidelines/#6-real-world-example","title":"6. Real World Example","text":"<ul> <li>Equinix Data Centers follow strict ISO 27001, SOC 2, and PCI-DSS standards across global facilities.  </li> <li>Google Cloud implements layered security from custom hardware to data encryption.  </li> <li>Target\u2019s 2013 data breach (from weak third-party access) highlighted the importance of strong security guidelines.  </li> </ul> <p>\ud83d\udc49 Easy Analogy: Security guidelines are like a rulebook for running a safe city: - Police (physical security). - Digital ID checks (logical access). - City bylaws and courts (compliance policies). Together, they ensure order and safety in the city (data center).  </p>"},{"location":"phase-1/dc-infra/12_Internet_Security_Guidelines/","title":"Internet Security and Guidelines","text":""},{"location":"phase-1/dc-infra/12_Internet_Security_Guidelines/#1-what-is-it","title":"1. What is it?","text":"<p>Internet Security refers to the practices, technologies, and policies used to protect systems, users, and data while connected to the internet. Internet Security Guidelines are the recommended best practices and frameworks that organizations follow to implement effective protections.  </p> <p>Together, they form the foundation for safe, reliable, and secure internet operations in a data center.  </p>"},{"location":"phase-1/dc-infra/12_Internet_Security_Guidelines/#2-theoretical-definition","title":"2. Theoretical Definition","text":"<ul> <li>Internet Security \u2192 Encompasses tools (firewalls, IDS/IPS, VPNs), processes (patching, monitoring), and policies (acceptable use, access control) that secure internet-facing systems.  </li> <li>Guidelines \u2192 Documented rules and standards based on frameworks like:  </li> <li>ISO/IEC 27033 \u2013 Network Security.  </li> <li>NIST Cybersecurity Framework.  </li> <li>OWASP \u2013 Open Web Application Security Project.  </li> </ul>"},{"location":"phase-1/dc-infra/12_Internet_Security_Guidelines/#3-why-is-it-important","title":"3. Why is it important?","text":"<ul> <li>Protects against cyber threats like phishing, malware, and ransomware.  </li> <li>Ensures safe online transactions (e-commerce, banking).  </li> <li>Prevents unauthorized access to data center resources.  </li> <li>Helps meet compliance requirements (GDPR, PCI-DSS).  </li> <li>Builds customer trust in digital services.  </li> </ul>"},{"location":"phase-1/dc-infra/12_Internet_Security_Guidelines/#4-how-is-it-planned","title":"4. How is it planned?","text":"<p>Key practices in Internet Security Guidelines:  </p> <ul> <li> <p>Perimeter Security </p> <ul> <li>Firewalls to filter traffic.  </li> <li>Intrusion Detection/Prevention Systems (IDS/IPS).  </li> <li>Web Application Firewalls (WAF).  </li> </ul> </li> <li> <p>Data Protection </p> <ul> <li>Use of SSL/TLS encryption for data in transit.  </li> <li>Encrypt sensitive data at rest.  </li> </ul> </li> <li> <p>Access Control </p> <ul> <li>Strong passwords and multi-factor authentication (MFA).  </li> <li>VPNs for remote access.  </li> <li>Least-privilege principle for user accounts.  </li> </ul> </li> <li> <p>Monitoring &amp; Response </p> <ul> <li>Security Information and Event Management (SIEM).  </li> <li>Real-time log analysis and anomaly detection.  </li> <li>Incident response plans.  </li> </ul> </li> <li> <p>Patch Management </p> <ul> <li>Regular software updates to prevent exploitation.  </li> </ul> </li> <li> <p>User Awareness </p> <ul> <li>Training to recognize phishing and social engineering attacks.  </li> </ul> </li> </ul>"},{"location":"phase-1/dc-infra/12_Internet_Security_Guidelines/#5-impact-if-not-done-correctly","title":"5. Impact if not done correctly","text":"<ul> <li>Data Breaches \u2192 Confidential customer or business data stolen.  </li> <li>Financial Losses \u2192 Fraud, ransomware payments, regulatory fines.  </li> <li>Downtime \u2192 DDoS attacks bringing systems offline.  </li> <li>Reputation Damage \u2192 Customers lose trust in the organization.  </li> </ul>"},{"location":"phase-1/dc-infra/12_Internet_Security_Guidelines/#6-real-world-example","title":"6. Real World Example","text":"<ul> <li>Target (2013 breach) \u2192 Hackers stole 40 million credit card numbers due to weak internet-facing security.  </li> <li>Sony PlayStation Network (2011 hack) \u2192 Took weeks to recover, exposing data of 77 million users.  </li> <li>Equifax (2017 breach) \u2192 Unpatched vulnerability led to massive data theft.  </li> <li>Google enforces HTTPS encryption across all its services as part of internet security best practices.  </li> </ul> <p>\ud83d\udc49 Easy Analogy: Think of internet security like securing your home Wi-Fi and devices: - Firewalls = The lock on your front door. - Encryption = Keeping your conversations private. - Guidelines = The house rules you set for everyone using the network. - Without them, anyone could walk in, steal data, or disrupt your digital life.  </p>"},{"location":"phase-1/dc-infra/13_Source_Security_Issues/","title":"Source Security Issues","text":""},{"location":"phase-1/dc-infra/13_Source_Security_Issues/#1-what-is-it","title":"1. What is it?","text":"<p>Source Security Issues are risks that originate from within the organization or through external sources such as vendors, contractors, or compromised software components. They are often harder to detect because they come from trusted sources.  </p>"},{"location":"phase-1/dc-infra/13_Source_Security_Issues/#2-theoretical-definition","title":"2. Theoretical Definition","text":"<p>Source security issues are vulnerabilities or threats that arise from: - Insider Threats \u2192 Employees or contractors misusing access intentionally or accidentally. - Supply Chain Risks \u2192 Malicious code, compromised hardware, or weak vendor security. - Unverified Sources \u2192 Downloading software, scripts, or updates from untrusted origins.  </p>"},{"location":"phase-1/dc-infra/13_Source_Security_Issues/#3-why-is-it-important","title":"3. Why is it important?","text":"<ul> <li>High Impact \u2192 Attackers can bypass defenses since the source is trusted.  </li> <li>Difficult Detection \u2192 Malicious activity often looks legitimate.  </li> <li>Regulatory Impact \u2192 Violations if sensitive data is leaked.  </li> <li>Business Risk \u2192 Can lead to financial loss and reputational damage.  </li> </ul>"},{"location":"phase-1/dc-infra/13_Source_Security_Issues/#4-how-is-it-planned","title":"4. How is it planned?","text":"<p>Strategies to mitigate source security issues: - Vendor Risk Management</p> <pre><code>- Conduct security audits of third-party vendors.  \n- Use contracts with security clauses (SLAs, compliance requirements).\n</code></pre> <ul> <li> <p>Access Control </p> <ul> <li>Implement the principle of least privilege.  </li> <li>Monitor privileged accounts closely.  </li> </ul> </li> <li> <p>Software Integrity </p> <ul> <li>Only use signed and verified software updates.  </li> <li>Conduct code reviews and vulnerability scans.  </li> </ul> </li> <li> <p>Insider Threat Detection </p> <ul> <li>Monitor logs for unusual user behavior.  </li> <li>Use tools like UEBA (User and Entity Behavior Analytics).  </li> </ul> </li> </ul>"},{"location":"phase-1/dc-infra/13_Source_Security_Issues/#5-impact-if-not-done-correctly","title":"5. Impact if not done correctly","text":"<ul> <li>Supply Chain Compromise \u2192 Attackers inject malware into trusted software updates.  </li> <li>Insider Abuse \u2192 Employees leaking or stealing data.  </li> <li>Malware Propagation \u2192 Through downloads from unverified sources.  </li> <li>Loss of Customer Trust \u2192 Customers lose confidence in your ability to safeguard data.  </li> </ul>"},{"location":"phase-1/dc-infra/13_Source_Security_Issues/#6-real-world-example","title":"6. Real World Example","text":"<ul> <li>SolarWinds Attack (2020) \u2192 Hackers compromised a trusted software update, impacting thousands of organizations worldwide.  </li> <li>Edward Snowden (2013) \u2192 Insider with high-level access leaked classified NSA documents.  </li> <li>Target Breach (2013) \u2192 Attackers gained entry through a third-party HVAC vendor\u2019s compromised credentials.  </li> </ul> <p>\ud83d\udc49 Easy Analogy: Source security issues are like someone you trust bringing a Trojan horse inside your home. - Outsiders may be locked out (firewalls), but insiders or trusted partners can unintentionally (or maliciously) open the door from within.  </p>"},{"location":"phase-1/dc-infra/14_Best_Practices_System_Administration/","title":"Best Practices for System Administration","text":""},{"location":"phase-1/dc-infra/14_Best_Practices_System_Administration/#1-what-is-it","title":"1. What is it?","text":"<p>System Administration is the daily practice of managing and maintaining servers, networks, and IT infrastructure. Best Practices are the proven methods that help system administrators ensure security, efficiency, and reliability in operations.  </p>"},{"location":"phase-1/dc-infra/14_Best_Practices_System_Administration/#2-theoretical-definition","title":"2. Theoretical Definition","text":"<p>Best practices in system administration are standardized operational, security, and management routines that ensure IT systems remain stable, secure, and scalable. They align with frameworks such as ITIL (Information Technology Infrastructure Library) and NIST guidelines.  </p>"},{"location":"phase-1/dc-infra/14_Best_Practices_System_Administration/#3-why-is-it-important","title":"3. Why is it important?","text":"<ul> <li>Ensures systems run reliably with minimal downtime.  </li> <li>Improves security posture against cyber threats.  </li> <li>Makes IT operations predictable and auditable.  </li> <li>Reduces human errors through standardized procedures.  </li> <li>Helps organizations comply with industry regulations.  </li> </ul>"},{"location":"phase-1/dc-infra/14_Best_Practices_System_Administration/#4-how-is-it-planned","title":"4. How is it planned?","text":"<p>Some key best practices:  </p> <ul> <li> <p>Regular Patching &amp; Updates </p> <ul> <li>Keep operating systems and applications updated.  </li> <li>Apply security patches promptly.  </li> </ul> </li> <li> <p>Backup &amp; Recovery </p> <ul> <li>Automate daily backups.  </li> <li>Test restores regularly.  </li> </ul> </li> <li> <p>Monitoring &amp; Logging </p> <ul> <li>Use monitoring tools (Nagios, Prometheus, Zabbix).  </li> <li>Review system logs for anomalies.  </li> </ul> </li> <li> <p>Access Control</p> <ul> <li>Enforce the principle of least privilege.  </li> <li>Implement strong passwords and MFA.  </li> </ul> </li> <li> <p>Documentation </p> <ul> <li>Maintain clear documentation of system configurations.  </li> <li>Ensure knowledge sharing within the IT team.  </li> </ul> </li> <li> <p>Change Management</p> <ul> <li>Use structured processes to introduce changes.  </li> <li>Test changes in staging before production.  </li> </ul> </li> <li> <p>Security Hygiene </p> <ul> <li>Disable unused services and ports.  </li> <li>Regular vulnerability scans and penetration testing.  </li> </ul> </li> </ul>"},{"location":"phase-1/dc-infra/14_Best_Practices_System_Administration/#5-impact-if-not-done-correctly","title":"5. Impact if not done correctly","text":"<ul> <li>Systems become vulnerable to attacks and outages.  </li> <li>Longer downtimes due to poor troubleshooting.  </li> <li>Compliance failures leading to fines.  </li> <li>IT staff waste time reinventing solutions.  </li> </ul>"},{"location":"phase-1/dc-infra/14_Best_Practices_System_Administration/#6-real-world-example","title":"6. Real World Example","text":"<ul> <li>NASA enforces strict sysadmin policies after past breaches caused by weak practices.  </li> <li>Banks implement rigorous patching and logging routines to comply with RBI and global regulations.  </li> <li>Tech companies like Google enforce standardized automation and monitoring to minimize human error.  </li> </ul> <p>\ud83d\udc49 Easy Analogy: Best practices for system administration are like regular car maintenance: - Oil changes (patching). - Brake checks (monitoring). - Keeping logs of service history (documentation). If skipped, the car may still run, but eventually, it breaks down in costly and dangerous ways.  </p>"},{"location":"phase-1/dc-infra/15_System_Administration_Automation/","title":"System Administration Work Automation","text":""},{"location":"phase-1/dc-infra/15_System_Administration_Automation/#1-what-is-it","title":"1. What is it?","text":"<p>System Administration Work Automation is the practice of using scripts, tools, and platforms to perform routine IT tasks automatically instead of manually. It reduces human error, saves time, and ensures consistency across large infrastructures.  </p>"},{"location":"phase-1/dc-infra/15_System_Administration_Automation/#2-theoretical-definition","title":"2. Theoretical Definition","text":"<p>Automation in system administration refers to the application of Infrastructure as Code (IaC), configuration management, and orchestration tools to replace repetitive manual processes.  </p> <p>Common automation tools: - Ansible, Puppet, Chef, SaltStack \u2192 Configuration management. - Terraform \u2192 Infrastructure as Code for cloud resources. - Bash/PowerShell Scripts \u2192 Simple automation of repetitive commands. - CI/CD Pipelines (Jenkins, GitHub Actions) \u2192 Automated deployment and updates.  </p>"},{"location":"phase-1/dc-infra/15_System_Administration_Automation/#3-why-is-it-important","title":"3. Why is it important?","text":"<ul> <li>Reduces Human Error \u2192 Automated scripts follow exact steps every time.  </li> <li>Saves Time \u2192 Hundreds of servers can be updated at once.  </li> <li>Consistency \u2192 Standardized configurations across environments.  </li> <li>Scalability \u2192 Enables DevOps practices like auto-scaling.  </li> <li>Reliability \u2192 Tasks are repeatable and can be scheduled without manual intervention.  </li> </ul>"},{"location":"phase-1/dc-infra/15_System_Administration_Automation/#4-how-is-it-planned","title":"4. How is it planned?","text":"<p>Steps to implement automation: 1. Identify Repetitive Tasks \u2192 User provisioning, patching, backups, log rotation. 2. Select Tools \u2192 Choose scripting or orchestration tools suitable for your environment. 3. Write &amp; Test Automation Scripts \u2192 Validate in staging before production. 4. Integrate with CI/CD Pipelines \u2192 Automate deployment and rollback. 5. Monitor &amp; Improve \u2192 Track automation results and refine as needed.  </p>"},{"location":"phase-1/dc-infra/15_System_Administration_Automation/#5-impact-if-not-done-correctly","title":"5. Impact if not done correctly","text":"<ul> <li>Misconfigurations at Scale \u2192 If the script has an error, it can break hundreds of servers.  </li> <li>Security Risks \u2192 Poorly managed automation may expose credentials.  </li> <li>Over-reliance \u2192 Teams may lose manual troubleshooting skills.  </li> <li>Lack of Documentation \u2192 Automated processes must still be documented for audit and recovery.  </li> </ul>"},{"location":"phase-1/dc-infra/15_System_Administration_Automation/#6-real-world-example","title":"6. Real World Example","text":"<ul> <li>Facebook\u2019s SRE teams automate server provisioning and patching at hyperscale.  </li> <li>Netflix uses automation for deploying services globally across AWS regions.  </li> <li>Banks automate compliance reporting and routine system checks.  </li> </ul> <p>\ud83d\udc49 Easy Analogy: System administration automation is like using a dishwasher in a busy restaurant: - Instead of washing each plate by hand (manual work), the dishwasher (automation) handles it consistently and faster. - If programmed incorrectly (bad script), all plates come out dirty or broken\u2014so planning and monitoring are critical.  </p>"},{"location":"phase-2/01_Overview/","title":"Phase 2: Virtualization, Cloud, and Modern Data Center Management","text":""},{"location":"phase-2/01_Overview/#overview","title":"Overview","text":"<p>In this phase, we move beyond physical infrastructure to explore virtualization, cloud technologies, and modern approaches to data center operations. Students will learn how to abstract, pool, and manage resources efficiently while ensuring scalability, availability, and automation.  </p> <p>This phase sets the foundation for understanding how today\u2019s IT infrastructure is built, operated, and optimized in enterprises.</p>"},{"location":"phase-2/01_Overview/#topics-covered","title":"Topics Covered","text":""},{"location":"phase-2/01_Overview/#1-virtualization-foundations","title":"1. Virtualization Foundations","text":"<ul> <li>Introduction to virtualization concepts  </li> <li>Types of virtualization: Type 1 (bare-metal) and Type 2 (hosted)  </li> <li>Advanced techniques: hardware virtualization, para-virtualization, cloning, snapshots, and templates  </li> <li>Operating system-level virtualization  </li> </ul>"},{"location":"phase-2/01_Overview/#2-high-availability-storage","title":"2. High Availability &amp; Storage","text":"<ul> <li>Cluster architecture and requirements  </li> <li>Configuring and managing a SAN (using FreeNAS)  </li> <li>Leveraging SANs for high availability  </li> <li>ZFS volume management  </li> <li>IP-based storage communication  </li> <li>Object storage services  </li> </ul>"},{"location":"phase-2/01_Overview/#3-cloud-computing-essentials","title":"3. Cloud Computing Essentials","text":"<ul> <li>Introduction to cloud computing  </li> <li>Cloud architecture and deployment models: Public, Private, Hybrid  </li> <li>Service models: IaaS, PaaS, SaaS  </li> <li>Key services: compute, storage, databases, developer tools, security, and more  </li> <li>Cloud SPI model and security (SLA and IAM)  </li> <li>Cloud development best practices  </li> <li>Introduction to OpenStack  </li> <li>Hyper-Converged Infrastructure (HCI) and its comparison with cloud  </li> <li>Software-Defined Networking (SDN)  </li> <li>Cloud API integration  </li> </ul>"},{"location":"phase-2/01_Overview/#4-data-center-disaster-recovery-dcdr","title":"4. Data Center &amp; Disaster Recovery (DC/DR)","text":"<ul> <li>Migration of workloads and servers to the cloud  </li> <li>DC/DR migration strategies  </li> <li>Storage synchronization across DC/DR sites  </li> <li>Bootstrapping configuration management tools (Chef/Puppet)  </li> </ul>"},{"location":"phase-2/01_Overview/#5-cloud-operations-monitoring","title":"5. Cloud Operations &amp; Monitoring","text":"<ul> <li>Centralized logging and observability  </li> <li>Monitoring with Nagios and Prometheus (next-gen NMS)  </li> <li>Identifying and resolving performance bottlenecks  </li> <li>Auto-scaling, auto-rebuilding, and auto-healing of cloud instances  </li> <li>Techniques for updating servers without downtime  </li> </ul>"},{"location":"phase-2/01_Overview/#6-case-study","title":"6. Case Study","text":"<ul> <li>Real-world Cloud-Enabled Data Center design and operations case study  </li> </ul>"},{"location":"phase-2/01_Overview/#learning-outcome","title":"Learning Outcome","text":"<p>By the end of this phase, students will:</p> <ul> <li>Understand virtualization and its role in modern IT infrastructure.  </li> <li>Configure and manage storage and clusters for high availability.  </li> <li>Deploy and manage workloads on cloud platforms securely and efficiently.  </li> <li>Explore disaster recovery strategies for enterprise continuity.  </li> <li>Implement monitoring, scaling, and automation in cloud environments.  </li> <li>Analyze a real-world case study to connect theory with practice.  </li> </ul>"},{"location":"phase-2/cloud-computing/01_cloud_computing/","title":"Cloud Computing","text":""},{"location":"phase-2/cloud-computing/01_cloud_computing/#lets-beign-with-cloud-computing","title":"Let's beign with Cloud Computing","text":""},{"location":"phase-2/cloud-computing/02_hci/","title":"Hyper-Converged Infrastructure (HCI)","text":""},{"location":"phase-2/cloud-computing/02_hci/#what-is-hci","title":"What is HCI?","text":""},{"location":"phase-2/cloud-computing/02_hci/#what-is-it","title":"What is it?","text":"<p>Hyper-Converged Infrastructure (HCI) is an IT architecture that integrates compute, storage, and networking into a single software-driven system. Unlike traditional data centers where these components are managed separately, HCI combines them into a unified, virtualized environment managed through a single platform.</p> <p>In simple terms: Instead of having separate servers, storage arrays, and networking gear, HCI puts everything into one cluster of servers, managed centrally, and optimized by software.</p>"},{"location":"phase-2/cloud-computing/02_hci/#theoretical-definition","title":"Theoretical Definition","text":"<p>HCI is a software-defined IT infrastructure that tightly integrates compute (virtualized servers), storage (software-defined storage), and networking (virtual switches and SDN) on commodity x86 hardware, with centralized management.</p> <p>Key characteristics:</p> <ul> <li>Software-defined: The intelligence is in the software, not the hardware.</li> <li>Integrated management: A single dashboard to manage compute, storage, and networking.</li> <li>Scale-out design: Add more nodes to increase capacity/performance.</li> </ul>"},{"location":"phase-2/cloud-computing/02_hci/#evolution-from-traditional-infrastructure-to-hci","title":"Evolution: From Traditional Infrastructure to HCI","text":"<ul> <li> <p>Traditional Infrastructure (3-tier architecture):</p> <ul> <li>Separate compute (servers), storage (SAN/NAS), and networking (switches).</li> <li>Complex to deploy and manage.</li> <li>Expensive proprietary hardware.</li> </ul> </li> <li> <p>Converged Infrastructure (CI):</p> <ul> <li>Bundled servers, storage, and networking in pre-validated racks.</li> <li>Still separate layers, but tested together.</li> </ul> </li> <li> <p>Hyper-Converged Infrastructure (HCI):</p> <ul> <li>Compute, storage, networking all in software.</li> <li>Runs on commodity servers.</li> <li>Managed from one platform.</li> </ul> </li> </ul>"},{"location":"phase-2/cloud-computing/02_hci/#hci-vs-cloud-computing","title":"HCI vs Cloud Computing","text":"Feature Hyper-Converged Infrastructure (HCI) Cloud Computing Definition On-premises system integrating compute, storage, and networking in one platform Delivery of IT services (compute, storage, apps) over the internet Deployment Runs on physical hardware in your data center Runs on shared infrastructure owned by cloud provider Ownership Owned and managed by the organization Owned and managed by provider (AWS, Azure, GCP) Scalability Scale-out by adding nodes Virtually unlimited scalability across regions Management Centralized, software-defined, local control Provider-managed, accessed via APIs/portals Cost Model Capital expense (CapEx) + ongoing maintenance Operational expense (OpEx), pay-as-you-go Use Case Private clouds, VDI, on-prem workloads Public-facing apps, global scalability <p>\ud83d\udc49 Think of HCI as a private cloud enabler \u2014 it brings cloud-like agility to on-premises infrastructure.</p>"},{"location":"phase-2/cloud-computing/02_hci/#hci-architecture","title":"HCI Architecture","text":""},{"location":"phase-2/cloud-computing/02_hci/#core-components","title":"Core Components","text":"<ol> <li> <p>Compute </p> <ul> <li>Runs on commodity x86 servers with hypervisors (VMware ESXi, Hyper-V, KVM).</li> <li>Virtual machines (VMs) or containers run applications.</li> </ul> </li> <li> <p>Storage (SDS \u2013 Software-Defined Storage) </p> <ul> <li>Local disks (SSD/HDD) across nodes are pooled into a distributed storage system.</li> <li>Features: deduplication, compression, snapshots, replication.</li> </ul> </li> <li> <p>Networking (SDN \u2013 Software-Defined Networking) </p> <ul> <li>Virtual networking inside the cluster.</li> <li>Integration with physical switches for external connectivity.</li> </ul> </li> <li> <p>Management Layer </p> <ul> <li>Centralized dashboard to provision, monitor, and scale resources.</li> <li>API-driven for automation.</li> </ul> </li> </ol>"},{"location":"phase-2/cloud-computing/02_hci/#key-benefits-of-hci","title":"Key Benefits of HCI","text":"<ul> <li>Simplicity: Single platform for compute, storage, and networking.</li> <li>Scalability: Add nodes easily as demand grows.</li> <li>Cost Efficiency: Uses commodity hardware instead of expensive SAN/NAS.</li> <li>High Availability: Built-in redundancy and fault tolerance.</li> <li>Cloud-like Agility: Self-service provisioning and automation.</li> <li>Data Services: Snapshots, replication, backup, disaster recovery.</li> </ul>"},{"location":"phase-2/cloud-computing/02_hci/#leading-hci-vendors","title":"Leading HCI Vendors","text":"<ul> <li>VMware vSAN (VMware Cloud Foundation) \u2013 Industry leader, integrates with vSphere.</li> <li>Nutanix \u2013 Pioneer of HCI, software-focused solution.</li> <li>HPE SimpliVity \u2013 Hardware + software appliance.</li> <li>Cisco HyperFlex \u2013 Cisco\u2019s HCI solution with UCS servers.</li> <li>Microsoft Azure Stack HCI \u2013 Hybrid cloud integration with Azure.</li> <li>Dell EMC VxRail \u2013 Joint solution with VMware, popular in enterprises.</li> </ul>"},{"location":"phase-2/cloud-computing/02_hci/#_1","title":"HCI","text":""},{"location":"phase-2/cloud-computing/02_hci/#real-world-use-cases","title":"Real-World Use Cases","text":"<ol> <li> <p>Virtual Desktop Infrastructure (VDI)    HCI simplifies scaling hundreds of virtual desktops for enterprises.</p> </li> <li> <p>Private Cloud Deployment    Organizations use HCI as the foundation for private clouds.</p> </li> <li> <p>Remote &amp; Branch Offices (ROBO)    HCI appliances are compact, easy to deploy, and perfect for branches.</p> </li> <li> <p>Backup &amp; Disaster Recovery    Built-in replication and failover ensure business continuity.</p> </li> <li> <p>Dev/Test Environments    Fast provisioning of isolated environments for developers.</p> </li> </ol>"},{"location":"phase-2/cloud-computing/02_hci/#examples","title":"Examples","text":"<ul> <li>A university uses HCI for hosting e-learning systems and student portals on a private cloud.  </li> <li>A bank runs its core banking applications on Nutanix HCI to reduce reliance on expensive SANs.  </li> <li>An e-commerce company uses VMware vSAN for hybrid cloud workloads, integrating with AWS for burst capacity.  </li> </ul> <p>WoW Tip</p> <p>HCI is often seen as a stepping stone to hybrid cloud. Many enterprises start with HCI in their data centers for agility, then connect it to public clouds like AWS, Azure, or GCP to achieve a true hybrid cloud model.</p>"},{"location":"phase-2/cloud-computing/02_hci/#summary","title":"Summary","text":"<ul> <li>HCI integrates compute, storage, and networking into a single, software-defined platform.  </li> <li>It is simpler, more scalable, and more cost-effective than traditional infrastructure.  </li> <li>While not the same as public cloud, HCI enables cloud-like agility on-premises.  </li> <li>Leading vendors include VMware, Nutanix, HPE, Cisco, and Microsoft.  </li> <li>HCI is widely used for VDI, private cloud, backup/DR, and edge deployments.  </li> </ul>"},{"location":"phase-2/cloud-computing/03_open_stack/","title":"OpenStack: The Open-Source Cloud Platform","text":""},{"location":"phase-2/cloud-computing/03_open_stack/#what-is-openstack","title":"What is OpenStack?","text":""},{"location":"phase-2/cloud-computing/03_open_stack/#what-is-it","title":"What is it?","text":"<p>OpenStack is an open-source cloud computing platform for building and managing private and public clouds. It provides Infrastructure-as-a-Service (IaaS) by pooling compute, storage, and networking resources, all managed through a dashboard (Horizon) or RESTful APIs.</p> <p>In simple terms: OpenStack lets organizations build their own private cloud \u2014 similar to AWS or Azure, but on their own hardware and fully customizable.</p>"},{"location":"phase-2/cloud-computing/03_open_stack/#theoretical-definition","title":"Theoretical Definition","text":"<p>OpenStack is a modular cloud operating system that controls large pools of compute, storage, and networking resources in a data center, managed through a web interface, APIs, or CLI.  </p> <p>It was originally created in 2010 by Rackspace Hosting and NASA and is now maintained by the OpenInfra Foundation.</p>"},{"location":"phase-2/cloud-computing/03_open_stack/#why-openstack-role-in-private-cloud","title":"Why OpenStack? (Role in Private Cloud)","text":""},{"location":"phase-2/cloud-computing/03_open_stack/#key-benefits","title":"Key Benefits","text":"<ul> <li>Open-source: No vendor lock-in, fully customizable.</li> <li>Private Cloud Enabler: Build your own AWS/Azure-like infrastructure inside your data center.</li> <li>Scalable: Supports small labs to large enterprise deployments.</li> <li>Multi-tenancy: Securely isolates workloads for different users/teams.</li> <li>API-driven: Integrates with DevOps and automation tools (Terraform, Ansible, Kubernetes).</li> </ul> <p>\ud83d\udc49 OpenStack is widely used by telecom providers, governments, and enterprises that want cloud agility while retaining control.</p>"},{"location":"phase-2/cloud-computing/03_open_stack/#openstack-core-components","title":"OpenStack Core Components","text":"<p>OpenStack is made of many services, each handling a specific function:</p> <ul> <li>Nova \u2192 Compute service (manages VMs and instances).  </li> <li>Neutron \u2192 Networking (virtual networks, routers, firewalls, SDN integration).  </li> <li>Cinder \u2192 Block Storage (persistent storage for VMs).  </li> <li>Swift \u2192 Object Storage (similar to Amazon S3).  </li> <li>Glance \u2192 Image service (stores VM images and templates).  </li> <li>Keystone \u2192 Identity service (authentication, authorization).  </li> <li>Horizon \u2192 Dashboard (web UI for managing OpenStack).  </li> <li>Heat \u2192 Orchestration (templates for automated cloud deployments).  </li> <li>Ceilometer \u2192 Telemetry (monitoring, billing, usage).  </li> </ul>"},{"location":"phase-2/cloud-computing/03_open_stack/#openstack-vs-public-cloud-awsazure","title":"OpenStack vs Public Cloud (AWS/Azure)","text":"Feature OpenStack (Private Cloud) AWS/Azure (Public Cloud) Ownership Organization-owned and managed Provider-owned and managed Deployment Runs in local data center Runs on provider\u2019s global infrastructure Cost Model CapEx (hardware) + maintenance OpEx (pay-as-you-go) Customization Fully customizable (open-source) Limited to provider\u2019s services Use Case Private cloud, compliance-driven workloads Public-facing apps, global scale <p>\ud83d\udc49 OpenStack is often used as the foundation for private/hybrid clouds, sometimes integrated with AWS, Azure, or GCP for hybrid models.</p>"},{"location":"phase-2/cloud-computing/03_open_stack/#vendors-distributions","title":"Vendors &amp; Distributions","text":"<p>Several companies provide commercial support and customized versions of OpenStack:</p> <ul> <li>Red Hat OpenStack Platform (RHOSP) </li> <li>Canonical\u2019s Charmed OpenStack (Ubuntu-based) </li> <li>Mirantis Cloud Platform </li> <li>SUSE OpenStack Cloud </li> <li>Huawei FusionSphere (OpenStack-based) </li> </ul>"},{"location":"phase-2/cloud-computing/03_open_stack/#real-world-use-cases","title":"Real-World Use Cases","text":"<ul> <li>Telecom Industry (5G Core Networks): OpenStack powers NFV (Network Function Virtualization).  </li> <li>Government Clouds: Secure, private deployments for compliance.  </li> <li>Research &amp; Universities: Flexible, low-cost private clouds for HPC.  </li> <li>Enterprises: Run private clouds for internal apps, dev/test, and regulated workloads.  </li> </ul>"},{"location":"phase-2/cloud-computing/03_open_stack/#example-scenario","title":"Example Scenario","text":"<p>At TechOps Inc., the IT team wants to run a private cloud for developers.  </p> <ul> <li>OpenStack is deployed across 5 servers.  </li> <li>Developers log in to Horizon and spin up VMs within minutes.  </li> <li>Storage is provided by Cinder (block) and Swift (object).  </li> <li>Networking managed by Neutron.  </li> <li>Authentication handled by Keystone.  </li> </ul> <p>This setup allows TechOps Inc. to provide an AWS-like experience internally, without depending on public cloud providers.</p> <p>WOW Tip</p> <p>OpenStack is the second most deployed open-source project in the cloud world after Kubernetes. </p> <p>Fun Fact</p> <p>Many public cloud providers (like OVH, Rackspace, and CityCloud) actually run their services on top of OpenStack.</p>"},{"location":"phase-2/cloud-computing/03_open_stack/#summary","title":"Summary","text":"<ul> <li>OpenStack is an open-source cloud platform for building private and hybrid clouds.  </li> <li>It provides modular services for compute, storage, networking, and management.  </li> <li>Competes with AWS/Azure by offering on-premise cloud capabilities.  </li> <li>Widely adopted in telecom, government, research, and enterprises.  </li> </ul>"},{"location":"phase-2/cloud-computing/04_sdn/","title":"Software-Defined Networking (SDN)","text":""},{"location":"phase-2/cloud-computing/04_sdn/#what-is-sdn","title":"What is SDN?","text":""},{"location":"phase-2/cloud-computing/04_sdn/#what-is-it","title":"What is it?","text":"<p>Software-Defined Networking (SDN) is a modern approach to networking that separates the control plane (decision-making about where traffic goes) from the data plane (the actual movement of traffic). This allows networks to be programmatically managed through software rather than relying only on hardware (switches and routers).</p> <p>In simple terms: Traditional networking = manually configuring each switch/router. SDN = central brain (controller) manages the whole network using software and APIs.</p>"},{"location":"phase-2/cloud-computing/04_sdn/#theoretical-definition","title":"Theoretical Definition","text":"<p>According to the ONF (Open Networking Foundation):  </p> <p>SDN is an architectural approach that enables programmatic management, dynamic provisioning, and automation of networks by decoupling control and forwarding functions.</p> <p>Key concept: - Control Plane \u2192 Centralized in SDN controller (software). - Data Plane \u2192 Distributed across physical devices (switches/routers). - Northbound APIs \u2192 Connect applications to the controller. - Southbound APIs \u2192 Connect controller to devices (e.g., OpenFlow).  </p>"},{"location":"phase-2/cloud-computing/04_sdn/#sdn-architecture","title":"SDN Architecture","text":""},{"location":"phase-2/cloud-computing/04_sdn/#layers","title":"Layers:","text":"<ol> <li> <p>Application Layer </p> <ul> <li>Business applications (firewall policies, load balancing, monitoring).  </li> <li>Communicate with the controller using northbound APIs.  </li> </ul> </li> <li> <p>Control Layer (SDN Controller) </p> <ul> <li>Acts as the brain of SDN.  </li> <li>Examples: OpenDaylight, ONOS, Cisco APIC.  </li> <li>Provides a global view of the network.  </li> </ul> </li> <li> <p>Infrastructure Layer (Data Plane) </p> <ul> <li>Physical or virtual switches and routers.  </li> <li>Forward packets based on controller instructions.  </li> </ul> </li> </ol>"},{"location":"phase-2/cloud-computing/04_sdn/#key-benefits-of-sdn","title":"Key Benefits of SDN","text":"<ul> <li>Centralized Control: One controller manages the whole network.  </li> <li>Programmability: Network behavior is defined in software.  </li> <li>Agility: Faster provisioning of services.  </li> <li>Scalability: Manage thousands of devices with ease.  </li> <li>Cost Savings: Uses commodity hardware, reduces vendor lock-in.  </li> <li>Integration with Cloud: Works seamlessly with virtualization and OpenStack/Kubernetes.  </li> </ul>"},{"location":"phase-2/cloud-computing/04_sdn/#sdn-vs-traditional-networking","title":"SDN vs Traditional Networking","text":"Feature Traditional Networking Software-Defined Networking (SDN) Control Plane Distributed across each device Centralized in SDN Controller Data Plane Same device as control plane Remains in switches/routers Configuration Manual per device (CLI) Automated via APIs Agility Slow, hardware-dependent Fast, software-driven Visibility Limited to device-level Global network view from controller Cost Proprietary, expensive hardware Commodity hardware, open-source flexibility"},{"location":"phase-2/cloud-computing/04_sdn/#sdn-protocols","title":"SDN Protocols","text":"<ul> <li>OpenFlow \u2192 Most widely used, standard southbound protocol.  </li> <li>NETCONF \u2192 Configuration protocol for network devices.  </li> <li>REST APIs \u2192 Used for northbound communication with applications.  </li> </ul>"},{"location":"phase-2/cloud-computing/04_sdn/#leading-sdn-vendors-platforms","title":"Leading SDN Vendors &amp; Platforms","text":"<ul> <li>Cisco ACI (Application Centric Infrastructure) </li> <li>VMware NSX </li> <li>OpenDaylight (open source) </li> <li>ONOS (Open Network Operating System) </li> <li>Nutanix Flow (security-focused SDN) </li> <li>Juniper Contrail </li> </ul>"},{"location":"phase-2/cloud-computing/04_sdn/#real-world-use-cases","title":"Real-World Use Cases","text":"<ol> <li>Data Centers \u2192 Dynamic bandwidth allocation, tenant isolation.  </li> <li>Cloud Environments \u2192 OpenStack Neutron integrates with SDN.  </li> <li>Telecom Providers \u2192 5G networks use SDN + NFV for slicing.  </li> <li>Campus Networks \u2192 Simplified policy-based management.  </li> <li>Security \u2192 Microsegmentation with VMware NSX.  </li> </ol>"},{"location":"phase-2/cloud-computing/04_sdn/#example-scenario","title":"Example Scenario","text":"<p>At TechOps Inc., the IT team deploys an SDN controller to manage 50 switches across two data centers.  </p> <ul> <li>Instead of logging into each switch, they configure traffic policies in the SDN controller.  </li> <li>When a new application is deployed in OpenStack, the SDN controller automatically provisions network paths.  </li> <li>Security teams use SDN to isolate traffic between finance and HR applications (microsegmentation).  </li> </ul> <p>WoW Tip</p> <p>Google uses SDN in its global B4 WAN (Wide Area Network) to manage inter-data center traffic. This allows Google to dynamically allocate bandwidth for services like YouTube, Gmail, and Google Search \u2014 improving performance and reducing costs.</p>"},{"location":"phase-2/cloud-computing/04_sdn/#summary","title":"Summary","text":"<ul> <li>SDN separates control plane from data plane, enabling programmable, centralized network management.  </li> <li>It provides agility, scalability, and integration with cloud-native environments.  </li> <li>Core architecture: Application Layer \u2192 Controller \u2192 Infrastructure Layer.  </li> <li>Widely used in data centers, telecom, cloud, and enterprise networks.  </li> </ul>"},{"location":"phase-2/cloud-computing/05_public_cloud/","title":"\ud83d\udcd8 Introduction to Public Cloud","text":"<p>Objectives</p> <p>By the end of this chapter, you should be able to:</p> <ul> <li>Define what public cloud is and how it differs from private/hybrid models.  </li> <li>Explain the key advantages and challenges of public cloud.  </li> <li>Understand why organizations adopt public cloud for IT infrastructure and DevOps.  </li> <li>Identify common use cases (where public cloud is a good fit, and where it\u2019s not).  </li> </ul>"},{"location":"phase-2/cloud-computing/05_public_cloud/#what-is-public-cloud","title":"\ud83c\udf29\ufe0f What is Public Cloud?","text":"<p>A public cloud is a computing model where IT services (compute, storage, networking, AI, databases, etc.) are delivered over the internet by a third-party provider.  </p> <ul> <li>The infrastructure (data centers, servers, storage) is owned and managed by the cloud provider.  </li> <li>Customers rent or subscribe to resources on demand.  </li> <li>Examples: Amazon Web Services (AWS), Microsoft Azure, Google Cloud Platform (GCP), Oracle Cloud Infrastructure (OCI).  </li> </ul> <p>\ud83d\udc49 Think of it like electricity: instead of building your own power plant (private data center), you pay only for the electricity (compute/storage) you consume.  </p> <p></p>"},{"location":"phase-2/cloud-computing/05_public_cloud/#public-vs-private-vs-hybrid-cloud","title":"\ud83c\udfe2 Public vs Private vs Hybrid Cloud","text":"Model Who owns it? Where does it run? Typical Use Case Public Cloud Third-party providers (AWS, etc.) Shared data centers Startups, enterprises scaling quickly Private Cloud Single organization On-premises or dedicated data center Banks, defense, sensitive workloads Hybrid Cloud Mix of both Combines private + public Enterprises needing flexibility"},{"location":"phase-2/cloud-computing/05_public_cloud/#key-characteristics-of-public-cloud","title":"\u2705 Key Characteristics of Public Cloud","text":"<ol> <li>On-Demand Self-Service \u2013 Provision servers or storage instantly.  </li> <li>Broad Network Access \u2013 Services accessible from anywhere via the internet.  </li> <li>Resource Pooling \u2013 Multi-tenancy (resources shared across many customers).  </li> <li>Elasticity &amp; Scalability \u2013 Scale up/down automatically with demand.  </li> <li>Pay-as-You-Go Pricing \u2013 No upfront capital expense.  </li> </ol> <p>These characteristics align with NIST\u2019s definition of cloud computing.  </p>"},{"location":"phase-2/cloud-computing/05_public_cloud/#why-do-organizations-use-public-cloud","title":"\ud83d\udca1 Why Do Organizations Use Public Cloud?","text":""},{"location":"phase-2/cloud-computing/05_public_cloud/#benefits","title":"Benefits:","text":"<ul> <li>Cost Efficiency \u2192 No large upfront capex, pay only for usage.  </li> <li>Speed &amp; Agility \u2192 Launch new applications in minutes.  </li> <li>Global Reach \u2192 Deploy apps close to customers in multiple regions.  </li> <li>Innovation \u2192 Access to advanced services (AI, ML, IoT, big data).  </li> <li>High Availability \u2192 Built-in redundancy across multiple zones.  </li> </ul>"},{"location":"phase-2/cloud-computing/05_public_cloud/#challenges","title":"Challenges:","text":"<ul> <li>Data Security &amp; Compliance \u2192 Sensitive data may need private cloud.  </li> <li>Vendor Lock-in \u2192 Hard to move workloads between providers.  </li> <li>Performance Variability \u2192 Dependent on internet and shared infra.  </li> <li>Cost Overruns \u2192 If not managed, pay-as-you-go can become expensive.  </li> </ul>"},{"location":"phase-2/cloud-computing/05_public_cloud/#real-world-use-cases","title":"\ud83c\udf0d Real-World Use Cases","text":"<ol> <li> <p>Startups \u2192 Launch globally with zero upfront investment.  </p> <ul> <li>Example: A fintech startup hosting mobile app backend on AWS Lambda + DynamoDB.</li> </ul> </li> <li> <p>Enterprises \u2192 Migrate legacy workloads to reduce data center costs. </p> <ul> <li>Example: A bank using Azure for customer portals but keeping core banking on private cloud.  </li> </ul> </li> <li> <p>DevOps/IT Teams \u2192 Automate CI/CD pipelines in cloud environments. </p> <ul> <li>Example: GitHub Actions deploying code to GCP Kubernetes clusters.  </li> </ul> </li> <li> <p>Big Data &amp; AI \u2192 Process petabytes of data using managed ML/AI services.  </p> <ul> <li>Example: Netflix running recommendation engine on AWS.  </li> </ul> </li> </ol>"},{"location":"phase-2/cloud-computing/05_public_cloud/#key-takeaway","title":"\ud83e\udded Key Takeaway","text":"<p>The public cloud is now the default platform for modern IT and DevOps. </p> <ul> <li>It offers speed, scalability, and global access.  </li> <li>It does not eliminate private or hybrid cloud but often complements them.  </li> <li>As future DevOps/IT engineers, your skillset must include understanding public cloud services and APIs.  </li> </ul> <p>\u2728 Next Chapter: We\u2019ll explore \u201cServices Provided by Public Clouds &amp; Comparison of Top Providers\u201d (AWS, Azure, GCP).  </p>"},{"location":"phase-2/cloud-computing/06_public_cloud_services/","title":"\ud83d\udcd8 Services Provided by Public Clouds &amp; Comparison of Top Public Cloud Providers","text":"<p>Objectives</p> <p>By the end of this chapter you will be able to:</p> <ul> <li>Describe the core service models (IaaS, PaaS, SaaS, CaaS, FaaS) used by public cloud providers.  </li> <li>List and explain the major service categories offered by clouds (compute, storage, DB, networking, security, serverless, containers, analytics, AI/ML, CDN, migration, monitoring).  </li> <li>Compare the leading public cloud providers (AWS, Microsoft Azure, Google Cloud Platform) at a high level \u2014 strengths, enterprise fit, and hybrid/multicloud strategies.  </li> <li>Know where to look (official docs) and what hands-on exercises to do next.</li> </ul> <p>Quick context</p> <p>Public cloud is dominated by a few large providers \u2014 often referenced as the \u201cbig three\u201d (AWS, Microsoft Azure, Google Cloud). This dominance affects available features, global reach, pricing pressure, and partner ecosystems.</p>"},{"location":"phase-2/cloud-computing/06_public_cloud_services/#_1","title":"Services of Public Cloud","text":""},{"location":"phase-2/cloud-computing/06_public_cloud_services/#cloud-service-models-short-practical-definitions","title":"Cloud service-models (short &amp; practical definitions)","text":"<ul> <li> <p>IaaS (Infrastructure as a Service)   Low-level building blocks (VMs, block storage, virtual networks). You manage OS, runtime, apps; provider manages hypervisor, physical hosts, networks, and storage.</p> </li> <li> <p>PaaS (Platform as a Service)   Managed runtime/platform for apps (platform hides OS/patching). Examples: managed app-hosting, managed databases, managed integration services.</p> </li> <li> <p>SaaS (Software as a Service)   Fully managed applications delivered over the web (e.g., Office 365, Salesforce). No infra management.</p> </li> <li> <p>CaaS (Containers as a Service)   Managed container hosting/orchestration platforms (hosted Kubernetes or container services).</p> </li> <li> <p>FaaS / Serverless (Function as a Service)   Short-lived functions invoked by events; provider manages scaling and server management (e.g., AWS Lambda).</p> </li> </ul> <p>Practical note</p> <p>Vendor APIs/CLIs/SDKs let you automate IaaS/PaaS/FaaS operations (create VM, attach storage, create bucket, or deploy function).</p>"},{"location":"phase-2/cloud-computing/06_public_cloud_services/#core-service-categories-in-public-cloud","title":"\ud83d\udcd8 Core Service Categories in Public Cloud","text":""},{"location":"phase-2/cloud-computing/06_public_cloud_services/#compute-running-applications","title":"Compute (Running Applications)","text":"<ul> <li> <p>What it is: Virtual machines, containers, or serverless functions that run your applications.  </p> </li> <li> <p>Why it matters: Every app needs compute power (CPU + memory).  </p> </li> <li> <p>Examples:  </p> <ul> <li>AWS \u2192 EC2, Lambda  </li> <li>Azure \u2192 Virtual Machines, Azure Functions  </li> <li>GCP \u2192 Compute Engine, Cloud Functions  </li> </ul> </li> <li> <p>Watch out for:  </p> <ul> <li>Choosing wrong instance size = higher costs.  </li> <li>Data on temporary disks is lost if VM stops.  </li> </ul> </li> </ul>"},{"location":"phase-2/cloud-computing/06_public_cloud_services/#storage-saving-data","title":"Storage (Saving Data)","text":"<ul> <li> <p>What it is: Services to store files, application data, or databases.  </p> </li> <li> <p>Types:  </p> <ul> <li>Object Storage \u2192 for files, images, backups (S3, Blob, Cloud Storage).  </li> <li>Block Storage \u2192 attached to VMs, like virtual hard drives (EBS, Managed Disks, Persistent Disk).  </li> <li>File Storage \u2192 shared network drives (EFS, Azure Files, Filestore).  </li> </ul> </li> <li> <p>Why it matters: Different apps need different storage types (databases need block storage, websites need object storage).  </p> </li> <li> <p>Watch out for:  </p> <ul> <li>Data transfer (egress) costs.  </li> <li>Access permissions \u2014 misconfigured storage often causes data leaks.  </li> </ul> </li> </ul>"},{"location":"phase-2/cloud-computing/06_public_cloud_services/#databases","title":"Databases","text":"<ul> <li> <p>What it is: Managed relational (SQL) or non-relational (NoSQL) databases.  </p> </li> <li> <p>Why it matters: Almost all apps need structured data storage.  </p> </li> <li> <p>Examples:  </p> <ul> <li>Relational: RDS (AWS), Azure SQL Database, Cloud SQL (GCP).  </li> <li>NoSQL: DynamoDB, Cosmos DB, Firestore.  </li> <li>Analytics: Redshift, Synapse, BigQuery.  </li> </ul> </li> <li> <p>Watch out for:  </p> <ul> <li>Costs can grow quickly with scale.  </li> <li>Replication/backup setup is critical for DR.  </li> </ul> </li> </ul>"},{"location":"phase-2/cloud-computing/06_public_cloud_services/#networking-content-delivery","title":"Networking &amp; Content Delivery","text":"<ul> <li> <p>What it is: Services that connect cloud resources and deliver apps globally.  </p> </li> <li> <p>Why it matters: Without networking, your VM is isolated.  </p> </li> <li> <p>Examples:  </p> <ul> <li>VPC (all providers) \u2192 private cloud networks.  </li> <li>Load Balancers \u2192 distribute traffic.  </li> <li>CDN \u2192 caches content near users (CloudFront, Azure CDN, Cloud CDN).  </li> </ul> </li> <li> <p>Watch out for:  </p> <ul> <li>Misconfigured firewalls can expose resources publicly.  </li> <li>Cross-region data transfer adds cost.  </li> </ul> </li> </ul>"},{"location":"phase-2/cloud-computing/06_public_cloud_services/#identity-security","title":"Identity &amp; Security","text":"<ul> <li> <p>What it is: Tools to control who can access what in your cloud.  </p> </li> <li> <p>Why it matters: Security is the #1 risk in cloud.  </p> </li> <li> <p>Examples:  </p> <ul> <li>IAM (AWS), Azure Active Directory, IAM (GCP).  </li> <li>Key Management: AWS KMS, Azure Key Vault, Cloud KMS.  </li> </ul> </li> <li> <p>Watch out for:  </p> <ul> <li>Over-permissive policies (\u201c*\u201d access).  </li> <li>Misconfigured public buckets.  </li> </ul> </li> </ul>"},{"location":"phase-2/cloud-computing/06_public_cloud_services/#serverless-event-driven","title":"Serverless &amp; Event-Driven","text":"<ul> <li> <p>What it is: Running code without managing servers.  </p> </li> <li> <p>Why it matters: Great for automating small tasks, cost-efficient.  </p> </li> <li> <p>Examples:  </p> <ul> <li>AWS Lambda, Azure Functions, GCP Cloud Functions.  </li> </ul> </li> <li> <p>Use case:     Process image when it\u2019s uploaded to storage.  </p> </li> <li> <p>Watch out for:  </p> <ul> <li>Execution time limits.  </li> <li>Cold-start latency.  </li> </ul> </li> </ul>"},{"location":"phase-2/cloud-computing/06_public_cloud_services/#containers-orchestration","title":"Containers &amp; Orchestration","text":"<ul> <li> <p>What it is: Run applications in lightweight, portable containers.  </p> </li> <li> <p>Why it matters: Industry standard for microservices.  </p> </li> <li> <p>Examples:  </p> <ul> <li>AWS EKS, Azure AKS, Google GKE (all are managed Kubernetes).  </li> </ul> </li> <li> <p>Watch out for:  </p> <ul> <li>Cluster cost (idle nodes still cost money).  </li> <li>Networking/storage setup for stateful apps.  </li> </ul> </li> </ul>"},{"location":"phase-2/cloud-computing/06_public_cloud_services/#monitoring-logging","title":"Monitoring &amp; Logging","text":"<ul> <li> <p>What it is: Services to track performance, errors, and logs.  </p> </li> <li> <p>Why it matters: Without monitoring, you don\u2019t know when systems fail.  </p> </li> <li> <p>Examples:  </p> <ul> <li>AWS CloudWatch, Azure Monitor, Google Cloud Operations Suite.  </li> </ul> </li> <li> <p>Watch out for:  </p> <ul> <li>High logging costs with verbose apps.  </li> <li>Need alerts (not just dashboards).  </li> </ul> </li> </ul>"},{"location":"phase-2/cloud-computing/06_public_cloud_services/#big-data-machine-learning","title":"Big Data &amp; Machine Learning","text":"<ul> <li> <p>What it is: Platforms to process massive datasets and build AI models.  </p> </li> <li> <p>Why it matters: Modern apps rely on analytics &amp; AI.  </p> </li> <li> <p>Examples:  </p> <ul> <li>AWS SageMaker, Azure ML, Google Vertex AI.  </li> <li>AWS EMR, Azure Synapse, Google BigQuery.  </li> </ul> </li> <li> <p>Watch out for:  </p> <ul> <li>Data transfer costs between services.  </li> <li>Lack of data governance.  </li> </ul> </li> </ul>"},{"location":"phase-2/cloud-computing/06_public_cloud_services/#migration-hybrid-tools","title":"Migration &amp; Hybrid Tools","text":"<ul> <li> <p>What it is: Services to move apps/data into cloud or connect on-prem data centers.  </p> </li> <li> <p>Why it matters: Few companies start from scratch in cloud.  </p> </li> <li> <p>Examples:  </p> <ul> <li>AWS DMS (Database Migration Service), Azure Migrate, GCP Migrate for Compute.  </li> </ul> </li> <li> <p>Watch out for:  </p> <ul> <li>Large data transfers take time/cost.  </li> <li>Need cutover planning to avoid downtime.  </li> </ul> </li> </ul>"},{"location":"phase-2/cloud-computing/06_public_cloud_services/#cost-management-marketplace","title":"Cost Management &amp; Marketplace","text":"<ul> <li> <p>What it is: Tools to control spending + app marketplace.  </p> </li> <li> <p>Why it matters: Cloud can get expensive if not managed.  </p> </li> <li> <p>Examples:  </p> <ul> <li>Cost Explorer (AWS), Cost Management (Azure), Billing Reports (GCP).  </li> <li>Marketplaces with pre-built apps (VM images, SaaS).  </li> </ul> </li> <li> <p>Watch out for:  </p> <ul> <li>Hidden egress/network charges.  </li> <li>Marketplace apps may have extra licensing costs.  </li> </ul> </li> </ul> <p>Key Takeaway</p> <ul> <li>All cloud providers offer these 11 categories, even if names differ.  </li> <li>Focus on the concepts, not the brand names. Once you understand categories, you can map them across AWS, Azure, and GCP.  </li> </ul>"},{"location":"phase-2/cloud-computing/06_public_cloud_services/#how-clouds-expose-functionality-apis-cli-sdks","title":"How clouds expose functionality (APIs, CLI, SDKs)","text":"<ul> <li>RESTful APIs + JSON payloads are the canonical programmatic interface.  </li> <li>CLIs (aws/az/gcloud) provide scriptable tooling for labs and automation.  </li> <li>SDKs (Python/Go/Java/Node) are used inside applications and CI/CD pipelines.  </li> <li>Infrastructure-as-Code (Terraform, CloudFormation, ARM templates) enables reproducible infra and policy-as-code.</li> </ul>"},{"location":"phase-2/cloud-computing/06_public_cloud_services/#top-public-cloud-providers-short-comparison-positioning","title":"Top public cloud providers: short comparison &amp; positioning","text":""},{"location":"phase-2/cloud-computing/06_public_cloud_services/#provider-at-a-glance-high-level","title":"Provider-at-a-glance (high-level)","text":"Provider Strengths / Differentiator Enterprise fit / Common use-cases Hybrid / Edge offering AWS (Amazon Web Services) Largest breadth of services and global regions; mature ecosystem; many instance types and specialized hardware Startups \u2192 enterprise, feature-rich production systems, AI/ML infrastructure, broad partner ecosystem Outposts, Local Zones, Snow family for edge &amp; data transfer Microsoft Azure Deep enterprise integration (Active Directory, Windows Server, SQL Server), strong hybrid story Enterprises with Microsoft stack, large corp migrations, SaaS integrations Azure Arc, Azure Stack for on-prem hybrid Google Cloud Platform (GCP) Data, analytics and ML-first: strong data services and scale; network performance Data analytics platforms, ML/AI workloads, Kubernetes-native apps Anthos for hybrid/multicloud, edge solutions <p>Note: Each provider also offers multi-region redundancy, compliance frameworks, and managed enterprise support tiers.</p>"},{"location":"phase-2/cloud-computing/06_public_cloud_services/#example-provider-strengths-explained-practical","title":"Example provider strengths explained (practical)","text":"<ul> <li>AWS: unmatched service variety \u2014 good when you need a very specific managed service (e.g., managed message brokers, streaming, specialized instances). AWS docs are the canonical reference for its service behaviors.</li> <li>Azure: excellent if your environment is Windows-heavy or you want frictionless Active Directory + identity integration and vendor support agreements. Azure\u2019s storage (Blob) and VM offerings are comparable to others and integrate tightly with Microsoft ecosystem tools. </li> <li>GCP: invests heavily in data platforms (BigQuery), low-latency networking, and Kubernetes. Its Compute and data services are optimized for analytics and large-scale data processing.</li> </ul>"},{"location":"phase-2/cloud-computing/06_public_cloud_services/#how-similar-are-services-between-providers","title":"How similar are services between providers?","text":"<ul> <li>Functionally most categories exist across providers (compute, object storage, managed DBs, serverless, managed kubernetes, CDN) \u2014 they differ mainly in API/CLI ergonomics, SLA/pricing, extra features, and regional availability. Google provides an official service comparison/mapping which is useful to study when migrating or comparing features.</li> </ul>"},{"location":"phase-2/cloud-computing/06_public_cloud_services/#summary","title":"Summary","text":"<ul> <li>Public clouds provide the same core categories (compute, storage, networking, IAM, DB, serverless, containers), but each provider packages and names these services differently. Understanding the category matters more than memorizing names.  </li> <li>Start practical learning with one provider or choose provider based on your institution's priorities; then learn how to translate concepts across vendors.  </li> <li>Next chapter will give a service-name mapping table (AWS / Azure / GCP) and deeper explanations of common services so students can map terms across providers.</li> </ul>"},{"location":"phase-2/cloud-computing/07_public_cloud_service_comparision/","title":"Different Names of Services Provided by Public Cloud Providers","text":"<p>Learning Goal</p> <p>Understand that all major cloud providers offer similar services, but each uses different names. This chapter helps students quickly map services between AWS, Azure, and GCP, so they don\u2019t get confused when switching providers.</p>"},{"location":"phase-2/cloud-computing/07_public_cloud_service_comparision/#why-this-matters","title":"\ud83d\udd11 Why this matters","text":"<ul> <li>When you move between providers (or read documentation), you\u2019ll encounter different terms for the same concept.  </li> <li>Knowing this mapping makes it easier to learn once and apply everywhere.  </li> <li>Example: AWS S3 = Azure Blob Storage = GCP Cloud Storage \u2192 all are object storage services.  </li> </ul>"},{"location":"phase-2/cloud-computing/07_public_cloud_service_comparision/#service-name-comparison-table","title":"\ud83d\udcca Service Name Comparison Table","text":"Category AWS Azure GCP Compute (VMs) EC2 (Elastic Compute Cloud) Virtual Machines Compute Engine Serverless Functions Lambda Azure Functions Cloud Functions Containers (K8s) Elastic Kubernetes Service (EKS) Azure Kubernetes Service (AKS) Google Kubernetes Engine (GKE) Object Storage S3 (Simple Storage Service) Blob Storage Cloud Storage Block Storage EBS (Elastic Block Store) Managed Disks Persistent Disk File Storage EFS (Elastic File System) Azure Files Filestore Relational DB RDS (Relational Database Service) Azure SQL Database Cloud SQL NoSQL DB DynamoDB Cosmos DB Firestore / Bigtable Data Warehouse Redshift Synapse Analytics BigQuery Networking (VPC) VPC Virtual Network (VNet) VPC (same name) Load Balancing Elastic Load Balancer (ELB) Azure Load Balancer / App Gateway Cloud Load Balancing DNS Route 53 Azure DNS Cloud DNS CDN CloudFront Azure CDN Cloud CDN Identity &amp; Access IAM (Identity &amp; Access Mgmt) Azure Active Directory (Azure AD) IAM (same name) Key Management KMS Key Vault Cloud KMS Monitoring &amp; Logging CloudWatch + CloudTrail Azure Monitor + Log Analytics Cloud Monitoring + Logging Serverless Messaging SQS/SNS/EventBridge Service Bus / Event Grid Pub/Sub Big Data / Analytics EMR (Elastic MapReduce) HDInsight / Synapse Dataproc / Dataflow AI/ML SageMaker Azure Machine Learning Vertex AI Migration Tools Database Migration Service (DMS) Azure Migrate Migrate for Compute / Database Migration Service Cost Management Cost Explorer Cost Management + Billing Billing Reports / Cost Tools"},{"location":"phase-2/cloud-computing/07_public_cloud_service_comparision/#key-takeaway","title":"\ud83e\udded Key Takeaway","text":"<ul> <li>The services are almost the same \u2014 what changes is the branding.  </li> <li>If you know how to use one, learning the equivalent in another provider is much easier.  </li> <li>Focus on concepts like compute, storage, networking, databases, identity, serverless.  </li> </ul>"},{"location":"phase-2/cloud-computing/08_cloud_api_sdk/","title":"Cloud API Integration","text":""},{"location":"phase-2/cloud-computing/08_cloud_api_sdk/#introduction-to-apis-and-sdks","title":"Introduction to APIs and SDKs","text":"<p>API (Application Programming Interface)</p> <ul> <li>An API is a set of rules and tools that allows different software applications to communicate with each other.</li> <li>It acts as an intermediary between different systems, enabling them to exchange data or perform actions seamlessly.</li> <li>In the context of cloud computing, APIs are used to interact with cloud services, such as provisioning resources, managing data, or automating tasks.</li> <li>Example: The Amazon Web Services (AWS) API allows developers to programmatically create an EC2 instance or retrieve data from an S3 bucket.</li> </ul> <p>SDK (Software Development Kit)</p> <ul> <li>An SDK is a broader set of tools, libraries, and documentation designed to help developers build applications for a specific platform or framework.</li> <li>SDKs often include APIs, sample code, and utilities to simplify development tasks.</li> <li>In cloud computing, SDKs provide pre-built libraries in various programming languages (e.g., Python, Java, Node.js) to interact with cloud provider APIs.</li> <li>Example: AWS SDK for Python (Boto3) simplifies interacting with AWS services by providing ready-to-use functions for common tasks.</li> </ul> <p>Key Difference</p> <p>APIs are specific interfaces for communication, while SDKs are comprehensive toolkits that include APIs and additional resources to streamline development.</p> <p>Why They Are Used</p> <ul> <li>APIs and SDKs enable automation, scalability, and integration of cloud services into applications.</li> <li>They allow developers to manage cloud resources programmatically without relying on manual interfaces like web consoles.</li> <li>They provide flexibility to integrate cloud services with custom applications, third-party tools, or other cloud platforms.</li> </ul>"},{"location":"phase-2/cloud-computing/08_cloud_api_sdk/#apis-and-sdks-from-different-cloud-providers","title":"APIs and SDKs from Different Cloud Providers","text":"Amazon Web Services (AWS)Microsoft AzureGoogle Cloud Platform (GCP)Other Providers <ul> <li>APIs: AWS provides RESTful APIs for services like EC2, S3, Lambda, and IAM, accessible via HTTPS requests.</li> <li>SDKs: AWS offers SDKs for multiple languages, such as Boto3 (Python), AWS SDK for Java, and AWS SDK for JavaScript.</li> <li>Example: Using Boto3 to create an S3 bucket: <pre><code>import boto3\ns3 = boto3.client('s3')\ns3.create_bucket(Bucket='my-unique-bucket-name')\n</code></pre></li> </ul> <ul> <li>APIs: Azure REST APIs allow interaction with services like Azure Virtual Machines, Blob Storage, and Azure Functions.</li> <li>SDKs: Azure SDKs are available for Python, .NET, Java, and more, simplifying tasks like resource provisioning or data management.</li> <li>Example: Using Azure SDK for Python to list virtual machines: <pre><code>from azure.identity import DefaultAzureCredential\nfrom azure.mgmt.compute import ComputeManagementClient\ncredential = DefaultAzureCredential()\ncompute_client = ComputeManagementClient(credential, subscription_id)\nfor vm in compute_client.virtual_machines.list_all():\n    print(vm.name)\n</code></pre></li> </ul> <ul> <li>APIs: GCP provides APIs for services like Compute Engine, Cloud Storage, and BigQuery, accessible via REST or gRPC.</li> <li>SDKs: Google Cloud Client Libraries are available for Python, Java, Go, and other languages.</li> <li>Example: Using Google Cloud Python SDK to upload a file to Cloud Storage: <pre><code>from google.cloud import storage\nclient = storage.Client()\nbucket = client.get_bucket('my-bucket')\nblob = bucket.blob('my-file.txt')\nblob.upload_from_filename('local-file.txt')\n</code></pre></li> </ul> <ul> <li>Providers like IBM Cloud, Oracle Cloud, and DigitalOcean also offer APIs and SDKs tailored to their services, such as container management, database operations, or networking.</li> </ul>"},{"location":"phase-2/cloud-computing/08_cloud_api_sdk/#why-apis-and-sdks-are-beneficial-in-iaas","title":"Why APIs and SDKs Are Beneficial in IaaS","text":"<p>Infrastructure as a Service (IaaS):</p> <ul> <li>IaaS provides virtualized computing resources (e.g., virtual machines, storage, networks) over the internet.</li> <li>Examples: AWS EC2, Azure Virtual Machines, GCP Compute Engine.</li> </ul>"},{"location":"phase-2/cloud-computing/08_cloud_api_sdk/#benefits-of-apis-in-iaas","title":"Benefits of APIs in IaaS","text":"<ul> <li>Automation: APIs allow developers to automate the provisioning, configuration, and management of infrastructure resources, reducing manual effort.<ul> <li>Example: Automatically scaling EC2 instances based on demand using AWS APIs.</li> </ul> </li> <li>Scalability: APIs enable dynamic scaling of resources, such as adding or removing virtual machines based on workload.</li> <li>Integration: APIs allow IaaS resources to integrate with other services or applications, enabling complex workflows.<ul> <li>Example: Using AWS APIs to connect an EC2 instance to an S3 bucket for data storage.</li> </ul> </li> <li>Consistency: APIs ensure consistent management of resources across environments (e.g., development, testing, production).</li> </ul>"},{"location":"phase-2/cloud-computing/08_cloud_api_sdk/#benefits-of-sdks-in-iaas","title":"Benefits of SDKs in IaaS:","text":"<ul> <li>Simplified Development: SDKs provide high-level abstractions, reducing the complexity of interacting with raw APIs.<ul> <li>Example: Boto3\u2019s <code>create_instance</code> method simplifies launching an EC2 instance compared to constructing raw HTTP requests.</li> </ul> </li> <li>Error Handling: SDKs include built-in error handling and retry mechanisms, improving reliability.</li> <li>Language-Specific Support: SDKs are tailored to popular programming languages, making them accessible to a wide range of developers.</li> <li>Documentation and Examples: SDKs come with extensive documentation and sample code, accelerating development.</li> </ul>"},{"location":"phase-2/cloud-computing/08_cloud_api_sdk/#why-developers-prefer-using-apis-and-sdks","title":"Why Developers Prefer Using APIs and SDKs","text":"<p>Ease of Use:</p> <ul> <li>SDKs abstract low-level details of API calls, such as authentication, request formatting, and response parsing.</li> <li>Developers can focus on application logic rather than managing HTTP requests.</li> </ul> <p>Faster Development</p> <ul> <li>SDKs provide pre-built functions for common tasks, reducing development time.</li> <li>Example: AWS SDK for Python allows developers to create an S3 bucket with a single function call instead of multiple API requests.</li> </ul> <p>Cross-Platform Compatibility</p> <ul> <li>APIs and SDKs enable integration across different cloud providers or hybrid environments, allowing developers to build portable applications.</li> <li>Example: Using Terraform with APIs from AWS, Azure, and GCP to manage multi-cloud infrastructure.</li> </ul> <p>Community and Support</p> <ul> <li>Major cloud providers maintain active communities, comprehensive documentation, and support for their APIs and SDKs, making it easier for developers to troubleshoot issues.</li> </ul> <p>Flexibility</p> <ul> <li>APIs provide fine-grained control over cloud resources, allowing developers to customize solutions for specific use cases.</li> <li>Example: Using Azure APIs to create a custom autoscaling policy for virtual machines.</li> </ul> <p>Security</p> <ul> <li>APIs and SDKs support secure authentication methods (e.g., OAuth, API keys, IAM roles), ensuring safe access to cloud resources.</li> <li>Example: AWS SDKs handle IAM role-based authentication automatically, reducing security risks.</li> </ul> <p>Tip</p> <p>Many developers prefer SDKs over raw APIs because they reduce boilerplate code and improve productivity. For instance, AWS\u2019s Boto3 SDK simplifies tasks like handling pagination in API responses, which would otherwise require manual coding with raw APIs.</p>"},{"location":"phase-2/cloud-computing/08_cloud_api_sdk/#real-world-examples","title":"Real-World Examples","text":"<p>Automating Infrastructure:</p> <ul> <li>A company uses the AWS SDK for Python to automate the creation of EC2 instances during peak traffic hours, ensuring scalability for their e-commerce platform.</li> </ul> <p>Data Integration:</p> <ul> <li>A data analytics team uses Google Cloud APIs to pull data from BigQuery into a custom dashboard, enabling real-time business insights.</li> </ul> <p>Multi-Cloud Management:</p> <ul> <li>A DevOps engineer uses Terraform (which interacts with cloud APIs) to manage resources across AWS and Azure, ensuring consistent infrastructure across multiple providers.</li> </ul>"},{"location":"phase-2/cloud-computing/08_cloud_api_sdk/#best-practices-for-cloud-api-integration","title":"Best Practices for Cloud API Integration","text":"<p>Use SDKs When Possible:</p> <ul> <li>Leverage SDKs for faster development and better error handling unless specific API functionality is required.</li> </ul> <p>Secure API Access:</p> <ul> <li>Use secure authentication methods like IAM roles, OAuth tokens, or API keys, and avoid hardcoding credentials in code.</li> </ul> <p>Handle Rate Limits:</p> <ul> <li>Cloud APIs often have rate limits. Implement retry mechanisms and exponential backoff to handle throttling gracefully.</li> </ul> <p>Monitor API Usage:</p> <ul> <li>Use cloud provider tools (e.g., AWS CloudWatch, Azure Monitor) to track API usage and detect potential issues.</li> </ul> <p>Version Control:</p> <ul> <li>Use the latest API versions to access new features, but ensure backward compatibility when upgrading.</li> </ul> <p>Test Thoroughly:</p> <ul> <li>Test API integrations in a sandbox environment to avoid unintended changes to production resources.</li> </ul>"},{"location":"phase-2/cloud-computing/09_cloud_dr/","title":"Data Center and Disaster Recovery (DC/DR) Management","text":""},{"location":"phase-2/cloud-computing/09_cloud_dr/#dcdr-migration","title":"DC/DR Migration","text":"<p>Definition</p> <ul> <li>DC/DR Migration refers to the process of moving data, applications, or infrastructure from one data center (DC) to another or to a disaster recovery (DR) site to ensure business continuity, enhance performance, or meet compliance requirements.</li> <li>It involves transferring workloads, configurations, and data while minimizing downtime and ensuring data integrity.</li> </ul> <p>Why DC/DR Migrations Are Done</p> <ul> <li>Business Continuity: Ensures applications and data remain available during disasters (e.g., natural calamities, power outages).</li> <li>Cost Optimization: Relocates to a more cost-effective data center or cloud provider to reduce operational expenses.</li> <li>Performance Improvement: Moves to a geographically closer data center to reduce latency for end-users.</li> <li>Compliance: Meets regulatory requirements by hosting data in specific regions or secure facilities.</li> <li>Modernization: Upgrades to newer infrastructure or cloud-based environments for better scalability and efficiency.</li> </ul> <p>How DC/DR Migrations Are Done</p> <p>Planning:</p> <ul> <li>Assess current infrastructure, applications, and dependencies.</li> <li>Define migration goals (e.g., zero downtime, minimal data loss).</li> <li>Choose the target environment (e.g., another data center, cloud provider like AWS or Azure).</li> </ul> <p>Data Replication:</p> <ul> <li>Replicate data to the target site using tools like rsync, AWS DataSync, or Azure Site Recovery.</li> <li>Ensure data consistency between source and target.</li> </ul> <p>Application Migration:</p> <ul> <li>Use lift-and-shift (moving as-is), re-platforming (minor adjustments), or refactoring (rewriting for new environment).</li> <li>Test applications in the target environment before full migration.</li> </ul> <p>Testing and Validation:</p> <ul> <li>Conduct dry runs to validate configurations and performance.</li> <li>Verify network connectivity, security settings, and application functionality.</li> </ul> <p>Cutover</p> <ul> <li>Switch operations to the new site with minimal disruption.</li> <li>Use DNS updates or load balancers to redirect traffic.</li> </ul> <p>Post-Migration:</p> <ul> <li>Monitor performance and resolve issues.</li> <li>Decommission old infrastructure if no longer needed.</li> </ul> <p>Planning DR Drills</p> <p>Purpose: Simulate disaster scenarios to test the effectiveness of the DR plan.</p> <p>Steps:</p> <ul> <li>Schedule drills during low-impact periods.</li> <li>Define failure scenarios (e.g., server failure, network outage).</li> <li>Execute failover to the DR site and measure recovery time.</li> <li>Document results and update the DR plan based on findings.</li> </ul> <p>Frequency: Conduct drills quarterly or biannually to ensure preparedness.</p> <p>Real-World Examples</p> <ul> <li>A financial institution migrates its data center to AWS to comply with regional data residency laws, using AWS Database Migration Service for seamless data transfer.</li> <li>A retail company conducts a DR drill by simulating a power outage, failing over to a secondary data center using VMware Site Recovery Manager to ensure zero downtime for its e-commerce platform.</li> </ul>"},{"location":"phase-2/cloud-computing/09_cloud_dr/#dcdr-storage-synchronization","title":"DC/DR Storage Synchronization","text":"<p>Definition</p> <p>DC/DR Storage Synchronization is the process of continuously replicating and synchronizing data between a primary data center and a disaster recovery site to ensure data availability and consistency during failover.</p> <ul> <li>It ensures that the DR site has an up-to-date copy of critical data to support recovery operations.</li> </ul> <p>Why DC/DR Storage Synchronization Is Done</p> <ul> <li>Data Availability: Ensures data is accessible at the DR site during a disaster.</li> <li>Minimized Data Loss: Reduces the risk of data loss by keeping primary and DR sites in sync.</li> <li>Faster Recovery: Enables quick failover to the DR site with minimal downtime.</li> <li>Compliance: Meets regulatory requirements for data redundancy and backup.</li> </ul> <p>How DC/DR Storage Synchronization Is Done</p> <p>Replication Methods:</p> <ul> <li>Synchronous Replication: Data is written to both primary and DR sites simultaneously, ensuring zero data loss but requiring high-bandwidth, low-latency connections.</li> <li>Asynchronous Replication: Data is written to the primary site first and then replicated to the DR site with a slight delay, suitable for geographically distant sites.</li> </ul> <p>Tools and Technologies:</p> <ul> <li>Use storage solutions like ZFS, NetApp SnapMirror, or AWS S3 Cross-Region Replication for data synchronization.</li> <li>Implement block-level replication for databases or file-level replication for shared storage.</li> </ul> <p>Monitoring and Validation:</p> <ul> <li>Monitor replication status using tools like Nagios or AWS CloudWatch.</li> <li>Validate data integrity with checksums or hash comparisons.</li> </ul> <p>Failover and Failback:</p> <ul> <li>During a disaster, switch to the DR site using synchronized data.</li> <li>After recovery, synchronize changes back to the primary site (failback).</li> </ul> <p>Planning DR Drills for Storage Synchronization</p> <ul> <li>Test synchronization by simulating data corruption or site failure.</li> <li>Verify that the DR site can serve synchronized data without errors.</li> <li>Measure Recovery Point Objective (RPO) and Recovery Time Objective (RTO) to ensure they meet business requirements.</li> </ul> <p>Real-World Examples</p> <ul> <li>A healthcare provider uses Azure Blob Storage with Geo-Redundant Storage (GRS) to synchronously replicate patient records across regions, ensuring compliance with HIPAA regulations.</li> <li>An e-commerce company uses ZFS snapshots and replication to synchronize product inventory data between its primary data center and a DR site, enabling quick recovery during server failures.</li> </ul> <p> </p>"},{"location":"phase-2/cloud-computing/10_config_mgmt/","title":"Configuration Management","text":"<p>Objectives</p> <ul> <li>Understand what configuration management (CM) is and why it matters.  </li> <li>Distinguish CM from simple deployment scripts.  </li> <li>Learn the common CM tools (Chef, Puppet, Ansible, Salt) and how they differ.  </li> <li>See concrete examples (playbook/manifest/recipe) and real-world use cases.  </li> <li>Know core CM concepts: desired state, idempotence, convergence, agent vs agentless, inventories, modules/cookbooks/manifests, and testing.</li> </ul>"},{"location":"phase-2/cloud-computing/10_config_mgmt/#what-is-configuration-management","title":"What is Configuration Management?","text":"<ul> <li>Definition: Configuration Management is the practice and tooling that ensures systems (servers, network devices, containers) are configured to a defined \u201cdesired state\u201d and remain in that state over time.  </li> <li>Core idea: Declare what the system should look like (packages installed, services running, files present, users created) and have software enforce that state automatically and repeatedly.  </li> <li>Key properties: declarative (describe end-state), idempotent (apply repeatedly without side-effects), automated (applied by tooling), and auditable (reporting and drift detection).</li> </ul>"},{"location":"phase-2/cloud-computing/10_config_mgmt/#why-configuration-management-is-needed","title":"Why Configuration Management is Needed","text":"<ul> <li>Scale and consistency: Manual configuration doesn\u2019t scale; CM ensures hundreds or thousands of nodes get consistent configuration.  </li> <li>Drift prevention: CM continuously or periodically enforces the desired state, preventing configuration drift.  </li> <li>Repeatable environments: Recreate staging, test, and production environments reliably.  </li> <li>Compliance &amp; security: Enforce security baselines (patch levels, firewall rules, user accounts) and produce audit logs.  </li> <li>Faster recovery &amp; onboarding: New nodes can be brought to production state automatically; recovery and scaling are faster.  </li> <li>Separation of concerns: Operators and developers can express infrastructure and configuration as code.</li> </ul>"},{"location":"phase-2/cloud-computing/10_config_mgmt/#configuration-management-vs-deploy-scripts","title":"Configuration Management vs Deploy Scripts","text":"<ul> <li> <p>Deploy scripts (procedural):</p> <ul> <li>Typically a sequence of commands: <code>apt-get install X</code>, <code>edit file</code>, <code>systemctl restart</code>.</li> <li>Focus on how to perform steps (imperative).</li> <li>Often not idempotent; re-running the script can create duplicates or errors.</li> <li>Useful for one-off tasks or ad-hoc automation.</li> </ul> </li> <li> <p>Configuration Management (declarative / idempotent):</p> <ul> <li>Expresses what the final state should be (package X must be present, service Y must be running).</li> <li>Applying the same definition repeatedly yields the same result (idempotence).</li> <li>Provides abstractions (roles, modules, resources), reporting, and testing frameworks.</li> <li>Supports orchestration and drift correction.</li> </ul> </li> </ul>"},{"location":"phase-2/cloud-computing/10_config_mgmt/#core-concepts-components","title":"Core Concepts &amp; Components","text":"<ul> <li>Desired state: The specification of how a node should be configured (packages, files, services, users, permissions).  </li> <li>Resources: Smallest unit of change (e.g., package resource, file resource, service resource).  </li> <li>Runbook / Manifest / Playbook / Cookbook: The file(s) that describe desired state (terminology varies by tool).  </li> <li>Idempotence: Re-applying the same policy results in no change if the system already matches the desired state.  </li> <li>Convergence: Process by which nodes reach the desired state after applying CM instructions.  </li> <li>Inventory / Nodes list: The set of systems targeted by runs (e.g., Ansible inventory, Puppet nodes).  </li> <li>Agent vs Agentless:<ul> <li>Agent-based: An agent (daemon) runs on each node and polls or accepts connections from a central server (Chef, Puppet).  </li> <li>Agentless (push-based): A controller connects over SSH (or WinRM) to nodes and applies changes (Ansible).  </li> </ul> </li> <li>Master/Server vs Masterless: Central server manages configs and stores metadata (Chef/Puppet) vs masterless modes where nodes pull or apply local configs.  </li> <li>Modules / Cookbooks / Roles / Classes: Reusable collections of configuration (packaging policies, templates, tasks).</li> </ul>"},{"location":"phase-2/cloud-computing/10_config_mgmt/#popular-tools-overview-differences","title":"Popular Tools \u2014 Overview &amp; Differences","text":"Tool Model Language / Format Agent Strengths Typical use-cases Ansible Push-based, controller-driven YAML playbooks (simple) Agentless (SSH/WinRM) Simple, fast to start, human-readable Bootstrapping, ad-hoc tasks, deployments, small-to-medium fleets Chef Client-server (also solo) Ruby DSL (recipes/cookbooks) Agent (chef-client) Very flexible DSL, strong ecosystem, good for complex workflows Large-scale configuration requiring complex logic and test tooling Puppet Master-agent (also apply) Puppet DSL (manifests) Agent (puppet-agent) Mature reporting, model-driven config, robust for enterprise Policy/compliance at scale, detailed reporting Salt Master-minion (real-time) YAML / Python states Agent (salt-minion) Fast remote execution, event-driven, scalable Real-time orchestration, event-driven workflows"},{"location":"phase-2/cloud-computing/10_config_mgmt/#key-differences-explained","title":"Key differences explained","text":"<ul> <li>Agent vs agentless: Agent-based solutions allow node-initiated pulls and centralized reporting; agentless solutions (Ansible) require no pre-installed agent and work over SSH, simplifying initial setup.  </li> <li>Language and complexity: Chef and Puppet use more expressive DSLs (Ruby-like or domain-specific), allowing complex logic but with steeper learning curves; Ansible uses YAML that is easier for beginners.  </li> <li>Ecosystem &amp; modules: All tools provide large module repositories (Ansible Galaxy, Chef Supermarket, Puppet Forge) with reusable roles/cookbooks/manifests.  </li> <li>Reporting &amp; compliance: Puppet/Chef often provide richer state reporting, node classification, and enterprise features (Puppet Enterprise, Chef Automate).  </li> <li>Use pattern: Ansible is frequently used for orchestration and ad-hoc tasks; Chef/Puppet for long-term node enforcement at scale.</li> </ul>"},{"location":"phase-2/cloud-computing/10_config_mgmt/#architecture-patterns","title":"Architecture Patterns","text":"<ul> <li>Centralized server (Master) + Agents: Master stores configurations, agents pull catalogs and report back. Good for large fleets and fine-grained reporting (Puppet, Chef).  </li> <li>Controller (push) model: Controller pushes changes over SSH to nodes (Ansible). Simpler to set up; ideal for heterogeneous environments and episodic runs.  </li> <li>Hybrid / Masterless: Tools can be used in masterless modes (e.g., chef-solo, puppet apply) for ephemeral or cloud-native nodes.  </li> <li>Immutable infrastructure workflow: Build golden images (AMIs/container images) via CI using CM during image bake, then deploy immutable images rather than mutating running servers. CM still used during image build or for bootstrapping.</li> </ul>"},{"location":"phase-2/cloud-computing/10_config_mgmt/#typical-cm-workflows","title":"Typical CM Workflows","text":"<ul> <li>Bootstrapping (first-boot): Use CM to install runtime, app dependencies, create users, register with monitoring.  </li> <li>Configuration enforcement (continuous): Agents periodically re-apply manifests/playbooks to maintain state.  </li> <li>Orchestration: Execute ordered tasks across multiple nodes (e.g., database schema changes, rolling restarts).  </li> <li>Policy-as-code &amp; compliance: Express security and compliance rules as code and audit node compliance.</li> </ul>"},{"location":"phase-2/cloud-computing/10_config_mgmt/#idempotence-what-it-is-why-it-matters","title":"Idempotence \u2014 What it is &amp; why it matters","text":"<ul> <li>Explanation: A change is idempotent if applying it many times produces the same outcome as applying it once.  </li> <li>Example: Resource <code>package: httpd</code> \u2014 if the package is already installed, the CM tool does nothing (no error).  </li> <li>Why important: Enables safe repeated runs (daily enforcement, automated remediation) without causing side effects or duplicate operations.</li> </ul>"},{"location":"phase-2/cloud-computing/10_config_mgmt/#examples-practical-snippets","title":"Examples (practical snippets)","text":"Ansible playbookPuppet manifestChef recipe <pre><code>---\n- name: Install and configure Apache\nhosts: webservers\nbecome: yes\n\ntasks:\n    - name: Ensure httpd is installed\n    package:\n        name: httpd\n        state: present\n\n    - name: Ensure httpd service is running and enabled\n    service:\n        name: httpd\n        state: started\n        enabled: true\n\n    - name: Deploy index page\n    copy:\n        dest: /var/www/html/index.html\n        content: \"&lt;html&gt;&lt;body&gt;&lt;h1&gt;Hello from Ansible&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;\"\n        owner: root\n        group: root\n        mode: '0644'\n</code></pre> <ul> <li>Run command: <code>ansible-playbook -i inventory.ini site.yml</code></li> </ul> <pre><code>class webserver {\npackage { 'httpd':\n    ensure =&gt; present,\n}\n\nservice { 'httpd':\n    ensure =&gt; running,\n    enable =&gt; true,\n    require =&gt; Package['httpd'],\n}\n\nfile { '/var/www/html/index.html':\n    ensure  =&gt; file,\n    content =&gt; \"&lt;html&gt;&lt;body&gt;&lt;h1&gt;Hello from Puppet&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;\",\n    owner   =&gt; 'root',\n    group   =&gt; 'root',\n    mode    =&gt; '0644',\n    require =&gt; Service['httpd'],\n}\n}\n\ninclude webserver\n</code></pre> <ul> <li>Apply on node: <code>puppet apply site.pp</code></li> </ul> <pre><code>package 'httpd' do\naction :install\nend\n\nservice 'httpd' do\naction [:enable, :start]\nend\n\nfile '/var/www/html/index.html' do\ncontent '&lt;html&gt;&lt;body&gt;&lt;h1&gt;Hello from Chef&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;'\nowner 'root'\ngroup 'root'\nmode '0644'\naction :create\nend\n</code></pre> <ul> <li>Run with chef-client after uploading cookbook to Chef Server or run chef-solo for local testing.</li> </ul>"},{"location":"phase-2/cloud-computing/10_config_mgmt/#real-world-examples-use-cases","title":"Real-world Examples &amp; Use Cases","text":"<ul> <li>Web application fleet: Use CM to ensure all web nodes have the same app dependencies, configuration files, and monitoring agents. During deploy, orchestrate rolling restarts so service stays online.</li> <li>Security baseline enforcement: Ensure SSH configuration, firewall rules, user accounts, and audit settings comply with policy. CM provides drift detection and remediation.</li> <li>Patch management: Schedule CM-run playbooks/manifests to apply security patches and reboot nodes in controlled waves.</li> <li>Immutable image builds: Use CM tools to bake AMIs/VM images via CI pipelines (TestKitchen / Packer) so runtime nodes are identical.</li> <li>Hybrid environments: Use agentless Ansible to manage a mix of cloud VMs, on-prem servers, and network devices; use agents for high-scale servers for better reporting.</li> </ul>"},{"location":"phase-2/cloud-computing/10_config_mgmt/#secrets-sensitive-data-handling","title":"Secrets &amp; Sensitive Data Handling","text":"<ul> <li>Never store secrets in plain text within manifests/playbooks.</li> <li> <p>Integrate CM with secret stores:</p> </li> <li> <p>HashiCorp Vault, AWS Secrets Manager, Azure Key Vault.</p> </li> <li>Use lookup plugins (Ansible Vault) or templating that fetches secrets at run time with proper IAM policies.</li> </ul>"},{"location":"phase-2/cloud-computing/10_config_mgmt/#testing-and-validation","title":"Testing and Validation","text":"<ul> <li>Unit/Integration testing: Test recipes/playbooks locally: TestKitchen (Chef), Molecule (Ansible) to verify idempotence and behavior.</li> <li>Linting &amp; static checks: Use linters and style checks (rubocop for Chef, puppet-lint, ansible-lint).</li> <li>Staging &amp; canary: Apply changes to staging or a small canary group before full rollout.</li> <li>Reporting: Collect run results and drift reports (PuppetDB, Chef Automate, Ansible Tower/AWX).</li> </ul>"},{"location":"phase-2/cloud-computing/10_config_mgmt/#cm-cicd-integration","title":"CM &amp; CI/CD Integration","text":"<ul> <li> <p>CM plays multiple roles in pipelines:</p> </li> <li> <p>Image bake stage: Run CM in image-build to produce golden images.</p> </li> <li>Deployment stage: Trigger playbook/manifest runs as part of deploy pipelines.</li> <li>Rollback: Use CM to revert configuration or deploy a previous image.</li> <li>Tools commonly integrated: Jenkins/GitHub Actions/GitLab CI triggering Ansible, Chef, or Puppet runs; storing CM code in Git for versioning and review.</li> </ul>"},{"location":"phase-2/cloud-computing/10_config_mgmt/#best-practices-concise","title":"Best Practices (concise)","text":"<ul> <li>Express configuration as declarative, idempotent resources.</li> <li>Keep configurations modular and reusable (roles, modules, cookbooks).</li> <li>Store CM code in version control and use PR-based reviews.</li> <li>Use least-privilege for agent/controller credentials and integrate with secret managers.</li> <li>Test changes via automated test suites and use staging/canaries before global rollout.</li> <li>Prefer immutable images for production workloads where possible; use CM for image build and minor runtime fixes only.</li> </ul>"},{"location":"phase-2/cloud-computing/10_config_mgmt/#when-to-use-which-tool-short-guidance","title":"When to use which tool (short guidance)","text":"<ul> <li>Ansible: choose when you want quick start, agentless management, ad-hoc orchestration, and simple YAML-based playbooks. Good for bootstrapping and cross-platform tasks.</li> <li>Chef / Puppet: choose when you need a robust, enterprise-class CM with reporting, scaling, and complex configuration logic. Better when constant enforcement and detailed compliance reporting are required.</li> <li>Salt: choose when you need real-time job execution and event-driven automation at scale.</li> </ul>"},{"location":"phase-2/cloud-computing/10_config_mgmt/#limitations-challenges","title":"Limitations &amp; Challenges","text":"<ul> <li>Complexity at scale: large deployments require good modular design and governance.</li> <li>Stateful changes &amp; ordering: certain changes require careful orchestration (database schema updates).</li> <li>Secrets &amp; credential sprawl: careful handling and auditing of credentials are required.</li> <li>Drift outside CM: manual changes bypassing CM cause drift; strict processes &amp; monitoring are needed.</li> </ul>"},{"location":"phase-2/cloud-computing/10_config_mgmt/#summary","title":"Summary","text":"<p>Configuration Management is foundational for reliable, repeatable, and auditable infrastructure operations. It moves organizations from fragile, manual procedures to code-driven, testable, and enforceable infrastructure. Understanding the architecture (agent vs agentless), the core concepts (desired state, idempotence), and the practical differences between tools (Ansible, Chef, Puppet, Salt) allows engineers to pick the right tool and design effective, maintainable automation for their environment.</p>"},{"location":"phase-2/cloud-computing/11_cloud_migration/","title":"Migration of Physical Servers to Cloud","text":"<p>Objectives</p> <ul> <li>What physical-to-cloud migration is and why organisations do it.  </li> <li>Summarise common migration strategies and tools.  </li> <li>Highlight main risks and mitigation approaches.  </li> <li>Provide a compact planning checklist and validation criteria.</li> </ul>"},{"location":"phase-2/cloud-computing/11_cloud_migration/#what-is-physical-cloud-migration","title":"What is physical \u2192 cloud migration?","text":"<p>Physical-to-cloud migration is the process of moving workloads that run on physical servers (bare-metal) or on-prem virtual machines into cloud environments (public or private). The goal may be cost reduction, scaling, improved reliability, disaster recovery, or modernization.</p>"},{"location":"phase-2/cloud-computing/11_cloud_migration/#why-organisations-migrate-physical-servers-to-cloud","title":"Why organisations migrate physical servers to cloud","text":"<ul> <li>Operational cost reduction \u2014 reduce datacenter CAPEX (power, space, hardware) and shift to OPEX.  </li> <li>Elasticity &amp; scaling \u2014 on-demand compute and flexible sizing.  </li> <li>Managed services \u2014 replace self-managed components (DB, storage, monitoring) with managed cloud services.  </li> <li>Business continuity &amp; geographic reach \u2014 easier multi-region deployment and DR capabilities.  </li> <li>Faster provisioning &amp; DevOps \u2014 automation, CI/CD, and infrastructure-as-code support faster delivery.</li> </ul>"},{"location":"phase-2/cloud-computing/11_cloud_migration/#common-migration-approaches-short","title":"Common migration approaches (short)","text":"<ol> <li>P2V (Physical to Virtual) <ul> <li>Convert physical disk to a virtual image (VMDK/OVA) and import to cloud VM. Good first step for legacy apps.</li> </ul> </li> <li>Rehost (Lift-and-Shift) <ul> <li>Move application as-is to cloud VMs (minimal change). Fast, low-touch.</li> </ul> </li> <li>Replatform <ul> <li>Make small changes (e.g., move database to managed RDS) to gain cloud benefits without full refactor.</li> </ul> </li> <li>Refactor / Re-architect <ul> <li>Rebuild app to use cloud-native services (microservices, serverless). Higher payoff but higher effort.</li> </ul> </li> <li>Agent-based continuous replication <ul> <li>Use migration agents to replicate disk/OS state continuously and cutover with minimal downtime (best for low-RTO).</li> </ul> </li> <li>Hybrid / phased (wave) <ul> <li>Pilot \u2192 waves of similar workloads \u2192 full cutover; common at enterprise scale.</li> </ul> </li> </ol>"},{"location":"phase-2/cloud-computing/11_cloud_migration/#typical-tools-services-examples","title":"Typical tools &amp; services (examples)","text":"<ul> <li>VM Import/Export \u2014 import VMDK/OVA into cloud as AMI/VM image.  </li> <li>Agent-based migration services (e.g., AWS Application Migration Service / MGN) \u2014 replicate, test, cutover.  </li> <li>Database migration tools (e.g., AWS DMS) \u2014 migrate databases with minimal downtime.  </li> <li>Storage transfer \u2014 rsync, DataSync, Storage Gateway, or physical devices (Snowball) for very large initial datasets.  </li> <li>Configuration management &amp; IaC \u2014 Ansible, Packer, Terraform for environment build and image baking.</li> </ul>"},{"location":"phase-2/cloud-computing/11_cloud_migration/#key-risks-mitigations","title":"Key risks &amp; mitigations","text":"<ul> <li>Downtime &amp; data loss<ul> <li>Risk: inconsistent or long cutover windows.  </li> <li>Mitigation: use continuous replication (agents), schedule maintenance windows, perform final delta sync and validation.</li> </ul> </li> <li>Compatibility &amp; driver issues<ul> <li>Risk: OS or hardware drivers on physical servers may not work in cloud images.  </li> <li>Mitigation: test on small pilot VMs; use generic drivers; consider reinstallation of ephemeral drivers.</li> </ul> </li> <li>Licensing &amp; compliance<ul> <li>Risk: software licenses may not transfer or may incur extra cost.  </li> <li>Mitigation: verify license portability and cloud licensing terms early.</li> </ul> </li> <li>Performance surprises<ul> <li>Risk: wrong instance sizing leads to poor performance or cost blowouts.  </li> <li>Mitigation: benchmark workloads; start with conservative sizes and right-size after monitoring.</li> </ul> </li> <li>Network &amp; security differences<ul> <li>Risk: IPs, firewall rules, IAM, and DNS differ in cloud.  </li> <li>Mitigation: design VPC/subnet mapping, security groups, and IAM roles; update DNS and firewall rules in runbook.</li> </ul> </li> <li>Cost overruns<ul> <li>Risk: unexpected egress, reserved instance misplanning, or persistent oversized instances.  </li> <li>Mitigation: enable cost monitoring, tagging, and budget alerts; use spot/reserved sizing where appropriate.</li> </ul> </li> </ul>"},{"location":"phase-2/cloud-computing/11_cloud_migration/#practical-planning-checklist-concise","title":"Practical planning checklist (concise)","text":"<ol> <li>Discovery &amp; inventory<ul> <li>Identify OS, apps, dependencies, storage, IPs, backup windows, and RTO/RPO needs.</li> </ul> </li> <li>Classify workloads<ul> <li>Map criticality and pick migration approach per workload (rehost / replatform / refactor).</li> </ul> </li> <li>Proof of Concept (PoC)<ul> <li>Migrate one non-critical server and validate functionality and performance.</li> </ul> </li> <li>Network &amp; security design<ul> <li>Design VPC layout, subnets, routing, NAT, and security groups; map firewall rules.</li> </ul> </li> <li>Data transfer strategy<ul> <li>Choose online replication, DataSync, or physical shipment for bulk data.</li> </ul> </li> <li>Cutover plan &amp; rollback<ul> <li>Define final sync steps, DNS swap, verification checks, and rollback steps if validation fails.</li> </ul> </li> <li>Testing &amp; validation<ul> <li>Functional tests, performance tests, security scans, and a runbook rehearsal (tabletop or partial drill).</li> </ul> </li> <li>Automation &amp; repeatability<ul> <li>Use scripts/IaC for deployments, configuration management for post-migration state.</li> </ul> </li> <li>Cost &amp; license review<ul> <li>Estimate ongoing costs, optimize instance types and storage classes, confirm license terms.</li> </ul> </li> <li>Cleanup &amp; optimization<ul> <li>Post-migration, decommission on-prem resources and right-size cloud resources.</li> </ul> </li> </ol>"},{"location":"phase-2/cloud-computing/11_cloud_migration/#cutover-rollback-essentials","title":"Cutover &amp; rollback essentials","text":"<ul> <li>Final sync: stop writes or use delta replication to ensure consistent data.  </li> <li>DNS &amp; traffic switch: plan TTLs and rollback DNS entries.  </li> <li>Smoke tests: scripted checks to validate service health post-cutover.  </li> <li>Rollback triggers: predefined failure criteria (e.g., &gt;X% error rate) and procedures to revert traffic.</li> </ul>"},{"location":"phase-2/cloud-computing/11_cloud_migration/#are-organisations-doing-this-at-scale","title":"Are organisations doing this at scale?","text":"<ul> <li>Yes \u2014 many enterprises run multi-wave migration programs (hundreds to thousands of servers). Typical pattern:<ul> <li>Start with low-risk apps \u2192 migrate similar workloads in waves \u2192 automate and accelerate subsequent waves.  </li> <li>Use professional services or migration tools for complex, high-criticality systems.  </li> <li>Mature organisations move beyond lift-and-shift to replatform/refactor where business value justifies effort.</li> </ul> </li> </ul>"},{"location":"phase-2/cloud-computing/11_cloud_migration/#validation-success-metrics-short","title":"Validation &amp; success metrics (short)","text":"<ul> <li>Functional correctness \u2014 app behaves as expected.  </li> <li>Performance parity \u2014 latency/throughput meets SLA.  </li> <li>RTO/RPO met \u2014 target recovery metrics satisfied.  </li> <li>Cost target \u2014 operating cost in cloud matches projected model.  </li> <li>Security &amp; compliance \u2014 scans and audits pass.</li> </ul>"},{"location":"phase-2/cloud-computing/11_cloud_migration/#short-summary","title":"Short summary","text":"<p>Physical-to-cloud migration is a pragmatic blend of technical, process and business decisions. Pick the right migration pattern per workload, plan carefully (discovery, PoC, cutover), mitigate compatibility/licenses/cost risks, and validate through tests. For large-scale programs, automation, repeatable tooling and phased waves are essential to succeed without disrupting business.</p>"},{"location":"phase-2/cloud-computing/12_monitoring/","title":"Monitoring, Logging &amp; Cloud Resilience","text":"<p>Learning Objectives</p> <ul> <li>Explain the role of centralized logging in IT infrastructure.</li> <li>Compare monitoring solutions: Nagios vs. Prometheus.</li> <li>Identify performance bottlenecks in data centers.</li> <li>Understand cloud-native resilience: auto-scaling, self-healing, and zero-downtime updates.</li> <li>Analyze a real-world cloud-enabled data center case study.</li> </ul>"},{"location":"phase-2/cloud-computing/12_monitoring/#centralized-logging","title":"Centralized Logging","text":"<ul> <li>Definition: Collecting logs from multiple servers, applications, and devices into a single platform.</li> <li> <p>Why it matters:</p> <ul> <li>Faster troubleshooting.</li> <li>Security auditing &amp; compliance (PCI-DSS, HIPAA).</li> <li>Capacity planning &amp; trend analysis.</li> </ul> </li> <li> <p>Tools:</p> <ul> <li>ELK Stack (Elasticsearch, Logstash, Kibana).</li> <li>Fluentd/Fluent Bit for lightweight log forwarding.</li> <li>Cloud-native: AWS CloudWatch Logs, Azure Monitor.</li> </ul> </li> </ul> <p></p> <p>Got it \u2014 I\u2019ll expand your \u201cMonitoring with Nagios\u201d section into a more complete, syllabus-aligned theory note. Here\u2019s the enriched version in Markdown:</p>"},{"location":"phase-2/cloud-computing/12_monitoring/#monitoring-with-nagios","title":"Monitoring with Nagios","text":""},{"location":"phase-2/cloud-computing/12_monitoring/#nagios-overview","title":"Nagios Overview","text":"<p>Nagios is one of the most widely adopted open-source IT infrastructure monitoring tools. It provides proactive monitoring of systems, applications, services, and business processes. Administrators use Nagios to detect and resolve IT infrastructure problems before they affect critical business processes.</p> <p>Architecture:</p> <ul> <li>Nagios Core: The main monitoring engine, responsible for scheduling checks, executing plugins, and handling alerts.</li> <li>Plugins: Small executables or scripts that perform actual monitoring tasks (e.g., check CPU load, memory usage, disk space, service uptime).</li> <li>Add-ons: Extensions such as Nagios XI (commercial GUI and enterprise features) and visualization plugins.</li> <li>Agent-based Monitoring: Using agents like NRPE (Nagios Remote Plugin Executor) for Linux/Unix or NSClient++ for Windows to run checks locally.</li> <li>Agentless Monitoring: Uses standard protocols like SNMP, SSH, or WMI to monitor without installing agents.</li> </ul> <p>Key Capabilities:</p> <ul> <li>Monitors host availability (up/down), services, network devices, and applications.</li> <li>Supports notification via email, SMS, Slack, or ticketing system integration.</li> <li>Enables escalation policies to ensure critical issues are addressed quickly.</li> </ul>"},{"location":"phase-2/cloud-computing/12_monitoring/#strengths-of-nagios","title":"Strengths of Nagios","text":"<ul> <li>Mature Ecosystem: With over 20 years in production use, Nagios has a proven track record in enterprise IT.</li> <li>Extensible via Plugins: Thousands of community and official plugins exist for virtually every system, database, and application.</li> <li>Threshold-Based Alerts: Simple yet powerful \u2014 define critical and warning levels for metrics (e.g., CPU &gt; 90%).</li> <li>Integration-Friendly: Works with tools like Grafana, Prometheus exporters, and DevOps pipelines for hybrid monitoring.</li> <li>Lightweight &amp; Efficient: Minimal resource footprint on monitoring nodes.</li> </ul>"},{"location":"phase-2/cloud-computing/12_monitoring/#limitations-of-nagios","title":"Limitations of Nagios","text":"<ul> <li>Complex Configuration: Initial setup requires editing multiple config files (hosts, services, commands). YAML/JSON-based modern tools are easier.</li> <li>Limited Visualization: Core Nagios provides basic web UI; modern dashboards require add-ons like Nagios XI or Grafana.</li> <li>Scaling Challenges: Performance bottlenecks when monitoring thousands of hosts without careful tuning.</li> <li>Static Configs: Dynamic cloud-native environments (Kubernetes, auto-scaling clusters) need additional integrations to work smoothly.</li> <li>Maintenance Effort: Manual updates to configs and plugins can become tedious in large enterprises.</li> </ul> <p>Exam/Interview Tip</p> <p>Expect questions like \u201cHow does Nagios differ from Prometheus?\u201d (Answer: Nagios is check-based and threshold-driven, while Prometheus is time-series &amp; pull-based, better suited for cloud-native metrics).</p> <p>Nagios Dashboard</p> <p></p>"},{"location":"phase-2/cloud-computing/12_monitoring/#prometheus-next-generation-nms","title":"Prometheus \u2013 Next Generation NMS","text":""},{"location":"phase-2/cloud-computing/12_monitoring/#key-concepts","title":"Key Concepts","text":"<p>Prometheus is an open-source monitoring and alerting toolkit designed for modern, dynamic, cloud-native environments. Unlike traditional monitoring tools, Prometheus focuses on metrics rather than logs or events, and stores them as time-series data.</p> <p>Time-Series Metrics Collection:</p> <ul> <li>Each metric is stored with a timestamp and optional labels (key-value pairs) for context (e.g., <code>http_requests_total{method=\"GET\",status=\"200\"}</code>).</li> <li>Enables detailed filtering, aggregation, and slicing of data.</li> </ul> <p>Pull-Based Model:</p> <ul> <li>Prometheus scrapes metrics from targets at regular intervals.</li> <li>Targets expose an HTTP endpoint (usually <code>/metrics</code>) via exporters (e.g., Node Exporter for Linux, cAdvisor for containers, Blackbox Exporter for endpoints).</li> <li>This model simplifies security and scaling compared to push-based monitoring.</li> </ul> <p>PromQL (Prometheus Query Language):</p> <ul> <li>A powerful query language for extracting and manipulating time-series data.</li> <li> <p>Examples:</p> <p><pre><code># CPU usage above 80% in last 5 minutes\navg(rate(node_cpu_seconds_total{mode=\"user\"}[5m])) &gt; 0.8\n</code></pre>   * Enables dashboards, alerts, and ad-hoc troubleshooting.</p> </li> </ul>"},{"location":"phase-2/cloud-computing/12_monitoring/#ecosystem","title":"Ecosystem","text":"<p>Prometheus is rarely used alone; it integrates with a rich ecosystem of tools:</p> <p>Alertmanager: Handles alerts generated by Prometheus rules.</p> <ul> <li>Features: deduplication, grouping, silencing, routing to email, PagerDuty, Slack, etc.</li> </ul> <p>Grafana: Visualization platform often paired with Prometheus.</p> <ul> <li>Provides rich dashboards for real-time monitoring.</li> </ul> <p>Exporters: Components that expose metrics in Prometheus format (over 500 exist).</p> <ul> <li>Examples: MySQL exporter, JMX exporter (Java apps), SNMP exporter.</li> </ul> <p>Remote Storage: Prometheus itself stores data locally (short-term). For long-term retention, integrates with Thanos, Cortex, or VictoriaMetrics.</p>"},{"location":"phase-2/cloud-computing/12_monitoring/#why-next-gen","title":"Why \u201cNext Gen\u201d?","text":"<p>Prometheus is considered a next-generation network and systems monitoring (NMS) solution because it overcomes the static, threshold-based approach of legacy tools like Nagios:</p> <p>Cloud-Native &amp; Container-Friendly:</p> <ul> <li>Deep integration with Kubernetes (auto-discovers services, pods, and nodes).</li> <li>Supports microservices environments where IPs and services change frequently.</li> </ul> <p>Dynamic Environments:</p> <ul> <li>Works seamlessly with auto-scaling, ephemeral workloads, and serverless environments.</li> <li>Eliminates manual configuration of hosts/services.</li> </ul> <p>Scalability:</p> <ul> <li>Can handle millions of metrics per second when used with horizontal scaling solutions (e.g., Thanos).</li> </ul> <p>Observability Focused:</p> <ul> <li>Prometheus aligns with modern observability practices (metrics, logs, traces), not just monitoring.</li> <li>PromQL enables real-time troubleshooting beyond static alerts.</li> </ul> <p>Exam Tips</p> <p>Be ready to contrast Prometheus with Nagios:</p> <ul> <li>Nagios = event/threshold-based checks, static configs, limited cloud integration.</li> <li>Prometheus = time-series metrics, dynamic discovery, Kubernetes-native, powerful queries.</li> </ul>"},{"location":"phase-2/cloud-computing/12_monitoring/#identifying-bottlenecks","title":"Identifying Bottlenecks","text":"<p>Types:</p> <ul> <li>CPU: High utilization, poor thread management.</li> <li>Memory: Leaks, insufficient RAM.</li> <li>Disk/Storage: IOPS saturation, slow reads/writes.</li> <li>Network: Latency, packet loss, bandwidth limits.</li> <li>Application-level: Inefficient code, poor DB queries.</li> </ul> <p>Approach:</p> <ul> <li>Monitor KPIs (CPU %, latency, throughput).</li> <li>Use APM (Application Performance Monitoring) tools.</li> </ul>"},{"location":"phase-2/cloud-computing/12_monitoring/#auto-scaling-auto-rebuilding","title":"Auto-Scaling &amp; Auto-Rebuilding","text":"<p>Auto-Scaling:</p> <ul> <li>Horizontal scaling: Add/remove instances (e.g., AWS Auto Scaling Groups).</li> <li>Vertical scaling: Increase resources of existing server.</li> </ul> <p>Auto-Rebuilding:</p> <ul> <li>Replace failed nodes automatically.</li> <li>Examples: AWS ASG + health checks, Kubernetes ReplicaSets.</li> </ul>"},{"location":"phase-2/cloud-computing/12_monitoring/#updating-servers-without-downtime","title":"Updating Servers Without Downtime","text":"<p>Traditional problem: Updating services means restarts \u2192 downtime.</p> <p>Modern strategies:</p> <ul> <li>Blue-Green Deployment: Maintain two environments; switch traffic.</li> <li>Rolling Updates: Update nodes one at a time.</li> <li>Canary Releases: Test update on a small subset of users.</li> </ul>"},{"location":"phase-2/cloud-computing/12_monitoring/#auto-healing","title":"Auto-Healing","text":"<p>Definition: Automatic detection and recovery of unhealthy resources.</p> <p>Examples:</p> <ul> <li>AWS ELB terminates and replaces failed EC2 instances.</li> <li>Kubernetes reschedules failed pods.</li> </ul> <p>Benefits:</p> <ul> <li>Improves resilience.</li> <li>Reduces manual intervention.</li> </ul>"},{"location":"phase-2/cloud-computing/12_monitoring/#cloud-enabled-data-center-case-study","title":"Cloud-Enabled Data Center Case Study","text":"<p>Scenario \u2013 TechOps Inc.</p> <ul> <li>Migrated from legacy monitoring (Nagios only) \u2192 Hybrid approach (Prometheus + Cloud-native tools).</li> <li> <p>Outcomes:</p> <ul> <li>Reduced downtime from 4 hrs/month \u2192 &lt;30 mins/month.</li> <li>Auto-scaling allowed handling traffic spikes (50% savings in infra cost).</li> <li>Centralized logging improved incident response time by 40%.</li> </ul> </li> </ul>"},{"location":"phase-2/cloud-computing/lab10/","title":"Lab 10: Open Stack Demo","text":""},{"location":"phase-2/cloud-computing/lab11/","title":"\ud83e\uddea Lab 11: AWS Hands-On Lab","text":""},{"location":"phase-2/cloud-computing/lab11/#objectives","title":"\ud83c\udfaf Objectives","text":"<p>In this lab you will: - Create a free AWS account. - Launch your first EC2 instance. - Create a Lambda function. - Set up an S3 bucket for storage. - Design a VPC with public and private subnets. - Deploy instances in both subnets and enable communication.  </p>"},{"location":"phase-2/cloud-computing/lab11/#prerequisites","title":"\ud83d\udd11 Prerequisites","text":"<ul> <li>Laptop with internet access.  </li> <li>AWS Free Tier account (credit/debit card required for signup).  </li> <li>Basic Linux commands knowledge (<code>yum</code>, <code>apt</code>, <code>curl</code>).  </li> </ul>"},{"location":"phase-2/cloud-computing/lab11/#1-create-free-aws-account","title":"1. Create Free AWS Account","text":"<ol> <li>Go to https://aws.amazon.com/free.  </li> <li>Click Create an AWS Account.  </li> <li>Enter email, password, and choose an account name.  </li> <li>Add contact details and payment method (international debit/credit card works).  </li> <li>Verify phone number using OTP.  </li> <li>Select Free Tier plan.  </li> <li>Log in to AWS Management Console.  </li> </ol> <p>\u2705 Checkpoint: You should see the AWS console dashboard as below.</p> <p></p>"},{"location":"phase-2/cloud-computing/lab11/#2-launch-an-ec2-instance","title":"2. Launch an EC2 Instance","text":"<ol> <li>From the AWS console, search for EC2.  </li> <li>Click Launch Instance \u2192 give it a name (e.g., <code>ditiss-ec2-test</code>).  </li> <li>Choose Amazon Linux 2 AMI (Free Tier eligible).  </li> <li>Select t2.micro (Free Tier).  </li> <li>Create a new key pair \u2192 download <code>.pem</code> file.  </li> <li>Network settings: allow SSH (22) and HTTP (80) from My IP.  </li> <li>Launch instance.  </li> <li> <p>Convert you <code>pem</code> file to ppk to access from Windows Putty</p> <ul> <li>Download PuTTY &amp; PuTTYgen from https://www.putty.org/</li> <li>Open PuTTYgen by searching \"PuTTYgen\" in you search bar</li> <li>Click on <code>Load</code> button</li> <li>Select your downloaded <code>pem</code> file from step 5 above</li> <li>Click on <code>Save Private key</code> button (If prompted to save without paraphase, click Yes/Okay)</li> <li>Give it a name which is easy to remember and save it to a known location</li> <li>This will output a <code>.ppk</code> file which we will use next.</li> </ul> </li> <li> <p>Connect via Putty:</p> <ul> <li>Open PuTTY by searching \"PuTTY\" in you search bar</li> <li>On the left side in \"Category\" list, under Connection, expand the <code>SSH</code> option by clicking <code>+</code> sign</li> <li>Then expand the <code>Auth</code> section by clicking <code>+</code> sign</li> <li>Click on <code>Credentials</code></li> <li>Click on <code>Browse</code> on the Private key file for authentication: field (The first one from the top)</li> <li>Browse the <code>.ppk</code> file you exported in Step 8 above and click <code>Open</code></li> <li>Then again on the left side list (Category) scroll to the top and click on <code>Session</code></li> <li>In the <code>Host Name (or IP Address)</code> enter the name or Public IP of your EC2 instance<ul> <li>To get the name of your EC2 instance, click on EC2 instance ID, then copy the Public DNS</li> <li>To get the IP of your EC2 instance, click on EC2 instance ID, then copy the Public IPv4 address</li> </ul> </li> <li>Click on <code>Open</code></li> <li>Accept the certificate</li> <li>Once the terminal opens up, enter user name as ec2-user</li> <li>You will be logged in to your newly deployed virtual machine in AWS public cloud</li> </ul> </li> </ol> <p>\u2705 Checkpoint: You can log in to your EC2 instance.  </p> <p>Video Guide</p>"},{"location":"phase-2/cloud-computing/lab11/#3-create-an-s3-bucket","title":"3. Create an S3 Bucket","text":"<ol> <li>Search for S3 in console.  </li> <li>Click Create Bucket \u2192 name: <code>ditiss-lab-bucket-&lt;yourname&gt;</code>.  </li> <li>Choose region (same as EC2).  </li> <li>Block all public access (recommended).  </li> <li>Upload a sample file (text/image).  </li> <li>Download file back from console to confirm.  </li> </ol> <p>\u2705 Checkpoint: File successfully uploaded and downloaded.  </p> <p>Video Guide</p>"},{"location":"phase-2/cloud-computing/lab11/#4-create-a-lambda-function","title":"4. Create a Lambda Function","text":"<ol> <li>In the console, search for Lambda.  </li> <li>Click Create Function \u2192 Author from scratch.  </li> <li>Function name: <code>ditiss-lambda-hello</code>.  </li> <li>Runtime: Python 3.x.  </li> <li>Use default execution role.  </li> <li> <p>Paste this code:</p> <pre><code>def lambda_handler(event, context):\n    return {\n        'statusCode': 200,\n        'body': 'Hello from DITISS Lambda!'\n    }\n</code></pre> </li> <li> <p>Deploy and test with a sample event.  </p> </li> </ol> <p>\u2705 Checkpoint: Output should return <code>\"Hello from DITISS Lambda!\"</code>.  </p> <p>Video Guide</p>"},{"location":"phase-2/cloud-computing/lab11/#5-create-a-new-vpc-with-public-private-subnets","title":"5. Create a New VPC with Public &amp; Private Subnets","text":"<p>We\u2019ll design a custom VPC called <code>ditiss-lab</code>.  </p>"},{"location":"phase-2/cloud-computing/lab11/#step-1-create-vpc","title":"Step 1: Create VPC","text":"<ol> <li>Go to VPC in console \u2192 Create VPC.  </li> <li>Resources to create: <code>VPC Only</code></li> <li>Name: <code>ditiss-lab</code>.</li> <li>IPv4 CIDR block: <code>IPv4 CIDR manual input</code></li> <li>IPv4: <code>172.20.0.0/16</code>.  </li> <li>Leave all other settings as defaul</li> <li>Click on <code>Create VPC</code> button.  </li> </ol>"},{"location":"phase-2/cloud-computing/lab11/#step-2-create-subnets","title":"Step 2: Create Subnets","text":"<ol> <li>On the VPC Dashboard page, on the right side under <code>Virtual Private Cloud</code>, click on <code>Subnets</code></li> <li>Click on <code>Create Subnet</code></li> <li>VPC ID: Select the subnet which has <code>ditiss-lab</code> as suffix</li> <li>Public Subnet: <ul> <li>Subnet Name: <code>public-subnet</code>.</li> <li>Availability Zone: <code>No Preference</code></li> <li>IPv4 VPC CIDR block: Selected by default <code>172.20.0.0/16</code></li> <li>IPv4 subnet CIDR block: <code>172.20.5.0/24</code>.</li> </ul> </li> <li>Private Subnet:  <ul> <li>Click on <code>Add new subnet</code> button</li> <li>Subnet Name: <code>private-subnet</code>.</li> <li>IPv4 VPC CIDR block: Selected by default <code>172.20.0.0/16</code></li> <li>IPv4 subnet CIDR block: <code>172.20.10.0/24</code>.</li> </ul> </li> <li>Click on <code>Create Subnet</code> button</li> </ol>"},{"location":"phase-2/cloud-computing/lab11/#step-3-internet-gateway-igw","title":"Step 3: Internet Gateway (IGW)","text":"<ol> <li>On the VPC Dashboard page, on the right side under <code>Virtual Private Cloud</code>, click on <code>Internet Gateways</code></li> <li>Click on <code>Creat Internet gateway</code></li> <li>Name Tag: <code>igw-dittis-lab</code> </li> <li>Click on <code>Create Internet Gateway</code></li> <li>One the homepage of <code>Internet gateways</code>, select your newly created igw-dittis-lab</li> <li>Click on <code>Action</code> button on the top right side</li> <li>Select <code>Attach to VPC</code></li> <li>Select <code>ditiss-lab</code></li> <li>Click on <code>Attach internet gateway</code></li> </ol>"},{"location":"phase-2/cloud-computing/lab11/#step-4-create-route-tables","title":"Step 4: Create Route Tables","text":"<ol> <li>On the VPC Dashboard page, on the right side under <code>Virtual Private Cloud</code>, click on <code>Route Tables</code></li> <li>Click on <code>Create Route Tables</code></li> <li>Name: <code>rtb-dittis-lab</code></li> <li>VPC: <code>ditiss-lab</code></li> <li>Click on <code>Create route table</code></li> <li>On the Route tables Dashboard, select the newly created route table <code>rtb-dittis-lab</code> and click on <code>Action</code> button on top right side.</li> <li>Click on <code>Edit Routes</code></li> <li>Click on <code>Add Route</code><ul> <li>Destination: <code>0.0.0.0/0</code></li> <li>Target: <code>Internet Gateway</code><ul> <li>Select <code>igw-dittis-lab</code></li> </ul> </li> <li>Click on Save Changes</li> </ul> </li> </ol>"},{"location":"phase-2/cloud-computing/lab11/#step-5-change-settings-of-public-subnet","title":"Step 5: Change settings of public-subnet","text":"<ol> <li>On the VPC Dashboard page, on the right side under <code>Virtual Private Cloud</code>, click on <code>Subnets</code></li> <li>Select <code>public-subnet</code></li> <li>Click on <code>Actions</code> button on top right side</li> <li>Click on <code>Edit subnet settings</code></li> <li>Select/Check the <code>Enable auto-assign public IPv4 address</code> in Auto-assign IP settings window</li> <li>Click on <code>Save</code></li> <li>Again, on Subnets dashboard, select <code>public-subnet</code> and click on <code>Actions</code> button on top right side</li> <li>The select <code>Edit route table association</code></li> <li>Route Table ID: Select <code>rtb-ditiss-lab</code></li> <li>Click on <code>Save</code></li> </ol>"},{"location":"phase-2/cloud-computing/lab11/#step-6-change-settings-of-private-subnet","title":"Step 6: Change settings of private-subnet","text":"<p>Alert</p> <p>This setting is only for demo purposes, in real world, a private subnet should never have a public IP assigned. Instead we use a Jump/Bastion Host which acts as a jump betwen internet and private subnets.</p> <ol> <li>On the VPC Dashboard page, on the right side under <code>Virtual Private Cloud</code>, click on <code>Subnets</code></li> <li>Select <code>private-subnet</code></li> <li>Click on <code>Actions</code> button on top right side</li> <li>Click on <code>Edit subnet settings</code></li> <li>Select/Check the <code>Enable auto-assign public IPv4 address</code> in Auto-assign IP settings window</li> <li>Click on <code>Save</code></li> <li>Again, on Subnets dashboard, select <code>public-subnet</code> and click on <code>Actions</code> button on top right side</li> <li>The select <code>Edit route table association</code></li> <li>Route Table ID: Select <code>rtb-ditiss-lab</code></li> <li>Click on <code>Save</code></li> </ol>"},{"location":"phase-2/cloud-computing/lab11/#step-7-create-security-groups","title":"Step 7: Create Security Groups","text":"<p>Info</p> <p>Security Groups are integral part of any VPC. This security groups are the network firewall rules which controls what traffic to flow into the hosts/machines inside those security groups. Essentailly we tell the virtual machines which networks and ports you can access or cannot access.</p> <ol> <li>On the VPC Dashboard page, on the right side under <code>Security</code>, click on <code>Security Groups</code></li> <li>Click on <code>Create security group</code> button on top right side</li> <li> <p>Enter following details</p> <ul> <li>Security group name: <code>sg-public</code></li> <li>Description: <code>public ssh &amp; http access</code></li> <li>VPC: Select <code>ditiss-lab</code></li> </ul> </li> <li> <p>Inside Inbound rules tab, click on <code>Add rule</code></p> <ul> <li>Type: <code>SSH</code></li> <li>Source: <code>Custom</code></li> <li>IP Range: <code>0.0.0.0/0</code></li> <li>Again click on Add rule</li> <li>Type: <code>HTTP</code></li> <li>Source: <code>Custom</code></li> <li>IP Range: <code>0.0.0.0/0</code></li> </ul> </li> <li> <p>Keep other settings as default</p> </li> <li>Click on <code>Create security group</code></li> </ol> <p>Repeat the same steps again for creating one more security group for private subnet</p> <ol> <li>On the VPC Dashboard page, on the right side under <code>Security</code>, click on <code>Security Groups</code></li> <li>Click on <code>Create security group</code> button on top right side</li> <li> <p>Enter following details</p> <ul> <li>Security group name: <code>sg-private</code></li> <li>Description: <code>private ssh &amp; http access</code></li> <li>VPC: Select <code>ditiss-lab</code></li> </ul> </li> <li> <p>Inside Inbound rules tab, click on <code>Add rule</code></p> <ul> <li>Type: <code>SSH</code></li> <li>Source: <code>Custom</code></li> <li>IP Range: <code>0.0.0.0/0</code></li> <li>Again click on Add rule</li> <li>Type: <code>HTTP</code></li> <li>Source: <code>Custom</code></li> <li>IP Range: <code>172.20.0.0/0</code></li> </ul> </li> <li> <p>Keep other settings as default</p> </li> <li>Click on <code>Create security group</code></li> </ol>"},{"location":"phase-2/cloud-computing/lab11/#step-8-create-instances","title":"Step 8: Create Instances","text":"<ol> <li>In search bar, search for EC2</li> <li> <p>Click on Launch Instances</p> </li> <li> <p>Public Instance:  </p> <ul> <li>Name: <code>public-instance</code>.  </li> <li>Choose Amazon Linux 2 AMI (Free Tier eligible).  </li> <li>Select t3.micro (Free Tier). </li> <li>Use the same key-pair used for creating inital virtual machine at the beginning or create new one as per your prefrence.</li> <li> <p>In the Network Settings:</p> <ul> <li>Click on Edit </li> <li>VPC: Select the <code>ditiss-lab</code></li> <li>Subnet: <code>public-subnet</code></li> <li>Firewall (security groups): <code>Select existing security groups</code></li> <li>Select <code>sg-public</code> from the dropdown.</li> </ul> </li> <li> <p>Keep other settings as default  </p> </li> <li>Click on Launch Instance </li> </ul> </li> <li> <p>Private Instance:  </p> <ul> <li>Name: <code>private-instance</code>.  </li> <li>Choose Amazon Linux 2 AMI (Free Tier eligible).  </li> <li>Select t3.micro (Free Tier). </li> <li>Use the same key-pair used for creating inital virtual machine at the beginning or create new one as per your prefrence.</li> <li> <p>In the Network Settings:</p> <ul> <li>Click on Edit </li> <li>VPC: Select the <code>ditiss-lab</code></li> <li>Subnet: <code>private-subnet</code></li> <li>Firewall (security groups): <code>Select existing security groups</code></li> <li>Select <code>sg-private</code> from the dropdown.</li> </ul> </li> <li> <p>Keep other settings as default  </p> </li> <li>Click on Launch Instance </li> </ul> </li> </ol>"},{"location":"phase-2/cloud-computing/lab11/#step-9-install-apache-httpd-on-private-instance","title":"Step 9: Install Apache (httpd) on Private Instance","text":"<ol> <li>SSH into private-instance.  </li> <li> <p>Install Apache on private-instance:</p> <pre><code>sudo yum update -y\nsudo yum install -y httpd\nsudo systemctl start httpd\nsudo systemctl enable httpd\n</code></pre> </li> <li> <p>Create a test page:</p> <pre><code>echo \"Hello from Private Instance in DITISS Lab!\" | sudo tee /var/www/html/index.html\n</code></pre> </li> </ol>"},{"location":"phase-2/cloud-computing/lab11/#step-10-test-with-curl-from-pubic-instance","title":"Step 10: Test with <code>curl</code> from pubic-instance","text":"<ol> <li>SSH into public-instance using public IPv4</li> <li> <p>On public-instance, run:</p> <pre><code>curl http://&lt;Private-Instance-Private-IP&gt;\n</code></pre> </li> </ol> <p>\u2705 Checkpoint: You should see <code>\"Hello from Private Instance in DITISS Lab!\"</code>.  </p> <p>Video Guide</p>"},{"location":"phase-2/cloud-computing/lab11/#key-takeaways","title":"\ud83e\udded Key Takeaways","text":"<ul> <li>You created and explored core AWS services (EC2, Lambda, S3, VPC).  </li> <li>You designed a custom network with public/private subnets.  </li> <li>You tested private-to-public connectivity using <code>curl</code>.  </li> </ul>"},{"location":"phase-2/cloud-computing/lab12/","title":"Lab: Bootstrapping Nodes with Chef Server","text":""},{"location":"phase-2/cloud-computing/lab12/#objectives","title":"Objectives","text":"<ul> <li>Launch and configure two EC2 instances in AWS and bootstrap them to a Chef Server.  </li> <li>Apply the <code>web</code> role to one node and the <code>app</code> role to another.  </li> <li>Install Chef Client on a VirtualBox VM and bootstrap it with a chosen role.  </li> </ul> Part 1 \u2014 Bootstrapping EC2 Instances on AWSPart 2 \u2014 Bootstrapping a VirtualBox VM"},{"location":"phase-2/cloud-computing/lab12/#step-1-launch-two-ec2-instances","title":"Step 1: Launch two EC2 instances","text":"<ol> <li>Log in to your AWS account.  </li> <li>Launch two EC2 instances:<ul> <li>AMI: Ubuntu 22.04 LTS (or Amazon Linux 2).  </li> <li>Instance type: <code>t2.micro</code> (Free Tier eligible).  </li> <li>Key pair: create or use an existing <code>.pem</code> key.  </li> <li>Security group: allow SSH (22) and HTTP (80).  </li> </ul> </li> <li>Name the instances:<ul> <li><code>web-node</code> </li> <li><code>app-node</code> </li> </ul> </li> </ol>"},{"location":"phase-2/cloud-computing/lab12/#step-2-install-chef-client","title":"Step 2: Install Chef Client","text":"<p>SSH into each node and install Chef Client:</p> <pre><code>curl -L https://omnitruck.chef.io/install.sh | sudo bash -s -- -P chef -c stable\n</code></pre> <p>Verify installation:</p> <pre><code>chef-client --version\n</code></pre>"},{"location":"phase-2/cloud-computing/lab12/#step-3-download-the-organization-validator-key","title":"Step 3: Download the organization validator key","text":"<p>The instructor has shared a validator PEM (<code>ditissorg-validator.pem</code>) via S3. Download it on each node and save it as <code>/etc/chef/validation.pem</code>:</p> <pre><code># replace URL with the one provided by instructor\ncurl -o validation.pem \"https://ditiss-lab-bucket-sid3315.s3.eu-north-1.amazonaws.com/ditissorg-validator.pem\"\n</code></pre> <pre><code>sudo mkdir -p /etc/chef\nsudo mv validation.pem /etc/chef/validation.pem\nsudo chmod 600 /etc/chef/validation.pem\n</code></pre>"},{"location":"phase-2/cloud-computing/lab12/#step-4-accept-chef-licenses","title":"Step 4: Accept Chef licenses","text":"<p>Chef requires license acceptance. Create the accepted license files:</p> <pre><code>sudo mkdir -p /etc/chef/accepted_licenses\necho &gt; /etc/chef/accepted_licenses/chef_infra_client\necho &gt; /etc/chef/accepted_licenses/inspec\nsudo chmod 644 /etc/chef/accepted_licenses/*\n</code></pre>"},{"location":"phase-2/cloud-computing/lab12/#step-5-create-chef-client-configuration","title":"Step 5: Create Chef client configuration","text":"<p>Create <code>/etc/chef/client.rb</code>. Replace <code>&lt;CHEF_SERVER_PUBLIC_DNS&gt;</code> with the DNS of the instructor\u2019s Chef Server.</p> <pre><code>sudo tee /etc/chef/client.rb &lt;&lt;EOF\nlog_level        :info\nlog_location     STDOUT\nchef_server_url  'https://ec2-13-49-73-88.eu-north-1.compute.amazonaws.com/organizations/ditissorg'\nvalidation_client_name 'ditissorg-validator'\nnode_name        'web-node'\nssl_verify_mode  :verify_none\nEOF\n</code></pre> <p>On the <code>app-node</code>, change <code>node_name</code> to <code>app-node</code>.</p>"},{"location":"phase-2/cloud-computing/lab12/#step-6-register-node-with-chef-server","title":"Step 6: Register node with Chef Server","text":"<p>Run once on each node to register with Chef Server:</p> <pre><code>sudo chef-client\n</code></pre>"},{"location":"phase-2/cloud-computing/lab12/#step-7-execute-the-role","title":"Step 7: Execute the role","text":"<p>On each node, run chef-client with the appropriate role.</p> <p>On <code>web-node</code>:</p> <pre><code>sudo chef-client -o 'role[web]'\n</code></pre> <p>On <code>app-node</code>:</p> <pre><code>sudo chef-client -o 'role[app]'\n</code></pre>"},{"location":"phase-2/cloud-computing/lab12/#step-8-verify-results","title":"Step 8: Verify results","text":"<ul> <li>On <code>web-node</code>:</li> </ul> <pre><code>curl http://localhost\n</code></pre> <p>Should display Apache test page.</p> <ul> <li>On <code>app-node</code>:</li> </ul> <pre><code>cat /etc/myapp/config.yml\n/opt/myapp/sample-app.sh\n</code></pre>"},{"location":"phase-2/cloud-computing/lab12/#step-1-prepare-the-vm","title":"Step 1: Prepare the VM","text":"<ol> <li>Create a new VirtualBox VM (Ubuntu 22.04 recommended).  </li> <li>Allocate at least 1 vCPU and 1 GB RAM.  </li> <li>Ensure the VM has network access to the Chef Server (bridge networking recommended).  </li> </ol>"},{"location":"phase-2/cloud-computing/lab12/#step-2-install-chef-client_1","title":"Step 2: Install Chef Client","text":"<p>Inside the VM:</p> <pre><code>curl -L https://omnitruck.chef.io/install.sh | sudo bash -s -- -P chef -c stable\n</code></pre>"},{"location":"phase-2/cloud-computing/lab12/#step-3-download-the-validator-key","title":"Step 3: Download the validator key","text":"<p>Download the validator PEM from the instructor\u2019s S3 bucket and save it to <code>/etc/chef/validation.pem</code>:</p> <pre><code>curl -o validation.pem \"https://ditiss-lab-bucket-sid3315.s3.eu-north-1.amazonaws.com/ditissorg-validator.pem\"\n\nsudo mkdir -p /etc/chef\nsudo mv validation.pem /etc/chef/validation.pem\nsudo chmod 600 /etc/chef/validation.pem\n</code></pre>"},{"location":"phase-2/cloud-computing/lab12/#step-4-accept-chef-licenses_1","title":"Step 4: Accept Chef licenses","text":"<pre><code>sudo mkdir -p /etc/chef/accepted_licenses\necho &gt; /etc/chef/accepted_licenses/chef_infra_client\necho &gt; /etc/chef/accepted_licenses/inspec\nsudo chmod 644 /etc/chef/accepted_licenses/*\n</code></pre>"},{"location":"phase-2/cloud-computing/lab12/#step-5-configure-clientrb","title":"Step 5: Configure client.rb","text":"<p>Edit <code>/etc/chef/client.rb</code>:</p> <pre><code>sudo tee /etc/chef/client.rb &lt;&lt;EOF\nlog_level        :info\nlog_location     STDOUT\nchef_server_url  'https://ec2-13-49-73-88.eu-north-1.compute.amazonaws.com/organizations/ditissorg'\nvalidation_client_name 'ditissorg-validator'\nnode_name        'local-vm-node'\nssl_verify_mode  :verify_none\nEOF\n</code></pre>"},{"location":"phase-2/cloud-computing/lab12/#step-6-register-with-chef-server","title":"Step 6: Register with Chef Server","text":"<p>Run once to register:</p> <pre><code>sudo chef-client\n</code></pre>"},{"location":"phase-2/cloud-computing/lab12/#step-7-execute-a-role","title":"Step 7: Execute a role","text":"<p>Pick one role to apply (web or app).</p> <p>For web role:</p> <pre><code>sudo chef-client -o 'role[web]'\n</code></pre> <p>For app role:</p> <pre><code>sudo chef-client -o 'role[app]'\n</code></pre>"},{"location":"phase-2/cloud-computing/lab12/#step-8-verify","title":"Step 8: Verify","text":"<ul> <li>If <code>web</code> role applied: check the Apache page</li> </ul> <pre><code>curl http://localhost\n</code></pre> <ul> <li>If <code>app</code> role applied: check app config and sample script</li> </ul> <pre><code>cat /etc/myapp/config.yml\n/opt/myapp/sample-app.sh\n</code></pre>"},{"location":"phase-2/cloud-computing/lab12/#deliverables","title":"Deliverables","text":"<ul> <li>Screenshot 1: <code>knife node list</code> showing your node registered.</li> <li>Screenshot 2: Output of <code>curl http://&lt;web-node-ip&gt;</code> (web role) or <code>cat /etc/myapp/config.yml</code> (app role).</li> <li>Screenshot 3: VM bootstrap output (<code>chef-client</code> run log).</li> </ul>"},{"location":"phase-2/cloud-computing/lab12/#cleanup","title":"Cleanup","text":"<ul> <li>Terminate AWS instances when finished.</li> <li>Remove validator PEM from nodes (<code>sudo rm /etc/chef/ditissorg-validator.pem</code>) \u2014 they now use their own <code>client.pem</code>.</li> </ul>"},{"location":"phase-2/cloud-computing/lab13/","title":"Lab 13: AWS CLI/SDK Configuration Guide","text":"<p>A comprehensive, step-by-step guide to configure AWS CLI/SDK on your laptop and start using it.</p>"},{"location":"phase-2/cloud-computing/lab13/#step-1-install-aws-cli","title":"Step 1: Install AWS CLI","text":"WindowsmacOSLinux (Amazon Linux)Linux (Ubuntu/Debian) <ol> <li>Download the installer: AWS CLI Download</li> <li>Run the installer:</li> </ol> <p><pre><code>msiexec.exe /i https://awscli.amazonaws.com/AWSCLIV2.msi\n</code></pre> 3. Verify installation:</p> <pre><code>aws --version\n</code></pre> <ol> <li>Download and install:</li> </ol> <p><pre><code>curl \"https://awscli.amazonaws.com/AWSCLIV2.pkg\" -o \"AWSCLIV2.pkg\"\nsudo installer -pkg AWSCLIV2.pkg -target /\n</code></pre> 2. Verify installation:</p> <pre><code>aws --version\n</code></pre> <pre><code>sudo yum -y update\nsudo yum -y install aws-cli\naws --version\n</code></pre> <pre><code>sudo apt update\nsudo apt install -y awscli\naws --version\n</code></pre>"},{"location":"phase-2/cloud-computing/lab13/#step-2-create-aws-access-keys","title":"Step 2: Create AWS Access Keys","text":"<ol> <li>Sign in to AWS Console: AWS Console</li> <li>Navigate to IAM: Search for IAM in the Services menu.</li> <li> <p>Create or select a user:</p> <ul> <li>New user \u2192 Users \u2192 Create user</li> <li>Existing user \u2192 Click the username</li> </ul> </li> <li> <p>Create access keys:</p> <ul> <li>Go to Security credentials tab</li> <li>Click Create access key</li> <li>Choose Command Line Interface (CLI)</li> <li>Save credentials securely (CSV download or copy Access Key ID/Secret Key).</li> </ul> </li> </ol>"},{"location":"phase-2/cloud-computing/lab13/#step-3-configure-aws-cli","title":"Step 3: Configure AWS CLI","text":"<p>Run:</p> <pre><code>aws configure\n</code></pre> <p>Enter the following when prompted:</p> <ul> <li>AWS Access Key ID</li> <li>AWS Secret Access Key</li> <li>Default region name (e.g., <code>us-east-1</code>)</li> <li>Default output format (<code>json</code> recommended)</li> </ul> <p>Example:</p> <pre><code>AWS Access Key ID [None]: AKIAIOSFODNN7EXAMPLE\nAWS Secret Access Key [None]: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\nDefault region name [None]: us-east-1\nDefault output format [None]: json\n</code></pre>"},{"location":"phase-2/cloud-computing/lab13/#step-4-verify-configuration","title":"Step 4: Verify Configuration","text":"<pre><code># Check identity\naws sts get-caller-identity\n\n# List config\naws configure list\n\n# Test with S3\naws s3 ls\n</code></pre>"},{"location":"phase-2/cloud-computing/lab13/#step-5-using-named-profiles-optional","title":"Step 5: Using Named Profiles (Optional)","text":"<p>For multiple AWS accounts:</p> <pre><code># Create a named profile\naws configure --profile myprofile\n\n# Use the profile\naws s3 ls --profile myprofile\n\n# Set default profile\nexport AWS_PROFILE=myprofile\n</code></pre>"},{"location":"phase-2/cloud-computing/lab13/#step-6-basic-aws-cli-usage-examples","title":"Step 6: Basic AWS CLI Usage Examples","text":""},{"location":"phase-2/cloud-computing/lab13/#s3-operations","title":"S3 Operations","text":"<pre><code># List buckets\naws s3 ls\n\n# Create bucket\naws s3 mb s3://my-unique-bucket-name\n\n# Upload file\naws s3 cp myfile.txt s3://my-unique-bucket-name/\n\n# Download file\naws s3 cp s3://my-unique-bucket-name/myfile.txt ./downloaded-file.txt\n</code></pre>"},{"location":"phase-2/cloud-computing/lab13/#ec2-operations","title":"EC2 Operations","text":"<pre><code># List instances\naws ec2 describe-instances\n\n# List available AMIs\naws ec2 describe-images --owners self\n\n# Create key pair\naws ec2 create-key-pair --key-name MyKeyPair\n</code></pre>"},{"location":"phase-2/cloud-computing/lab13/#iam-operations","title":"IAM Operations","text":"<pre><code># List users\naws iam list-users\n\n# List policies\naws iam list-policies --scope Local\n</code></pre>"},{"location":"phase-2/cloud-computing/lab13/#step-7-aws-sdk-setup","title":"Step 7: AWS SDK Setup","text":""},{"location":"phase-2/cloud-computing/lab13/#python-boto3","title":"Python (boto3)","text":"<pre><code>pip install boto3\n</code></pre>"},{"location":"phase-2/cloud-computing/lab13/#nodejs","title":"Node.js","text":"<pre><code>npm install aws-sdk\n</code></pre>"},{"location":"phase-2/cloud-computing/lab13/#java-maven-dependency","title":"Java (Maven dependency)","text":"<pre><code>&lt;dependency&gt;\n  &lt;groupId&gt;software.amazon.awssdk&lt;/groupId&gt;\n  &lt;artifactId&gt;aws-sdk-java&lt;/artifactId&gt;\n  &lt;version&gt;2.x.x&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre>"},{"location":"phase-2/cloud-computing/lab13/#troubleshooting-tips","title":"Troubleshooting Tips","text":"<ul> <li>Verify credentials: <code>aws configure list</code></li> <li>Check permissions in IAM</li> <li>Ensure system clock is synchronized</li> <li>Watch for conflicting environment variables</li> <li>Clear and reconfigure if needed: delete <code>~/.aws</code></li> </ul>"},{"location":"phase-2/cloud-computing/lab13/#security-best-practices","title":"Security Best Practices","text":"<ul> <li>Never share or commit access keys</li> <li>Prefer IAM roles over static keys</li> <li>Rotate access keys regularly</li> <li>Follow least privilege principle</li> <li>Enable MFA</li> <li>Use AWS SSO for multiple accounts</li> </ul>"},{"location":"phase-2/cloud-computing/lab13/#configuration-file-locations","title":"Configuration File Locations","text":"<ul> <li>Windows: <code>%USERPROFILE%\\.aws\\</code></li> <li>macOS/Linux: <code>~/.aws/</code></li> </ul> <p>Files created:</p> <ul> <li><code>credentials</code> \u2192 Contains access keys</li> <li><code>config</code> \u2192 Region and output format</li> </ul> <p>\u2705 You are now ready to use AWS CLI and SDKs to manage AWS resources from your laptop!</p>"},{"location":"phase-2/cloud-computing/lab14/","title":"Lab 14","text":""},{"location":"phase-2/cloud-computing/lab14/#lab-14-configuring-nagios-on-linux-server-and-adding-linux-client","title":"Lab 14: Configuring Nagios on Linux Server and Adding Linux Client","text":"Option A: Local Setup (VirtualBox)Option B: AWS Setup (EC2 Instances)"},{"location":"phase-2/cloud-computing/lab14/#1-prerequisites","title":"1. Prerequisites","text":"<ul> <li> <p>Install VirtualBox (latest version).</p> </li> <li> <p>Download:</p> <ul> <li>Ubuntu Server ISO (22.04 LTS recommended).</li> <li>Debian/Ubuntu Minimal ISO for client.</li> </ul> </li> </ul>"},{"location":"phase-2/cloud-computing/lab14/#2-create-nagios-server-vm","title":"2. Create Nagios Server VM","text":"<ol> <li>Open VirtualBox \u2192 New \u2192 Name: NagiosServer.</li> <li> <p>Choose:</p> <ul> <li>Type: <code>Linux</code></li> <li>Version: <code>Ubuntu (64-bit)</code></li> <li>Memory: <code>2048 MB</code></li> <li>Disk: <code>20 GB (VDI, Dynamically allocated)</code></li> </ul> </li> <li> <p>Attach the Ubuntu ISO to the VM and start installation.</p> </li> <li> <p>During install:</p> <ul> <li>Set hostname: <code>nagios-server</code></li> <li>Username: <code>student</code> / Password: <code>student123</code></li> <li>Install OpenSSH server (select during setup).</li> </ul> </li> </ol>"},{"location":"phase-2/cloud-computing/lab14/#3-install-nagios-core-on-server","title":"3. Install Nagios Core on Server","text":"<pre><code>sudo apt update\nsudo apt install -y nagios4 nagios-plugins nagios-nrpe-plugin apache2\n</code></pre> <ul> <li> <p>Access web UI:</p> <ul> <li>Open browser \u2192 <code>http://&lt;server-ip&gt;/nagios4</code></li> <li>Default user: <code>nagiosadmin</code> (create password with <code>htpasswd</code>).</li> </ul> </li> </ul>"},{"location":"phase-2/cloud-computing/lab14/#4-create-linux-client-vm","title":"4. Create Linux Client VM","text":"<ol> <li>In VirtualBox \u2192 New \u2192 Name: LinuxClient.</li> <li>Install minimal Ubuntu/Debian with hostname <code>linux-client</code>.</li> <li>Ensure network is Bridged Adapter so both VMs are in same LAN.</li> </ol>"},{"location":"phase-2/cloud-computing/lab14/#5-install-nrpe-on-client","title":"5. Install NRPE on Client","text":"<pre><code>sudo apt update\nsudo apt install -y nagios-nrpe-server nagios-plugins\n</code></pre> <ul> <li>Edit config:</li> </ul> <pre><code>sudo nano /etc/nagios/nrpe.cfg\n</code></pre> <ul> <li>Add server IP under:</li> </ul> <pre><code>allowed_hosts=&lt;nagios-server-ip&gt;\n</code></pre> <ul> <li>Restart service:</li> </ul> <pre><code>sudo systemctl restart nagios-nrpe-server\n</code></pre>"},{"location":"phase-2/cloud-computing/lab14/#6-add-client-to-nagios-server","title":"6. Add Client to Nagios Server","text":"<p>On Nagios server:</p> <pre><code>sudo nano /etc/nagios4/conf.d/linuxclient.cfg\n</code></pre> <p>Example config:</p> <pre><code>define host {\n    use             linux-server\n    host_name       linux-client\n    address         &lt;client-ip&gt;\n    max_check_attempts  5\n    check_period    24x7\n    notification_interval 30\n    notification_period   24x7\n}\n</code></pre> <ul> <li>Restart Nagios:</li> </ul> <pre><code>sudo systemctl restart nagios4\n</code></pre> <p>\u2705 Check web UI \u2192 you should see <code>linux-client</code> as monitored host.</p>"},{"location":"phase-2/cloud-computing/lab14/#1-setup-ec2-nagios-server","title":"1. Setup EC2 Nagios Server","text":"<ol> <li>Login to AWS Console \u2192 EC2 \u2192 Launch Instance.</li> <li>Name: <code>NagiosServer</code>.</li> <li>AMI: Ubuntu Server 22.04 LTS (Free Tier).</li> <li>Instance type: <code>t2.micro</code>.</li> <li>Configure Security Group: Allow inbound SSH (22), HTTP (80).</li> <li>Download key pair \u2192 <code>nagios-key.pem</code>.</li> <li>Launch instance \u2192 Connect via SSH:</li> </ol> <pre><code>chmod 400 nagios-key.pem\nssh -i nagios-key.pem ubuntu@&lt;public-ip&gt;\n</code></pre>"},{"location":"phase-2/cloud-computing/lab14/#2-install-nagios-core","title":"2. Install Nagios Core","text":"<p>(Same commands as VirtualBox).</p>"},{"location":"phase-2/cloud-computing/lab14/#3-setup-ec2-linux-client","title":"3. Setup EC2 Linux Client","text":"<ol> <li>Launch another EC2 instance: Name <code>LinuxClient</code>.</li> <li>Same AMI and type (<code>t2.micro</code>).</li> <li>Security group: Allow SSH, and allow Nagios server IP on port 5666 (NRPE).</li> <li>Install NRPE (same as VirtualBox client).</li> </ol>"},{"location":"phase-2/cloud-computing/lab14/#4-add-client-to-server","title":"4. Add Client to Server","text":"<p>(Same Nagios config steps).</p> <p>\u2705 Verify in web UI \u2192 client status visible.</p>"},{"location":"phase-2/cloud-computing/lab15/","title":"Lab 15","text":""},{"location":"phase-2/cloud-computing/lab15/#lab-2-configuring-nagios-on-linux-server-and-adding-windows-client","title":"Lab 2: Configuring Nagios on Linux Server and Adding Windows Client","text":"Option A: Local (VirtualBox)Option B: AWS Setup (EC2 with Windows Server)"},{"location":"phase-2/cloud-computing/lab15/#1-setup-windows-client-vm","title":"1. Setup Windows Client VM","text":"<ol> <li>Download Windows Server 2019/2022 Evaluation ISO (from Microsoft).</li> <li>In VirtualBox \u2192 New \u2192 Name: WindowsClient \u2192 Type: Windows (64-bit).</li> <li>Assign: 4096 MB RAM, 40 GB disk.</li> <li>Install Windows \u2192 create admin account <code>student</code>.</li> <li>Enable Remote Desktop for convenience.</li> </ol>"},{"location":"phase-2/cloud-computing/lab15/#2-install-nsclient","title":"2. Install NSClient++","text":"<ol> <li>Download from NSClient++ website.</li> <li> <p>Install with options:</p> <ul> <li>Enable NRPE Server.</li> <li>Enable CheckHelpers.</li> </ul> </li> <li> <p>Edit config file:</p> <ul> <li>Allow Nagios server IP under <code>allowed hosts</code>.</li> <li>Enable NRPE.</li> </ul> </li> </ol>"},{"location":"phase-2/cloud-computing/lab15/#3-verify-nrpe","title":"3. Verify NRPE","text":"<ul> <li>From Nagios server:</li> </ul> <pre><code>/usr/lib/nagios/plugins/check_nrpe -H &lt;windows-client-ip&gt;\n</code></pre>"},{"location":"phase-2/cloud-computing/lab15/#4-add-windows-client-to-nagios","title":"4. Add Windows Client to Nagios","text":"<pre><code>sudo nano /etc/nagios4/conf.d/windowsclient.cfg\n</code></pre> <p>Example config:</p> <pre><code>define host {\n    use             windows-server\n    host_name       windows-client\n    address         &lt;windows-client-ip&gt;\n    check_period    24x7\n    max_check_attempts  5\n    notification_interval 30\n    notification_period   24x7\n}\n</code></pre> <p>Restart Nagios and check web UI.</p>"},{"location":"phase-2/cloud-computing/lab15/#1-launch-windows-server-ec2","title":"1. Launch Windows Server EC2","text":"<ol> <li>AWS Console \u2192 EC2 \u2192 Launch Instance.</li> <li>AMI: Microsoft Windows Server 2019 Base.</li> <li>Instance type: <code>t2.micro</code> (not free tier, may incur cost).</li> <li>Security Group: Allow RDP (3389) from your IP, and allow Nagios server IP on NRPE port.</li> <li>Download password \u2192 Decrypt with <code>.pem</code> key \u2192 RDP into server.</li> </ol>"},{"location":"phase-2/cloud-computing/lab15/#2-install-nsclient_1","title":"2. Install NSClient++","text":"<p>(Same as VirtualBox instructions).</p>"},{"location":"phase-2/cloud-computing/lab15/#3-configure-nagios-server","title":"3. Configure Nagios Server","text":"<p>(Same host config as above).</p> <p>\u2705 Check Windows client appears in Nagios web UI.</p>"},{"location":"phase-2/san/01_overview/","title":"Storage Area Network (SAN) and Related Concepts","text":""},{"location":"phase-2/san/01_overview/#what-is-san","title":"What is SAN?","text":""},{"location":"phase-2/san/01_overview/#what-is-it","title":"What is it?","text":"<p>A Storage Area Network (SAN) is a specialized, high-speed network that connects servers (often called hosts) to a centralized pool of storage devices. Unlike traditional setups where each server has its own directly attached storage (DAS \u2013 Direct Attached Storage), a SAN allows multiple servers to share the same storage resources over a dedicated network.</p> <p>Think of SAN as creating a separate highway for storage traffic \u2014 independent of your normal LAN (Local Area Network) used for emails, web browsing, and applications. This ensures fast, reliable, and scalable access to data.</p>"},{"location":"phase-2/san/01_overview/#theoretical-definition","title":"Theoretical Definition","text":"<p>A SAN is a dedicated, block-level storage network that uses specialized protocols (such as Fibre Channel, iSCSI, or FCoE) to allow servers to access disks across the network as if they were locally attached hard drives.  </p> <p>Key points in its definition: - Dedicated network: SAN traffic is kept separate from standard LAN traffic to prevent congestion. - Block-level access: Unlike file storage (NAS), SAN provides raw storage blocks, which servers can format and use as if they were physical disks. - Scalability: New storage arrays or servers can be added without major disruption. - Flexibility: Different servers (Windows, Linux, VMware hosts, etc.) can all use the same storage pool.  </p>"},{"location":"phase-2/san/01_overview/#why-sans-are-needed","title":"Why SANs Are Needed","text":"<ol> <li> <p>Centralized Storage Management    Instead of managing disks inside each server, admins manage one large pool of storage.  </p> </li> <li> <p>Scalability    As applications grow, you can add more storage devices to the SAN without changing servers.  </p> </li> <li> <p>Performance    SANs use high-speed networking (16\u2013128 Gbps in Fibre Channel) or optimized Ethernet (10/25/40/100 Gbps in iSCSI/FCoE).  </p> </li> <li> <p>High Availability    SANs are built with redundancy (dual controllers, multiple network paths, RAID) to ensure zero downtime.  </p> </li> </ol>"},{"location":"phase-2/san/01_overview/#real-world-example","title":"Real-World Example","text":"<p>Imagine a bank\u2019s data center: - Hundreds of servers handle ATM transactions, online banking, and customer databases. - Instead of each server having its own disks, the bank uses a SAN. - All servers connect to a shared storage pool that is reliable, fast, and secure. - If one server fails, another can immediately take over and access the same data through the SAN.  </p>"},{"location":"phase-2/san/01_overview/#types-of-san-overview","title":"Types of SAN (Overview)","text":"<ul> <li>Fibre Channel SAN (FC-SAN): Uses Fibre Channel switches and HBAs; offers very high speed and reliability.  </li> <li>iSCSI SAN: Runs on standard Ethernet networks; more cost-effective, good for small/medium businesses.  </li> <li>Fibre Channel over Ethernet (FCoE): Combines Fibre Channel frames over Ethernet networks, reducing infrastructure needs.  </li> </ul> <p>WOW Tip</p> <p>SANs became popular in the late 1990s because they allowed organizations to separate compute and storage. This separation is the foundation of modern cloud and hyper-converged infrastructures.</p>"},{"location":"phase-2/san/01_overview/#das-vs-nas-vs-san","title":"DAS vs NAS vs SAN","text":"Feature DAS (Direct Attached Storage) NAS (Network Attached Storage) SAN (Storage Area Network) Definition Storage directly attached to a single server File-level storage accessed over LAN Block-level storage accessed over a dedicated network Access Method Server sees storage as local disks Clients access files via protocols (NFS, SMB) Servers access raw blocks via FC, iSCSI, FCoE Network Used No network (local bus, e.g., SATA/SAS) LAN (Ethernet) Dedicated storage network (Fibre Channel or IP-based) Performance High (limited to one server) Moderate (depends on LAN traffic) Very high (dedicated high-speed network) Scalability Limited to server capacity Easy to scale by adding NAS devices Highly scalable with storage arrays and switches Data Sharing Not shared (local to one server) Shared at file level Shared at block level across multiple servers Use Cases Personal PCs, small servers File sharing, backups, media servers Datacenters, virtualization, databases, enterprise apps Example Internal hard drives, external HDDs Synology/QNAP NAS devices EMC, NetApp, Dell, HP SAN solutions"},{"location":"phase-2/san/01_overview/#understanding-san","title":"Understanding SAN","text":""},{"location":"phase-2/san/01_overview/#san-expanded","title":"SAN Expanded","text":""},{"location":"phase-2/san/01_overview/#types-of-san","title":"Types of SAN","text":"<ol> <li> <p>Fibre Channel SAN </p> <ul> <li>Uses Fibre Channel switches and host bus adapters (HBAs).  </li> <li>High-speed (16\u2013128 Gbps).  </li> <li>Traditionally the most common in enterprise data centers.  </li> </ul> </li> <li> <p>iSCSI SAN </p> <ul> <li>Uses IP networks (Ethernet) to send SCSI commands.  </li> <li>More cost-effective than Fibre Channel.  </li> <li>Easier to set up for small and medium businesses.  </li> </ul> </li> <li> <p>Fibre Channel over Ethernet (FCoE) </p> <ul> <li>Combines Fibre Channel traffic over Ethernet.  </li> <li>Reduces the need for separate cabling.  </li> </ul> </li> </ol>"},{"location":"phase-2/san/01_overview/#advantages-of-san","title":"Advantages of SAN","text":"<ul> <li>High performance and reliability.  </li> <li>Centralized storage management.  </li> <li>Scalability (easy to add more storage).  </li> <li>Supports High Availability through redundancy.  </li> </ul>"},{"location":"phase-2/san/02_high_availablity/","title":"High Availability","text":""},{"location":"phase-2/san/02_high_availablity/#using-san-for-high-availability","title":"Using SAN for High Availability","text":""},{"location":"phase-2/san/02_high_availablity/#what-is-high-availability-ha","title":"What is High Availability (HA)?","text":"<p>High Availability (HA) refers to the ability of an IT system to remain continuously operational, with minimal or no downtime, even in the event of hardware or software failures.  </p> <p>In simple terms:  </p> <ul> <li>HA means your systems are always up and running.  </li> <li>Businesses often define HA with terms like \u201cfive nines\u201d availability (99.999%), which equals less than 5 minutes of downtime per year.  </li> </ul> <p>For storage systems, downtime could mean lost access to critical data \u2014 which is unacceptable in industries like healthcare, banking, aviation, or e-commerce.</p> <p></p>"},{"location":"phase-2/san/02_high_availablity/#how-san-enables-high-availability","title":"How SAN Enables High Availability","text":"<p>SANs are designed with redundancy and fault tolerance at every layer. Here\u2019s how they achieve HA:</p> <ol> <li> <p>Multiple Storage Controllers </p> <ul> <li>SAN storage arrays usually have at least two controllers.  </li> <li>If one fails, the other takes over seamlessly (failover).  </li> </ul> </li> <li> <p>Dual Power Supplies </p> <ul> <li>SAN devices and storage arrays use redundant power supplies connected to separate power circuits.  </li> <li>This protects against power failures in one source.  </li> </ul> </li> <li> <p>Multipathing (Redundant Network Paths) </p> <ul> <li>Servers connect to SAN storage through multiple physical network paths.  </li> <li>If one path (cable, switch, or port) fails, the other continues to provide access.  </li> </ul> </li> <li> <p>RAID or Replication </p> <ul> <li>RAID (Redundant Array of Independent Disks) protects against disk failures.  </li> <li>Replication (synchronous or asynchronous) mirrors data across different arrays or even data centers.  </li> </ul> </li> <li> <p>Cluster Integration </p> <ul> <li>SANs are often paired with server clusters.  </li> <li>If one server fails, another server in the cluster can immediately take over, accessing the same SAN data.  </li> </ul> </li> </ol>"},{"location":"phase-2/san/02_high_availablity/#example-hospital-it-system","title":"Example: Hospital IT System","text":"<p>In a hospital, patient data must be accessible 24/7:  </p> <ul> <li>Doctors need real-time access to patient history and lab results.  </li> <li>A SAN setup with dual controllers, redundant paths, and replication ensures that even if one component (controller, switch, disk) fails, data remains available instantly.  </li> <li>Without HA in SAN, even a short outage could mean delays in life-critical care.  </li> </ul> <p>Bonus/WOW Tip</p> <p>Some enterprise SANs offer geographically distributed HA \u2014 also known as metro clusters:</p> <ul> <li>Data is replicated in real-time across two different data centers in different locations.  </li> <li>Even if an entire building or city loses power, the system automatically switches to the remote SAN without users noticing downtime.  </li> <li>Example: Large banks often use metro clusters to ensure uninterrupted ATM and online transactions.  </li> </ul>"},{"location":"phase-2/san/03_san_components/","title":"Components","text":""},{"location":"phase-2/san/03_san_components/#1-zfs-volume-configuration","title":"1. ZFS Volume Configuration","text":""},{"location":"phase-2/san/03_san_components/#what-is-zfs","title":"What is ZFS?","text":"<p>ZFS (Zettabyte File System) is both a file system and a volume manager, originally developed by Sun Microsystems and now widely adopted in enterprise and open-source storage systems (like FreeNAS/TrueNAS). Unlike traditional file systems (ext4, NTFS), ZFS integrates file system and volume management in a single layer.</p>"},{"location":"phase-2/san/03_san_components/#key-features-of-zfs","title":"Key Features of ZFS","text":"<ol> <li> <p>Pooled Storage </p> <ul> <li>Traditional systems use fixed volumes tied to specific disks.  </li> <li>ZFS allows multiple physical disks to be grouped into a storage pool.  </li> <li>From this pool, administrators can create flexible file systems or block devices as needed.  </li> </ul> </li> <li> <p>Snapshots and Clones </p> <ul> <li>A snapshot is a read-only point-in-time copy of the file system.  </li> <li>A clone is a writable copy of a snapshot, useful for testing and development.  </li> </ul> </li> <li> <p>Self-Healing </p> <ul> <li>ZFS uses checksums to detect data corruption.  </li> <li>If a bad block is detected, it automatically repairs it from redundant copies.  </li> </ul> </li> <li> <p>Advanced RAID (RAID-Z) </p> <ul> <li>ZFS introduces RAID-Z, which is more reliable than traditional RAID-5.  </li> <li>It avoids the \u201cwrite hole problem\u201d (risk of data loss during power failure).  </li> </ul> </li> <li> <p>Compression and Deduplication </p> <ul> <li>Built-in compression saves storage space.  </li> <li>Deduplication ensures identical data blocks are stored only once.  </li> </ul> </li> </ol>"},{"location":"phase-2/san/03_san_components/#example","title":"Example","text":"<p>An admin configures a ZFS pool on FreeNAS with 6 disks: </p> <ul> <li>Pool created as RAID-Z2 (tolerates up to 2 disk failures).  </li> <li>Snapshots taken daily for backups.  </li> <li>Deduplication enabled to optimize storage for virtual machine images.  </li> </ul> <p>This setup ensures reliability, scalability, and efficient storage usage.</p> <p>WOW Tip</p> <p>ZFS is designed to scale up to 256 quadrillion zettabytes of storage. While this is far beyond current hardware limits, it makes ZFS essentially future-proof.</p>"},{"location":"phase-2/san/03_san_components/#_1","title":"Components","text":""},{"location":"phase-2/san/03_san_components/#2-ip-based-storage-communication","title":"2. IP-Based Storage Communication","text":""},{"location":"phase-2/san/03_san_components/#what-is-it","title":"What is it?","text":"<p>In SANs, not all organizations can afford expensive Fibre Channel infrastructure. IP-based storage communication allows block-level storage traffic to run over standard Ethernet networks, making SAN technology accessible to smaller businesses.</p>"},{"location":"phase-2/san/03_san_components/#theoretical-definition","title":"Theoretical Definition","text":"<p>Protocols like iSCSI (Internet Small Computer Systems Interface) encapsulate SCSI commands (used for disk operations) into IP packets. This allows servers to treat networked storage devices as if they were locally attached drives.</p> <p>Other approaches include:  </p> <ul> <li>FCoE (Fibre Channel over Ethernet): Fibre Channel traffic encapsulated over Ethernet.  </li> <li>NVMe over Fabrics (NVMe-oF): Uses Ethernet, Fibre Channel, or InfiniBand to deliver ultra-fast access to NVMe drives.  </li> </ul>"},{"location":"phase-2/san/03_san_components/#advantages-of-ip-based-sans","title":"Advantages of IP-Based SANs","text":"<ol> <li> <p>Cost-Effective </p> <ul> <li>Uses existing Ethernet switches instead of Fibre Channel infrastructure.  </li> </ul> </li> <li> <p>Flexibility </p> <ul> <li>Easy to extend SANs across geographic locations using standard IP networks.  </li> </ul> </li> <li> <p>Simpler Management </p> <ul> <li>Network admins familiar with TCP/IP can manage iSCSI without learning Fibre Channel.  </li> </ul> </li> <li> <p>Integration with Virtualization </p> <ul> <li>Popular hypervisors (VMware, Hyper-V, KVM) support iSCSI storage.  </li> </ul> </li> </ol> <p>Example</p> <ul> <li>A small company uses a 10 Gbps Ethernet network with FreeNAS configured for iSCSI.  </li> <li>Their servers connect to iSCSI targets (logical storage units).  </li> <li>Virtual machines hosted on VMware ESXi use this shared iSCSI storage for VM disks. This provides SAN-like benefits without high Fibre Channel costs.</li> </ul> <p>WOW Tip</p> <p>iSCSI SANs helped democratize enterprise storage. Many cloud providers started with iSCSI-based backends before upgrading to NVMe fabrics for scale.</p>"},{"location":"phase-2/san/03_san_components/#3-object-storage-services","title":"3. Object Storage Services","text":""},{"location":"phase-2/san/03_san_components/#what-is-object-storage","title":"What is Object Storage?","text":"<p>Unlike SAN (block storage) or NAS (file storage), Object Storage treats data as discrete units called objects. Each object contains:  </p> <ul> <li>Data (the actual file, like an image or video).  </li> <li>Metadata (details about the file, like creation date, permissions).  </li> <li>Unique Identifier (an ID used to retrieve the object).  </li> </ul>"},{"location":"phase-2/san/03_san_components/#_2","title":"Components","text":""},{"location":"phase-2/san/03_san_components/#theoretical-definition_1","title":"Theoretical Definition","text":"<p>Object storage is a flat storage system designed for massive scalability and unstructured data. Data is accessed via RESTful APIs (like Amazon S3 API) rather than traditional file system paths.  </p>"},{"location":"phase-2/san/03_san_components/#advantages","title":"Advantages","text":"<ol> <li> <p>Massive Scalability</p> <ul> <li>Can store petabytes or even exabytes of data.  </li> <li>No traditional file hierarchy, making it more efficient for large datasets.  </li> </ul> </li> <li> <p>Durability</p> <ul> <li>Objects are usually replicated across multiple servers or regions.  </li> </ul> </li> <li> <p>Accessibility via APIs</p> <ul> <li>Applications interact with object storage via URLs and APIs instead of mounting drives.  </li> </ul> </li> <li> <p>Cost-Effectiveness for Unstructured Data </p> <ul> <li>Great for backups, archives, videos, images, logs, and cloud-native apps.  </li> </ul> </li> </ol>"},{"location":"phase-2/san/03_san_components/#examples","title":"Examples","text":"<ul> <li>Amazon S3: Used globally for cloud applications.  </li> <li>Azure Blob Storage: Microsoft\u2019s object storage service.  </li> <li>MinIO: Open-source, S3-compatible object storage used for private clouds.  </li> </ul> <p>Real-World Use Case</p> <p>Netflix uses Amazon S3 to store and deliver its massive video library. When you stream a show, the data is fetched as objects from distributed storage, ensuring high availability and low latency.</p> <p>WOW Tip</p> <p>Unlike block or file storage, object storage is location-independent \u2014 meaning your application doesn\u2019t care where the data is physically stored. The unique object ID handles retrieval, making global-scale storage possible.</p>"},{"location":"phase-2/san/03_san_components/#summary","title":"Summary","text":"<ul> <li>ZFS provides enterprise-grade reliability with advanced features like snapshots, RAID-Z, and self-healing.  </li> <li>IP-based storage (iSCSI, FCoE, NVMe-oF) brings SAN capabilities to Ethernet networks, making them cost-effective.  </li> <li>Object Storage is built for the cloud era, handling massive unstructured datasets via APIs.  </li> </ul> <p>Together, these technologies complement SANs and modern data centers to provide scalable, reliable, and flexible storage solutions.</p>"},{"location":"phase-2/san/lab05/","title":"Lab 05: Installing and Configuring FreeNAS (TrueNAS CORE) in VirtualBox","text":""},{"location":"phase-2/san/lab05/#introduction","title":"Introduction","text":"<p>In this lab, you will learn how to set up FreeNAS (now called TrueNAS CORE) inside a virtual machine using VirtualBox. TrueNAS is an open-source storage operating system widely used to build NAS (Network Attached Storage) and SAN (Storage Area Network) systems.</p> <p>By the end of this lab, you will: - Install FreeNAS/TrueNAS CORE in VirtualBox. - Add virtual disks to simulate enterprise storage. - Create and configure a ZFS storage pool. - Create a basic dataset to be later used by your Lab 03 Linux VM (Lubuntu).</p> <p>This lab introduces you to the role of a Storage Administrator in a company like TechOps Inc., where servers rely on centralized storage.</p>"},{"location":"phase-2/san/lab05/#step-1-downloading-freenas-truenas-core","title":"Step 1: Downloading FreeNAS (TrueNAS CORE)","text":"<ol> <li>Open a browser on your Windows Host Machine.</li> <li>Go to the official TrueNAS download page:    \ud83d\udc49 https://www.truenas.com/download-truenas-core/</li> <li>Download the latest stable ISO (as of September 2025: TrueNAS CORE 13.x).</li> <li>Save the ISO file to your computer.</li> </ol>"},{"location":"phase-2/san/lab05/#step-2-creating-a-new-virtual-machine-for-freenas","title":"Step 2: Creating a New Virtual Machine for FreeNAS","text":"<ol> <li>Open VirtualBox on your Windows 11 host.</li> <li> <p>Click New \u2192 Fill in details:</p> <ul> <li>Name: <code>FreeNAS-Server</code></li> <li>Type: BSD</li> <li>Version: FreeBSD (64-bit)</li> </ul> </li> <li> <p>Assign resources:</p> <ul> <li>RAM: 4096 MB (4 GB)</li> <li>CPU: 2 processors (minimum)</li> </ul> </li> <li> <p>Do not create a hard disk yet (we will add disks manually).</p> </li> </ol>"},{"location":"phase-2/san/lab05/#step-3-adding-virtual-disks","title":"Step 3: Adding Virtual Disks","text":"<p>FreeNAS requires storage disks to create pools.</p> <ol> <li>Select your <code>FreeNAS-Server</code> VM \u2192 Settings \u2192 Storage.</li> <li>Add a Controller: SATA if not already present.</li> <li> <p>Add multiple virtual hard disks:</p> <ul> <li>Disk 1: 20 GB (System Disk, where FreeNAS OS will install).</li> <li>Disk 2: 10 GB (Data Disk 1).</li> <li>Disk 3: 10 GB (Data Disk 2).</li> <li>Disk 4: 10 GB (Data Disk 3).</li> </ul> <p>\ud83d\udc49 The extra disks (2\u20134) will simulate a storage array for ZFS.</p> </li> <li> <p>Attach the downloaded TrueNAS ISO as a virtual optical disk.</p> </li> </ol> <p>GUI method (VirtualBox Manager) for Step 4</p> <ol> <li>Open Oracle VirtualBox on your host machine.</li> <li>Select the VM you created (e.g. <code>FreeNAS-Server</code>) in the left VM list \u2014 do not start it yet.</li> <li>Click the Settings (\u2699\ufe0f) button in the toolbar (or right-click the VM \u2192 Settings).</li> <li>In the Settings window choose Storage from the left menu.</li> <li>Look at the Storage Tree panel in the middle:<ul> <li>You will see one or more controllers (e.g., <code>Controller: SATA</code>, <code>Controller: IDE</code>) and attached devices underneath.</li> <li>If there is an entry labeled Controller: IDE with an item <code>Empty</code> that has a little CD icon, select that <code>Empty</code> entry.</li> <li>If you don\u2019t see an IDE controller or an Empty optical drive, select a controller (IDE or SATA) and use the small CD icon with a + (or the little disk icon on the right) to Add Optical Drive.</li> </ul> </li> <li>With the optical drive (the <code>Empty</code> item) selected, look at the right-hand Attributes area. Click the small CD icon next to Optical Drive and choose Choose a disk file...</li> <li>In the file chooser dialog, navigate to the folder where you saved the TrueNAS ISO (e.g., <code>C:\\Users\\YourName\\Downloads\\TrueNAS-CORE-13.x.iso</code> on Windows or <code>/home/you/Downloads/TrueNAS-CORE-13.x.iso</code> on Linux), select the ISO and click Open.</li> <li>You should now see the ISO filename displayed under the controller in the Storage Tree (instead of <code>Empty</code>).</li> <li>(Important) Optional: verify boot order \u2014 go to System \u2192 Motherboard and ensure Optical is checked and listed above Hard Disk in the Boot Order so the VM boots from the ISO first.</li> <li>Click OK to save and close Settings.</li> </ol>"},{"location":"phase-2/san/lab05/#step-4-installing-freenastruenas-core","title":"Step 4: Installing FreeNAS/TrueNAS CORE","text":"<ol> <li>Start the VM \u2192 The TrueNAS installer should boot.</li> <li>Select Install/Upgrade.</li> <li>Choose the 20 GB system disk as the installation target.</li> <li>Set a root password (remember this carefully).</li> <li>Choose Boot via BIOS (default) or UEFI if prompted.</li> <li>Complete installation and reboot. Remove the ISO after reboot.</li> </ol> <p>When the VM restarts, you will see a console setup screen with network details (IP address).</p>"},{"location":"phase-2/san/lab05/#step-5-accessing-the-truenas-web-interface","title":"Step 5: Accessing the TrueNAS Web Interface","text":"<ol> <li> <p>From the console screen, note the IP address assigned to the FreeNAS VM.    Example: <code>http://192.168.1.120</code></p> </li> <li> <p>On your Windows Host machine, open a web browser and type the IP address.</p> </li> <li> <p>Log in with:</p> <ul> <li>Username: <code>root</code> OR <code>truenas_admin</code> (depending upon what you see during installation)</li> <li>Password: (the one you set during installation)</li> </ul> </li> </ol> <p>You are now inside the TrueNAS Web Interface.</p>"},{"location":"phase-2/san/lab05/#step-6-creating-a-zfs-storage-pool","title":"Step 6: Creating a ZFS Storage Pool","text":"<ol> <li>Go to Storage \u2192 Pools in the web interface.</li> <li>Click Add \u2192 Create new pool.</li> <li>Name the pool: <code>TechOpsPool</code></li> <li>Layout: RAID-Z1</li> <li>Width: 3</li> <li>Number of VDEVs: 1</li> <li>Click on Next, untill you are at last step (leave all other fields as default)</li> <li>Click on Create Pool</li> <li>Confirm and create the pool.</li> </ol> <p>\u2705 You now have a ZFS storage pool.</p>"},{"location":"phase-2/san/lab05/#step-7-creating-a-dataset","title":"Step 7: Creating a Dataset","text":"<p>Datasets are like folders within a ZFS pool, optimized for different use cases.</p> <ol> <li>In the TrueNAS web interface \u2192 Storage \u2192 Pools \u2192 TechOpsPool.</li> <li>Click the 3-dot menu \u2192 Add Dataset. OR directly click on Add Dateset</li> <li>Name it: <code>ProjectData</code></li> <li>Accept defaults (compression on, share type: generic).</li> </ol> <p>\u2705 You now have a dataset inside your ZFS pool.</p>"},{"location":"phase-2/san/lab05/#step-8-preparing-for-client-access","title":"Step 8: Preparing for Client Access","text":"<p>In later labs, we will:</p> <ul> <li>Connect the Lab 03 Lubuntu VM to this dataset using NFS/iSCSI.</li> <li>Configure multipath I/O for HA.</li> <li>Add file and object storage layers (SMB, MinIO).</li> </ul> <p>For now, ensure your FreeNAS VM is running and your pool + dataset exist.</p>"},{"location":"phase-2/san/lab05/#troubleshooting-tips","title":"Troubleshooting Tips","text":"<ul> <li>No network/IP shown: Change VM network to Bridged Adapter in VirtualBox settings.</li> <li>VM too slow: Increase RAM to 6 GB if your host allows.</li> <li>Can\u2019t access web interface: Check firewall on host, or try a different browser.</li> </ul> <p>\u2705 Congratulations! You have successfully installed TrueNAS CORE in VirtualBox, created a ZFS storage pool, and added a dataset. This forms the foundation of your SAN environment.</p>"},{"location":"phase-2/san/lab06/","title":"Lab 06: Advanced ZFS Configuration and Data Protection","text":"<p>File: Lab_06_ZFS_Advanced.md UUID: 8d3f9a4d-f61e-4425-bb8c-f71d35b98a91</p>"},{"location":"phase-2/san/lab06/#introduction","title":"Introduction","text":"<p>In this lab, you will build on the TechOpsPool you created in Lab 05. You will learn how to configure advanced ZFS features for data protection and reliability, and you will also connect your Lubuntu VM (from Lab 03) to test access to the storage.</p> <p>By the end of this lab, you will: - Work with datasets inside the existing TechOpsPool. - Create multiple datasets for different use cases. - Configure snapshots and test restoring from one. - Configure replication between datasets. - Mount an NFS share on your Lubuntu VM to verify access to ZFS datasets.</p>"},{"location":"phase-2/san/lab06/#step-1-verify-techopspool","title":"Step 1: Verify TechOpsPool","text":"<ol> <li>Log in to the TrueNAS Web Interface (use the IP noted in Lab 05).</li> <li>Go to Storage \u2192 Pools.</li> <li>Confirm that <code>TechOpsPool</code> exists and is healthy.</li> <li>If not, repeat Lab 05 steps to create it with Disks 2\u20134.</li> </ol> <p>\u2705 You will continue using this pool for all advanced ZFS tasks.</p>"},{"location":"phase-2/san/lab06/#step-2-creating-datasets","title":"Step 2: Creating Datasets","text":"<p>Datasets are like specialized folders inside a ZFS pool.</p> <ol> <li>Navigate to Datasets.</li> <li>Select <code>TechOpsPool</code></li> <li>Click on <code>Add Dataset</code></li> <li> <p>Create the following:</p> <ul> <li><code>WindowsData</code> (for development files)</li> </ul> <p>Warning</p> <p>Remember to click on <code>TechOpsPool</code> again before creating 2nd Dataset</p> <ul> <li><code>UnixData</code> (for testing snapshot/replication)</li> </ul> </li> <li> <p>Accept default options (compression enabled, share type generic).</p> </li> </ol> <p>\u2705 You now have two new datasets under <code>TechOpsPool</code>.</p>"},{"location":"phase-2/san/lab06/#step-3-creating-an-smb-user","title":"Step 3: Creating an SMB User","text":"<p>SMB Users are the local users in FreeNAS using which you access the storage blocks or disks on client machines</p> <ol> <li>Navigate to Credentials \u2192 Users.</li> <li>Click the Add button located at top right corner.</li> <li>Enter the following:</li> <li>Full Name: <code>SMB User</code></li> <li>Username: <code>smb_user</code></li> <li>Password &amp; Confirm Password: <code>*EnterStrongPassword*</code></li> <li>Home Directory: <code>/mnt/TechOpsPool/WindowsData</code></li> <li>Shell: <code>nologin</code></li> <li>Home Directory Permissions: <ul> <li>Select Read, Write, Execute for User &amp; Group</li> <li>Select Read, Execute for Other </li> </ul> </li> <li>Creaet Home Directory: <code>Unselect the Checkbox</code></li> <li>Click on Save</li> </ol> <p>\u2705 You now have created new user <code>smb_user</code> which we will use in next step</p>"},{"location":"phase-2/san/lab06/#step-4-creating-an-smb-share-for-windows","title":"Step 4: Creating an SMB Share for Windows","text":"<p>SMB Shares allow clients (virtual machines, servers, apps, etc) to access the ZFS storage and its pools to store and retrieve their data</p> <ol> <li>Click on <code>Shares</code> from the side menu</li> <li>In <code>Windows (SMB) Shares</code> click on <code>Add</code> button</li> <li>Enter following details:<ul> <li>Path: <code>/mnt/TechOpsPool/WindowsData</code></li> <li>Name: <code>WindowsData</code></li> <li>Leave other fields as defaul</li> <li>Click on <code>Save</code></li> </ul> </li> <li>If Promted to Start or Restart Service, click OK or Restart Service</li> <li>Configure ACL -&gt; Click on <code>Configure</code></li> <li>In the ACL Editor enter following details:<ul> <li>Owner: <code>smb_user</code></li> <li>Owner Group: <code>smb_user</code></li> </ul> </li> <li>Click on <code>Save ACL</code> button</li> </ol> <p>\u2705 You have now created an SMB Share Drive which can be accessed on any Windows Machine inside the network.</p>"},{"location":"phase-2/san/lab06/#step-5-accessing-the-pool-storage-from-windows","title":"Step 5: Accessing the Pool Storage from Windows","text":"<p>Now since you have created the Pool Storage, we will now access that storager and use that storage inside our Windows Device</p> <ol> <li>Go to your Windows 10/11 Desktop or anywhere</li> <li>Press <code>CMD + R</code> or Click on Search -&gt; Type <code>Run</code> -&gt; and Open Run Application</li> <li>Type: <code>\\\\&lt;ip of your FreeNAS-Server&gt;\\TechOpsPool\\WindowsData</code></li> <li>Press <code>Enter</code></li> <li>When prompted enter the following credentials:<ul> <li>Username: <code>smb_user</code></li> <li>Password: <code>Enter the password from Step 3</code></li> </ul> </li> <li>You should see the <code>WindowsData</code> Folder on your Windows 11</li> <li>Right click inside the folder and create new Text Document (name it anything)</li> <li>Open the newly created documented and wirte somethign inside that, save the file and exit</li> </ol> <p>\u2705 You have now accessed the storage created in FreeNAS on your Windows Machine and you can use it as normal file system. So in future if you Windows gets corrupted, your data is always secred on FreeNAS!</p>"},{"location":"phase-2/san/lab06/#step-6-configuring-snapshots","title":"Step 6: Configuring Snapshots","text":"<ol> <li>Go to DataSets \u2192 WindowsData.</li> <li>On the right side you will see the card/window called Data Protection</li> <li>Inside that card, click on <code>Create Snapshot</code></li> <li>Choose dataset: <code>WindowsData</code>.</li> <li>Name: <code>Initial Backup</code></li> <li>Click on <code>Save</code></li> <li>Go the same file that you created in Step 5, open it and change the contents of the same file.</li> <li>Take another snapshot after changes \u2192 name it <code>BackupData_Snap2</code>.</li> </ol> <p>\ud83d\udc49 Later, you will roll back to <code>BackupData_Snap1</code> and verify that changes are undone.</p>"},{"location":"phase-2/san/lab06/#step-7-replication-setup","title":"Step 7: Replication Setup","text":"<p>Replication copies data from one dataset to another for protection.</p> <ol> <li>Go to Data Protection \u2192 Replication Tasks \u2192 Add.</li> <li>Source Location: <code>On this System</code></li> <li>Source: <code>WindowsData</code>. (Select by using drop down menu)</li> <li>Destination Location: <code>On this System</code></li> <li>Destination: <code>ProjectData</code> (Select by using drop down menu)</li> <li>Click on <code>Next</code></li> <li>Replication Schedule: Run Once.</li> <li>Uncheck Make Destination Read-Only?</li> <li>Keep other details as default</li> <li>Click on <code>Save</code></li> </ol> <p>\u2705 You have now created a replication system. Meaning if one of your Harddisk is corrupted, your data is always there on other Harddisk on different location</p>"},{"location":"phase-2/san/lab06/#step-8-create-user-for-nfs","title":"Step 8: Create user for NFS","text":"<p>NFS User is required to access and store the data on NFS Shares. </p> <p>Important</p> <p>Before proceeding further, log in to your Lubuntu VM, and run the command <code>id &lt;your-username&gt;</code>. This will return the output as example (e.g., <code>uid=1000(username)</code>, <code>gid=1000(username)</code>).</p> <p>Note down the <code>uid</code> and <code>gid</code></p> <ol> <li>Navigate to Credentials \u2192 Users.</li> <li>Click the Add button located at top right corner.</li> <li>Enter the following:</li> <li>Full Name: <code>NFS User</code></li> <li>Username: <code>nfs_user</code></li> <li>**Select the option to <code>Disable Password</code>. (This is required for Unix System mount, we can use SSH keys as well)</li> <li>Home Directory: <code>/mnt/TechOpsPool/UnixData</code></li> <li>UID: Enter UID you received from your Lubuntu Usere above.</li> <li>Shell: <code>nologin</code></li> <li>Home Directory Permissions: <ul> <li>Select Read, Write, Execute for User &amp; Group</li> <li>Select Read, Execute for Other </li> </ul> </li> <li>Creaet Home Directory: <code>Unselect the Checkbox</code></li> <li> <ul> <li>Uncheck <code>SMB User</code> </li> </ul> </li> <li>Click on Save</li> </ol> <p>\u2705 You now have created new user <code>nfs_user</code> which we will use in next step</p> <p>\u2705 You have now created a replication system. Meaning if one of your Harddisk is corrupted, your data is always there on other Harddisk on different location</p>"},{"location":"phase-2/san/lab06/#step-8-connecting-lubuntu-vm-via-nfs","title":"Step 8: Connecting Lubuntu VM via NFS","text":"<p>Now let\u2019s make your Lubuntu VM from Lab 03 act as a client.</p>"},{"location":"phase-2/san/lab06/#on-truenas-server","title":"On TrueNAS (server):","text":"<ol> <li>Go to Shares \u2192 Unix Shares (NFS).</li> <li>Click Add.</li> <li>Path: <code>/mnt/TechOpsPool/UnixData</code>.</li> <li>Allow network: <code>192.168.0.0/24</code> (adjust to your local subnet).</li> <li>Hosts: Authrorised Hosts and IP Addresss: <code>Enter the IP of your Lubnutu VM</code></li> <li>Click on <code>Advanced Options</code></li> <li>Mapall User: <code>nfs_user</code></li> <li>Mapall Group: <code>nfs_user</code></li> <li>Save and enable the NFS service.</li> </ol>"},{"location":"phase-2/san/lab06/#on-lubuntu-client","title":"On Lubuntu (client):","text":"<ol> <li>Start your Lubuntu VM.</li> <li>Open the terminal.</li> <li>Install NFS client tools:    <pre><code>sudo apt update &amp;&amp; sudo apt install nfs-common -y\n</code></pre></li> <li>Create a mount point:    <pre><code>sudo mkdir /mnt/unixdata\n</code></pre></li> <li>Mount the NFS share (replace <code>&lt;truenas-ip&gt;</code> with actual IP):    <pre><code>sudo mount &lt;truenas-ip&gt;:/mnt/TechOpsPool/UnixData /mnt/unixdata\n</code></pre></li> <li>Verify:    <pre><code>ls -ltr /mnt/unixdata\n</code></pre>    It should list files/datasets from the TrueNAS server. Currently it should be blank</li> </ol>"},{"location":"phase-2/san/lab06/#step-9-testing-snapshots-rollback","title":"Step 9: Testing Snapshots (Rollback)","text":"<ol> <li>On Lubuntu, create a test file in the mounted directory:    <pre><code>echo \"Test File\" | sudo tee /mnt/unixdata/testfile.txt\n</code></pre></li> <li>On TrueNAS, take a snapshot of <code>UnixData</code> dataset as mentioned in Step 6.</li> <li>Delete the file from Lubuntu:    <pre><code>sudo rm /mnt/unixdata/testfile.txt\n</code></pre></li> <li>Roll back the dataset to the snapshot in TrueNAS web interface.<ul> <li>Go to DataSets</li> <li>Select <code>UnixData</code></li> <li>In Data Protection Card, click on <code>Manage Snapshots</code></li> <li>Click on the snap shot created in Step 2 of this Step</li> <li>Click on <code>Rollback</code></li> </ul> </li> <li>Refresh the mount on Lubuntu:    <pre><code>ls /mnt/unixdata\n</code></pre>    \u2705 The file should reappear \u2014 restored by ZFS snapshot rollback.</li> </ol>"},{"location":"phase-2/san/lab06/#troubleshooting-tips","title":"Troubleshooting Tips","text":"<ul> <li>NFS share not visible: Ensure NFS service is enabled on TrueNAS and firewall is off on host.</li> <li>Mount error in Lubuntu: Double-check IP and path. Use <code>ping &lt;truenas-ip&gt;</code> to verify connectivity.</li> <li>Low performance: Assign more RAM (6 GB) to the FreeNAS VM.</li> <li>Replication failed: Ensure both datasets exist and have enough space.</li> </ul> <p>\u2705 Congratulations! You\u2019ve now configured advanced ZFS features, tested snapshots &amp; replication, and connected your Lubuntu VM to access the storage via NFS. This demonstrates how SAN integrates with client servers in real-world setups.</p>"},{"location":"phase-2/san/lab07/","title":"Lab 07: Configuring iSCSI Targets and Multipath I/O (High Availability Simulation)","text":"<p>Alert</p> <p>This lab is not tested and may result in unexpected outcomes. The idea is to show how iSCSI is configured on TrueNAS</p>"},{"location":"phase-2/san/lab07/#introduction","title":"Introduction","text":"<p>In this lab, you will simulate a high availability (HA) SAN setup by configuring iSCSI targets in TrueNAS and enabling Multipath I/O (MPIO) on your Lubuntu VM (from Lab 03). This demonstrates how enterprise servers connect to centralized block storage with redundancy.</p> <p>By the end of this lab, you will:</p> <ul> <li>Enable and configure the iSCSI service in TrueNAS.</li> <li>Create an iSCSI target backed by a ZFS dataset.</li> <li>Simulate multiple network paths to the same target.</li> <li>Configure Multipath I/O (MPIO) on the Lubuntu VM.</li> <li>Verify redundancy and failover.</li> </ul>"},{"location":"phase-2/san/lab07/#step-1-preparing-the-environment","title":"Step 1: Preparing the Environment","text":"<ol> <li>Ensure your TrueNAS VM (FreeNAS-Server) is running with the TechOpsPool from Lab 05.</li> <li>Ensure your Lubuntu VM (from Lab 03) is running and connected to the same network (Bridged Adapter).</li> <li>Make sure both VMs can ping each other:</li> </ol> <pre><code>ping &lt;truenas-ip&gt;\nping &lt;lubuntu-ip&gt;\n</code></pre>"},{"location":"phase-2/san/lab07/#step-2-create-a-zvol","title":"Step 2: Create a Zvol","text":"<ol> <li>Browse to Datasets \u2192 Click on your TechOpsPool</li> <li>Click Add Zvol \u2192 Zvol name: <code>iscsi_zvol</code>, Size for this zvol: <code>10 GiB</code>.</li> <li>Leve all other fields as default</li> <li>Click on Save</li> </ol>"},{"location":"phase-2/san/lab07/#step-3-enable-iscsi-service","title":"Step 3: Enable iSCSI Service","text":"<ul> <li>Go to System \u2192 Services</li> <li>iSCSI \u2192 Running (Select) + Start Automatically (Select).</li> </ul>"},{"location":"phase-2/san/lab07/#step-4-configure-iscsi-target-wizard","title":"Step 4: Configure iSCSI Target Wizard","text":"<p>Go to Shares \u2192 Block Shares (iSCSI) \u2192 Wizard. </p> <ol> <li> <p>Target</p> <ul> <li>Target \u2192 Create New.</li> </ul> </li> <li> <p>Extent</p> <ul> <li>Name: <code>extent0</code>.</li> <li>Extent Type: Device.</li> <li>Device: Select the Zvol (<code>iscsi_zvol</code>).</li> <li>All other settings as default.</li> </ul> </li> <li> <p>Portal Options</p> <ul> <li>Portal: <code>Create New</code></li> <li>IP Address: <code>Add</code><ul> <li>IP Address: 0.0.0.0   </li> </ul> </li> <li>Initiators: <code>Leave Blank</code></li> </ul> </li> <li> <p>Click on <code>Save</code></p> </li> </ol>"},{"location":"phase-2/san/lab07/#step-3-adding-a-2nd-nic-in-virtualbox-bridged-mode","title":"Step 3: Adding a 2nd NIC in VirtualBox (Bridged Mode)","text":""},{"location":"phase-2/san/lab07/#1-power-down-truenas-vm","title":"1. Power Down TrueNAS VM","text":"<ul> <li>In VirtualBox main window \u2192 select TrueNAS VM</li> <li>Click Close \u2192 Power Off (or shut down gracefully inside TrueNAS).</li> </ul>"},{"location":"phase-2/san/lab07/#2-open-vm-settings","title":"2. Open VM Settings","text":"<ul> <li>Highlight your TrueNAS VM.</li> <li>Click \u2699\ufe0f Settings on the toolbar.</li> </ul>"},{"location":"phase-2/san/lab07/#3-go-to-network","title":"3. Go to Network","text":"<ul> <li>In the left menu \u2192 click Network.</li> <li>You\u2019ll see Adapter 1 already enabled (your current NIC).</li> </ul>"},{"location":"phase-2/san/lab07/#4-enable-adapter-2","title":"4. Enable Adapter 2","text":"<ul> <li>Click the Adapter 2 tab.</li> <li>Tick \u2705 Enable Network Adapter.</li> </ul>"},{"location":"phase-2/san/lab07/#5-configure-adapter-2","title":"5. Configure Adapter 2","text":"<ul> <li>Attached to: <code>Bridged Adapter</code></li> <li>Name: Select your host\u2019s actual physical network interface (e.g. Wi-Fi card or Ethernet port).</li> <li>Promiscuous Mode: <code>Allow All</code> (recommended for iSCSI multipath so no weird filtering happens).</li> <li>Cable Connected: \u2705 checked.</li> </ul>"},{"location":"phase-2/san/lab07/#6-save-boot","title":"6. Save &amp; Boot","text":"<ul> <li>Click OK.</li> <li>Start the TrueNAS VM.</li> </ul>"},{"location":"phase-2/san/lab07/#7-assign-ip-to-new-nic-inside-truenas","title":"7. Assign IP to New NIC inside TrueNAS","text":"<ul> <li>Log into TrueNAS web UI \u2192 Network \u2192 Interfaces \u2192 Add.</li> <li>Select the new NIC (will likely show up as <code>enp0s8</code>, <code>em1</code>, etc.).</li> <li>Set Static IP (e.g. <code>192.168.1.187/24</code>).</li> <li>Save + Apply.</li> </ul> <p>Now TrueNAS has:</p> <ul> <li>NIC1 \u2192 <code>192.168.1.186</code></li> <li>NIC2 \u2192 <code>192.168.1.187</code></li> </ul>"},{"location":"phase-2/san/lab07/#8-update-iscsi-portals","title":"8. Update iSCSI Portals","text":"<ul> <li>Go to Sharing \u2192 Block Shares (iSCSI) \u2192 Portals \u2192 Add.</li> <li>Create one portal bound to <code>192.168.1.186</code>.</li> <li>Create another portal bound to <code>192.168.1.187</code>.</li> </ul>"},{"location":"phase-2/san/lab07/#step-3-simulating-multiple-network-paths","title":"Step 3: Simulating Multiple Network Paths","text":"<p>To simulate multipathing in VirtualBox:</p> <ol> <li> <p>In TrueNAS VM \u2192 Settings \u2192 Network:</p> </li> <li> <p>Add a second network adapter (also set to Bridged Mode).</p> </li> <li>Restart the TrueNAS VM.</li> <li> <p>Assign an IP address to the second NIC inside TrueNAS (use the console menu if needed).    Example:</p> </li> <li> <p>NIC1: 192.168.1.120</p> </li> <li>NIC2: 192.168.1.121</li> </ol> <p>\u2705 Now the same iSCSI target is reachable through two network paths.</p>"},{"location":"phase-2/san/lab07/#step-4-connecting-lubuntu-to-iscsi-target","title":"Step 4: Connecting Lubuntu to iSCSI Target","text":"<ol> <li>On Lubuntu VM, install iSCSI initiator tools:</li> </ol> <pre><code>sudo apt update &amp;&amp; sudo apt install open-iscsi multipath-tools -y\n</code></pre> <ol> <li>Discover iSCSI targets from TrueNAS:</li> </ol> <pre><code>sudo iscsiadm -m discovery -t sendtargets -p &lt;truenas-ip&gt;\nsudo iscsiadm -m discovery -t sendtargets -p &lt;second-truenas-ip&gt;\n</code></pre> <ol> <li>Log in to discovered targets:</li> </ol> <pre><code>sudo iscsiadm -m node -l\n</code></pre> <ol> <li>Verify with:</li> </ol> <pre><code>lsblk\n</code></pre> <p>You should see a new disk (e.g., <code>/dev/sdb</code>).</p>"},{"location":"phase-2/san/lab07/#step-5-configuring-multipath-io-mpio","title":"Step 5: Configuring Multipath I/O (MPIO)","text":"<ol> <li>Enable multipath service:</li> </ol> <pre><code>sudo systemctl enable multipath-tools\nsudo systemctl start multipath-tools\n</code></pre> <ol> <li>Check multipath configuration:</li> </ol> <pre><code>sudo multipath -ll\n</code></pre> <p>You should see both paths listed to the iSCSI target.</p> <ol> <li>Create a filesystem and mount it:</li> </ol> <pre><code>sudo mkfs.ext4 /dev/mapper/mpatha\nsudo mkdir /mnt/iscsi\nsudo mount /dev/mapper/mpatha /mnt/iscsi\n</code></pre> <ol> <li>Verify:</li> </ol> <pre><code>df -h\nls /mnt/iscsi\n</code></pre>"},{"location":"phase-2/san/lab07/#step-6-testing-high-availability","title":"Step 6: Testing High Availability","text":"<ol> <li>From VirtualBox, temporarily disable one network adapter of the TrueNAS VM.</li> <li>On Lubuntu, run:</li> </ol> <pre><code>multipath -ll\n</code></pre> <p>You should still see one active path. 3. Access <code>/mnt/iscsi</code> and create a file:</p> <p><pre><code>echo \"HA Test File\" | sudo tee /mnt/iscsi/test.txt\n</code></pre> 4. Re-enable the network adapter and verify both paths are restored.</p> <p>\u2705 This confirms that multipath I/O maintains connectivity even if one path fails.</p>"},{"location":"phase-2/san/lab07/#troubleshooting-tips","title":"Troubleshooting Tips","text":"<ul> <li>Target not visible: Ensure iSCSI service is enabled on TrueNAS.</li> <li>No multipath device: Restart multipath service and check discovery commands.</li> <li>Login errors: Verify firewall rules and that both NICs are on the same subnet.</li> <li>Performance issues: Allocate more RAM/CPU to TrueNAS VM.</li> </ul> <p>\u2705 Congratulations! You have successfully configured iSCSI targets on TrueNAS and set up Multipath I/O on Lubuntu to simulate high availability in a SAN environment.</p>"},{"location":"phase-2/san/lab08/","title":"Lab 08: Configuring File-Based Storage with NFS and SMB (OPTIONAL)","text":""},{"location":"phase-2/san/lab08/#introduction","title":"Introduction","text":"<p>In this lab, you will configure file-based storage protocols using TrueNAS. Specifically, you will set up:</p> <ul> <li>NFS (Network File System) for Linux clients (Lubuntu VM).</li> <li>SMB (Server Message Block/CIFS) for Windows clients (your Host PC).</li> </ul> <p>This demonstrates how SAN/NAS systems also provide file-level storage in addition to block-level (iSCSI) access.</p> <p>By the end of this lab, you will:</p> <ul> <li>Enable and configure NFS shares.</li> <li>Enable and configure SMB shares.</li> <li>Access NFS shares from your Lubuntu VM.</li> <li>Access SMB shares from your Windows Host PC.</li> </ul>"},{"location":"phase-2/san/lab08/#step-1-preparing-the-environment","title":"Step 1: Preparing the Environment","text":"<ol> <li>Ensure your TrueNAS VM is running and <code>TechOpsPool</code> exists.</li> <li>Ensure your Lubuntu VM (Lab 03) is running.</li> <li>Ensure your Windows Host is connected to the same bridged network.</li> </ol>"},{"location":"phase-2/san/lab08/#step-2-configuring-an-nfs-share-in-truenas","title":"Step 2: Configuring an NFS Share in TrueNAS","text":"<ol> <li>Log in to the TrueNAS Web Interface.</li> <li>Go to Sharing \u2192 Unix Shares (NFS).</li> <li>Click Add.</li> <li>Path: <code>/mnt/TechOpsPool/DevTeam</code></li> <li>Allow network: <code>192.168.0.0/24</code> (adjust for your subnet).</li> <li>Save and start the NFS service.</li> </ol> <p>\u2705 NFS share is now active.</p>"},{"location":"phase-2/san/lab08/#step-3-accessing-nfs-share-from-lubuntu-vm","title":"Step 3: Accessing NFS Share from Lubuntu VM","text":"<ol> <li>On Lubuntu, open the terminal.</li> <li>Install NFS client tools:</li> </ol> <p><pre><code>sudo apt update &amp;&amp; sudo apt install nfs-common -y\n</code></pre> 3. Create a mount point:</p> <p><pre><code>sudo mkdir /mnt/devteam\n</code></pre> 4. Mount the NFS share:</p> <p><pre><code>sudo mount &lt;truenas-ip&gt;:/mnt/TechOpsPool/DevTeam /mnt/devteam\n</code></pre> 5. Verify:</p> <p><pre><code>ls /mnt/devteam\n</code></pre> 6. Test by creating a file:</p> <pre><code>echo \"Hello from Lubuntu\" | sudo tee /mnt/devteam/lubuntu_test.txt\n</code></pre> <p>\u2705 The file is now stored on TrueNAS and accessible from other clients.</p>"},{"location":"phase-2/san/lab08/#step-4-configuring-an-smb-share-in-truenas","title":"Step 4: Configuring an SMB Share in TrueNAS","text":"<ol> <li>In the TrueNAS web interface, go to Sharing \u2192 Windows Shares (SMB).</li> <li>Click Add.</li> <li>Path: <code>/mnt/TechOpsPool/DevTeam</code></li> <li>Name: <code>DevShare</code></li> <li>Save and enable the SMB service.</li> </ol> <p>\u2705 SMB share is now active.</p>"},{"location":"phase-2/san/lab08/#step-5-accessing-smb-share-from-windows-host","title":"Step 5: Accessing SMB Share from Windows Host","text":"<ol> <li> <p>On your Windows 11 Host:</p> </li> <li> <p>Open File Explorer.</p> </li> <li> <p>In the address bar, type:</p> <pre><code>\\\\&lt;truenas-ip&gt;\\DevShare\n</code></pre> <p>Example: <code>\\\\192.168.1.120\\DevShare</code> 2. Enter credentials:</p> </li> <li> <p>Username: <code>root</code></p> </li> <li>Password: (set during TrueNAS installation)</li> <li>You should now see the share contents.</li> <li>Test by creating a text file (<code>windows_test.txt</code>) inside the share.</li> </ol> <p>\u2705 Both Lubuntu and Windows can now access the same dataset over different protocols.</p>"},{"location":"phase-2/san/lab08/#step-6-verifying-cross-access","title":"Step 6: Verifying Cross-Access","text":"<ol> <li>On Lubuntu VM, check if the Windows file is visible:</li> </ol> <pre><code>ls /mnt/devteam\n</code></pre> <p>You should see <code>windows_test.txt</code>.</p> <ol> <li>On Windows Host, refresh the SMB share \u2014 you should see <code>lubuntu_test.txt</code> created earlier.</li> </ol> <p>\u2705 This confirms that multiple clients can access the same dataset using different file-sharing protocols.</p>"},{"location":"phase-2/san/lab08/#troubleshooting-tips","title":"Troubleshooting Tips","text":"<ul> <li>NFS mount fails: Ensure NFS service is running and subnet is correctly set in TrueNAS.</li> <li>Windows cannot access share: Enable SMB1/SMB2 in Windows features if needed.</li> <li>Authentication issues: Use the <code>root</code> account or create a dedicated SMB user in TrueNAS.</li> <li>Firewall issues: Allow SMB/NFS ports (111, 2049, 445) on your network.</li> </ul> <p>\u2705 Congratulations! You have successfully configured NFS and SMB shares on TrueNAS, and accessed them from both Lubuntu and Windows Host. This simulates real-world file sharing in mixed environments.</p>"},{"location":"phase-2/san/lab09/","title":"Lab 09: Deploying Object Storage with MinIO","text":""},{"location":"phase-2/san/lab09/#introduction","title":"Introduction","text":"<p>In this lab, you will deploy MinIO, an open-source, high-performance object storage server. MinIO is compatible with the Amazon S3 API, making it perfect for learning modern cloud-native storage concepts.</p> <p>By the end of this lab, you will:</p> <ul> <li>Install MinIO inside your Lubuntu VM (Lab 03).</li> <li>Run the MinIO server with local storage.</li> <li>Access the MinIO web interface.</li> <li>Create a bucket, upload/download objects.</li> <li>Configure access policies.</li> </ul> <p>This simulates how enterprises use object storage for unstructured data like images, videos, and backups.</p>"},{"location":"phase-2/san/lab09/#step-1-preparing-lubuntu-vm","title":"Step 1: Preparing Lubuntu VM","text":"<ol> <li>Ensure your Lubuntu VM (Lab 03) is running.</li> <li>Open a terminal inside Lubuntu.</li> <li>Update packages:</li> </ol> <pre><code>sudo apt update &amp;&amp; sudo apt upgrade -y\n</code></pre>"},{"location":"phase-2/san/lab09/#step-2-installing-minio","title":"Step 2: Installing MinIO","text":"<ol> <li>Download MinIO server binary:</li> </ol> <p><pre><code>wget https://dl.min.io/server/minio/release/linux-amd64/minio -O minio\n</code></pre> 2. Make it executable:</p> <p><pre><code>chmod +x minio\n</code></pre> 3. Move it to a system-wide location:</p> <pre><code>sudo mv minio /usr/local/bin/\n</code></pre> <p>\u2705 MinIO server is now installed.</p>"},{"location":"phase-2/san/lab09/#step-3-running-minio-server","title":"Step 3: Running MinIO Server","text":"<ol> <li>Create a directory for MinIO data:</li> </ol> <p><pre><code>mkdir ~/minio-data\n</code></pre> 2. Run the MinIO server:</p> <p><pre><code>minio server ~/minio-data --console-address \":9001\"\n</code></pre> 3. On first run, MinIO will display Access Key and Secret Key. Copy these values (you will need them to log in).</p>"},{"location":"phase-2/san/lab09/#step-4-accessing-the-minio-web-interface","title":"Step 4: Accessing the MinIO Web Interface","text":"<ol> <li>On your Windows Host PC, open a browser.</li> <li>Go to:</li> </ol> <pre><code>http://&lt;lubuntu-ip&gt;:9001\n</code></pre> <p>Example: <code>http://192.168.1.130:9001</code> 3. Log in with the Access Key and Secret Key provided by MinIO.</p> <p>\u2705 You are now inside the MinIO Web Console.</p>"},{"location":"phase-2/san/lab09/#step-5-creating-a-bucket","title":"Step 5: Creating a Bucket","text":"<ol> <li>In the MinIO console, click Buckets \u2192 Create Bucket.</li> <li>Name the bucket: <code>techops-bucket</code>.</li> <li>Keep default settings and save.</li> </ol> <p>\u2705 A bucket is like a folder for storing objects.</p>"},{"location":"phase-2/san/lab09/#step-6-uploading-and-downloading-objects","title":"Step 6: Uploading and Downloading Objects","text":"<ol> <li>Inside the <code>techops-bucket</code>, click Upload.</li> <li>Upload a simple text file or image (e.g., <code>hello.txt</code>).</li> <li>Verify the object appears in the bucket.</li> <li>Click on the object \u2192 Download to confirm you can retrieve it.</li> </ol> <p>\u2705 You have successfully uploaded and downloaded objects.</p>"},{"location":"phase-2/san/lab09/#step-7-sharing-the-files","title":"Step 7: Sharing the files","text":"<ol> <li>In the <code>techops-bucket</code> that you created, select the file you just uploaded by selecting checkmark on the left side of the file name.</li> <li>In the sub-menu on right side, you will find the Share button, click on it.</li> <li>Accept the default values for sharing time or add as per your needs.</li> <li>Copy the link and share to your instructor on Slack and updte your Jira Card for the lab.</li> </ol> <p>\u2705 You can now access the file directly via URL now.</p> <p>\u26a0\ufe0f Note: In production, access policies should be restricted for security.</p>"},{"location":"phase-2/san/lab09/#step-8-optional-using-minio-client-mc","title":"Step 8: (Optional) Using MinIO Client (mc)","text":"<ol> <li>Download MinIO client:</li> </ol> <p><pre><code>wget https://dl.min.io/client/mc/release/linux-amd64/mc -O mc\nchmod +x mc\nsudo mv mc /usr/local/bin/\n</code></pre> 2. Configure alias:</p> <p><pre><code>mc alias set local http://localhost:9000 &lt;ACCESS_KEY&gt; &lt;SECRET_KEY&gt;\n</code></pre> 3. List buckets:</p> <pre><code>mc ls local\n</code></pre> <p>\u2705 MinIO client provides powerful command-line management.</p>"},{"location":"phase-2/san/lab09/#troubleshooting-tips","title":"Troubleshooting Tips","text":"<ul> <li>Can\u2019t access web console: Ensure Lubuntu VM uses Bridged Adapter networking.</li> <li>Port blocked: Verify firewall rules, allow TCP ports <code>9000</code> and <code>9001</code>.</li> <li>Forgot access key/secret key: Restart the MinIO server \u2014 new keys will be generated.</li> <li>MinIO crashes on low RAM: Allocate at least 2 GB RAM to Lubuntu VM.</li> </ul> <p>\u2705 Congratulations! You have successfully deployed MinIO object storage, created a bucket, uploaded files, and configured access policies. You now understand how object storage works in modern cloud environments.</p>"},{"location":"phase-2/virtualization/01_introduction/","title":"Virtualization","text":""},{"location":"phase-2/virtualization/01_introduction/#so-what-is-virtualization","title":"So What is Virtualization?","text":""},{"location":"phase-2/virtualization/01_introduction/#virtualization-and-cluster-basics","title":"Virtualization and Cluster Basics","text":""},{"location":"phase-2/virtualization/01_introduction/#1-introduction-of-virtualization","title":"1. Introduction of Virtualization","text":""},{"location":"phase-2/virtualization/01_introduction/#what-is-it","title":"What is it?","text":"<p>Virtualization is the process of creating a virtual version of a physical resource such as a server, operating system, storage device, or network. It allows multiple virtual environments to run on the same physical machine.</p>"},{"location":"phase-2/virtualization/01_introduction/#theoretical-definition","title":"Theoretical Definition","text":"<p>According to the Cloud Computing Black Book (2024), virtualization is the technology that abstracts computing resources from the underlying hardware and makes them available as software-defined instances. For example, instead of running one operating system on one physical server, we can run multiple OS instances (called virtual machines) on the same hardware using a hypervisor.</p>"},{"location":"phase-2/virtualization/01_introduction/#example","title":"Example","text":"<ul> <li>A single physical server in a data center can host multiple virtual machines, each running different operating systems (e.g., Windows, Linux).  </li> </ul> <p>WOW Tip</p> <p>Virtualization is one of the key technologies that made cloud computing possible, because it enabled resource pooling and efficient hardware utilization.</p>"},{"location":"phase-2/virtualization/01_introduction/#2-virtualization-types-type-1-and-type-2","title":"2. Virtualization Types: Type 1 and Type 2","text":""},{"location":"phase-2/virtualization/01_introduction/#what-is-it_1","title":"What is it?","text":"<p>There are two main types of virtualization based on how the hypervisor interacts with hardware.</p>"},{"location":"phase-2/virtualization/01_introduction/#theoretical-definition_1","title":"Theoretical Definition","text":"<ul> <li>Type 1 Hypervisor (Bare-metal): Runs directly on the hardware without needing an operating system. It provides better performance and efficiency.  </li> <li>Type 2 Hypervisor (Hosted): Runs on top of a host operating system, making it easier to set up but with slightly less performance.</li> </ul>"},{"location":"phase-2/virtualization/01_introduction/#example_1","title":"Example","text":"<ul> <li>Type 1: VMware ESXi, Microsoft Hyper-V, Citrix XenServer  </li> <li>Type 2: Oracle VirtualBox, VMware Workstation  </li> </ul>"},{"location":"phase-2/virtualization/01_introduction/#wow-tip","title":"WOW Tip","text":"<p>Type 1 hypervisors are commonly used in enterprise data centers where performance and reliability are critical.</p>"},{"location":"phase-2/virtualization/01_introduction/#5-cluster-architecture","title":"5. Cluster Architecture","text":""},{"location":"phase-2/virtualization/01_introduction/#what-is-it_2","title":"What is it?","text":"<p>A cluster is a group of interconnected computers (or nodes) that work together as a single system to provide high availability, performance, and scalability.</p>"},{"location":"phase-2/virtualization/01_introduction/#theoretical-definition_2","title":"Theoretical Definition","text":"<p>Cluster architecture distributes workloads across multiple nodes. If one node fails, others continue to provide services, ensuring reliability.</p>"},{"location":"phase-2/virtualization/01_introduction/#example_2","title":"Example","text":"<ul> <li>A web server cluster can have multiple servers hosting the same website. If one fails, traffic is redirected to another server.  </li> <li>Hadoop clusters are used for big data processing.</li> </ul>"},{"location":"phase-2/virtualization/01_introduction/#wow-tip_1","title":"WOW Tip","text":"<p>Google built its early search engine on clusters of commodity servers, proving that clusters can outperform supercomputers at scale.</p>"},{"location":"phase-2/virtualization/01_introduction/#6-cluster-requirements","title":"6. Cluster Requirements","text":""},{"location":"phase-2/virtualization/01_introduction/#what-is-it_3","title":"What is it?","text":"<p>For a cluster to work effectively, certain hardware, software, and network requirements must be met.</p>"},{"location":"phase-2/virtualization/01_introduction/#theoretical-definition_3","title":"Theoretical Definition","text":"<p>A cluster requires: - Nodes (servers with adequate CPU, memory, and storage) - Networking (high-speed interconnects like Gigabit or InfiniBand) - Shared Storage (SAN, NAS, or distributed file systems) - Cluster Management Software (e.g., Kubernetes, Hadoop YARN, or Windows Failover Clustering)  </p>"},{"location":"phase-2/virtualization/01_introduction/#example_3","title":"Example","text":"<ul> <li>A database cluster may need redundant storage and a reliable network to avoid single points of failure.  </li> </ul>"},{"location":"phase-2/virtualization/02_concepts/","title":"Virtualization Concepts: Hardware, Para-Virtualization, Cloning, Snapshot, Template","text":""},{"location":"phase-2/virtualization/02_concepts/#what-is-it","title":"What is it?","text":"<p>Beyond just creating VMs, virtualization includes advanced techniques for performance, backup, and scalability.</p>"},{"location":"phase-2/virtualization/02_concepts/#theoretical-definition","title":"Theoretical Definition","text":"<ul> <li>Hardware Virtualization: Hypervisor creates a virtual hardware environment for VMs.  </li> <li>Para-Virtualization: Guest OS is aware it\u2019s running in a virtualized environment and communicates with the hypervisor more efficiently.  </li> <li>Cloning: Creating an exact copy of a VM for testing or deployment.  </li> <li>Snapshot: A saved state of a VM at a given point in time, useful for rollback.  </li> <li>Template: A pre-configured master copy of a VM used for quickly deploying new instances.</li> </ul>"},{"location":"phase-2/virtualization/02_concepts/#example","title":"Example","text":"<ul> <li>Developers often use snapshots before installing new software on a VM\u2014if something goes wrong, they roll back easily.  </li> <li>Organizations maintain templates for standard servers (like web servers or database servers).</li> </ul>"},{"location":"phase-2/virtualization/02_concepts/#explanations","title":"Explanations","text":"<ul> <li>Hardware Virtualization   Hardware virtualization is when the hypervisor emulates the underlying physical hardware and provides each virtual machine (VM) with its own virtual CPU, memory, storage, and network.   This allows multiple operating systems to run simultaneously on the same physical hardware without interfering with each other.</li> </ul> <p>Example: A physical server running VMware ESXi can host a Linux VM, a Windows VM, and a BSD VM at the same time \u2014 each VM thinks it has its own dedicated hardware.</p> <ul> <li>Para-Virtualization   In para-virtualization, the guest operating system is modified so it is aware that it is running in a virtualized environment. Instead of pretending it has direct hardware access, it communicates with the hypervisor using special APIs (called hypercalls).   This reduces overhead and improves performance compared to full hardware virtualization.  </li> </ul> <p>Example: Xen hypervisor allows para-virtualization, where a Linux guest OS can be optimized to run more efficiently by interacting directly with the Xen layer.  </p> <ul> <li>Cloning   Cloning is the process of creating an exact copy of an existing virtual machine. The new VM will have the same OS, applications, and settings as the original.   Cloning is commonly used to quickly deploy multiple identical systems for testing, training, or scaling up workloads.  </li> </ul> <p>Example: An organization may clone a pre-configured \u201cgolden image\u201d VM of a web server to instantly spin up 10 identical servers during peak traffic.  </p> <ul> <li>Snapshot   A snapshot captures the state of a VM at a specific point in time, including memory, disk, and settings.   Snapshots are useful for backup and rollback: if something goes wrong (e.g., software upgrade failure), the VM can be restored to the exact state it was in when the snapshot was taken.  </li> </ul> <p>Example: Before applying security patches, an admin takes a snapshot of the VM. If the patch causes issues, the VM can be reverted to the snapshot in minutes.  </p> <p>Note</p> <p>Snapshots are not replacements for backups. They are temporary and can consume a lot of storage if not managed properly.  </p> <ul> <li>Template   A template is a master copy of a virtual machine that is pre-installed with an operating system, configurations, and base applications.   Unlike a snapshot, templates are used to create new VMs, not to restore existing ones. They ensure consistency and save time when deploying multiple machines. Example: A template of an Ubuntu server with Apache pre-installed can be used to deploy multiple web servers instantly without manual setup.  </li> </ul>"},{"location":"phase-2/virtualization/02_concepts/#comparision","title":"Comparision","text":"Feature Snapshot Cloning Template Purpose Save VM state at a point in time Create an identical copy of a VM Create a reusable master for new VMs Creates New VM? \u274c No \u2705 Yes \u2705 Yes Storage Usage Incremental (depends on changes) Full copy (large storage required) Base image (efficient, reused many times) Use Case Rollback, testing, upgrades Testing, scaling, quick duplication Standardized deployments Persistence Temporary (not for long-term) Permanent VM Permanent reference image Performance Impact Can slow down over time if many Independent VM with full performance New VMs perform like normal Admin Best Practice Use before risky changes/patches Use for short-term duplication or testing Use to enforce consistency in deployments"},{"location":"phase-2/virtualization/02_concepts/#4-operating-system-virtualization","title":"4. Operating System Virtualization","text":""},{"location":"phase-2/virtualization/02_concepts/#what-is-it_1","title":"What is it?","text":"<p>This is virtualization at the OS level, where the kernel allows multiple isolated user-space instances to run on the same operating system.</p>"},{"location":"phase-2/virtualization/02_concepts/#theoretical-definition_1","title":"Theoretical Definition","text":"<p>OS virtualization provides lightweight, isolated environments known as containers. Unlike VMs, containers share the same OS kernel but are isolated from each other.</p>"},{"location":"phase-2/virtualization/02_concepts/#example_1","title":"Example","text":"<ul> <li>Docker and LXC (Linux Containers) are widely used OS virtualization technologies.  </li> <li>Running multiple microservices in containers on the same machine is a common DevOps practice.</li> </ul>"},{"location":"phase-2/virtualization/02_concepts/#wow-tip","title":"WOW Tip","text":"<p>Containers have become the backbone of microservices architectures and cloud-native applications.</p>"},{"location":"phase-2/virtualization/03_os_virtualization/","title":"Operating System Virtualization","text":""},{"location":"phase-2/virtualization/03_os_virtualization/#what-is-it","title":"What is it?","text":"<p>Operating System (OS) virtualization is a form of virtualization where the host operating system allows multiple isolated user environments (often called containers) to run on the same kernel. Unlike traditional virtualization, which creates separate virtual hardware for each virtual machine, OS virtualization shares the same kernel but isolates applications and processes so they behave as if running on separate systems.</p>"},{"location":"phase-2/virtualization/03_os_virtualization/#theoretical-definition","title":"Theoretical Definition","text":"<p>OS virtualization provides lightweight, portable, and isolated execution environments on top of a single operating system kernel. Each container has its own libraries, binaries, and dependencies, but all containers share the same underlying kernel. This makes them faster and more resource-efficient compared to full virtual machines.</p>"},{"location":"phase-2/virtualization/03_os_virtualization/#examples","title":"Examples","text":"<ul> <li>Docker: The most popular container platform, enabling developers to package applications with all dependencies into portable containers.  </li> <li>Linux Containers (LXC): An earlier containerization technology that provides OS-level isolation.  </li> <li>Podman and CRI-O: Alternatives to Docker for container management in enterprise and Kubernetes environments.  </li> </ul> <p>Use Case Example A company wants to deploy three microservices: - Service A (Python API) - Service B (Node.js backend) - Service C (MySQL database)  </p> <p>Instead of running three separate VMs (which would each need an OS), they can run all three as containers on the same Linux host \u2014 saving memory, CPU, and time.</p> <p>WOW Tip</p> <p>Containers are the foundation of cloud-native computing. Tech giants like Google, Netflix, and Amazon rely heavily on containers for scaling millions of services daily.</p> <p>Fun Fact</p> <p>Google launches over 2 billion containers every week internally using its Borg system (the predecessor of Kubernetes).  </p>"},{"location":"phase-2/virtualization/03_os_virtualization/#key-advantages","title":"Key Advantages","text":"<ul> <li>Lightweight: Containers start in seconds (unlike VMs that take minutes).  </li> <li>Portable: Run the same container image across a laptop, data center, or cloud.  </li> <li>Efficient: Use fewer resources since the OS kernel is shared.  </li> <li>Scalable: Ideal for microservices and DevOps pipelines.  </li> </ul>"},{"location":"phase-2/virtualization/03_os_virtualization/#quick-comparison-containers-vs-virtual-machines","title":"Quick Comparison: Containers vs Virtual Machines","text":"Aspect Containers (OS Virtualization) Virtual Machines (Hardware Virtualization) Kernel Shared with host OS Separate for each VM Size MBs (lightweight images) GBs (full OS + applications) Startup Time Seconds Minutes Isolation Process-level isolation Full hardware-level isolation Use Case Microservices, CI/CD, cloud-native apps Legacy apps, full OS environments"},{"location":"phase-2/virtualization/04_clusters/","title":"Clusters","text":""},{"location":"phase-2/virtualization/04_clusters/#cluster-architecture","title":"Cluster Architecture","text":""},{"location":"phase-2/virtualization/04_clusters/#what-is-it","title":"What is it?","text":"<p>A cluster is a group of interconnected computers (called nodes) that operate together as if they were a single system. The goal of a cluster is to improve availability, performance, and scalability by combining the resources of multiple machines.</p>"},{"location":"phase-2/virtualization/04_clusters/#theoretical-definition","title":"Theoretical Definition","text":"<p>Cluster architecture is the design and arrangement of multiple nodes that share workloads to provide seamless services. Key idea: If one node fails, others in the cluster continue the work, ensuring fault tolerance and high availability.  </p> <p>Clusters can be designed for: - Load Balancing: Distributing requests across multiple nodes (e.g., web server farms). - High Availability (HA): Ensuring uptime by having standby nodes ready to take over. - High Performance (HPC): Using parallel computing across nodes for tasks like scientific research or big data.  </p>"},{"location":"phase-2/virtualization/04_clusters/#examples","title":"Examples","text":"<ul> <li>Web Server Cluster: Multiple servers host the same website. A load balancer distributes user requests across them. If one server fails, traffic goes to others.  </li> <li>Hadoop Cluster: Used in big data, it distributes data and computations across many machines.  </li> <li>Database Cluster: Ensures redundancy and faster read/write operations by replicating data across nodes.  </li> </ul> <p>WOW Tip</p> <p>Google\u2019s early search engine ran on clusters of inexpensive commodity hardware instead of supercomputers. This proved that clusters could deliver world-class scalability at low cost, shaping the future of cloud computing.  </p>"},{"location":"phase-2/virtualization/04_clusters/#cluster-requirements","title":"Cluster Requirements","text":""},{"location":"phase-2/virtualization/04_clusters/#what-is-it_1","title":"What is it?","text":"<p>For a cluster to function properly, it must meet certain hardware, networking, and software requirements. If these are not fulfilled, the cluster may suffer from performance bottlenecks or single points of failure.</p>"},{"location":"phase-2/virtualization/04_clusters/#theoretical-definition_1","title":"Theoretical Definition","text":"<p>A cluster requires the following components:  </p> <ol> <li> <p>Nodes </p> <ul> <li>The physical or virtual servers that form the cluster.  </li> <li>Each should have adequate CPU, RAM, storage, and compatible operating systems.  </li> </ul> </li> <li> <p>Networking </p> <ul> <li>High-speed communication is critical.  </li> <li>Typically Gigabit Ethernet or InfiniBand for faster data transfer.  </li> </ul> </li> <li> <p>Shared Storage </p> <ul> <li>Centralized storage (SAN, NAS, or distributed file systems like HDFS) ensures all nodes can access the same data.  </li> <li>Redundancy (RAID, replication) is essential to prevent data loss.  </li> </ul> </li> <li> <p>Cluster Management Software </p> <ul> <li>Software that monitors and coordinates the cluster.  </li> <li>Examples: Kubernetes (containers), Hadoop YARN (big data), Windows Server Failover Clustering, Red Hat Pacemaker (Linux HA).  </li> </ul> </li> </ol>"},{"location":"phase-2/virtualization/04_clusters/#examples_1","title":"Examples","text":"<ul> <li>A database cluster needs redundant storage and reliable networking to avoid downtime.  </li> <li>A Kubernetes cluster requires multiple master and worker nodes, with etcd for configuration and state management.  </li> <li>A scientific HPC cluster may require specialized interconnects like InfiniBand for parallel computing speed.  </li> </ul> <p>WOW Tip</p> <p>Modern cloud-native clusters (like Kubernetes) can self-heal: if one container or node fails, the cluster automatically restarts or reassigns workloads, often without human intervention.  </p>"},{"location":"phase-2/virtualization/lab03/","title":"Lab 03: Create and Configure a Virtual Machine Using VirtualBox","text":""},{"location":"phase-2/virtualization/lab03/#introduction-to-virtualbox","title":"Introduction to VirtualBox","text":"<p>Oracle VirtualBox is a free and open-source virtualization software that allows you to run multiple operating systems on your computer. Instead of using multiple physical machines, VirtualBox lets you create Virtual Machines (VMs) \u2014 software-based computers that run like real ones. It is widely used for testing, learning, and development because it is lightweight and easy to use.</p>"},{"location":"phase-2/virtualization/lab03/#step-1-downloading-and-installing-virtualbox","title":"Step 1: Downloading and Installing VirtualBox","text":"<ol> <li> <p>Open a web browser and go to the official VirtualBox download page:    \ud83d\udc49 https://www.virtualbox.org/wiki/Downloads</p> </li> <li> <p>Download the latest stable version for Windows hosts.</p> </li> <li> <p>Once the installer is downloaded, double-click the file to begin installation.</p> </li> <li> <p>Installation steps:</p> <ul> <li>Click Next through the setup wizard.</li> <li>Keep the default options.</li> <li>Allow installation of network adapters when prompted.</li> <li>Click Install and wait for the process to finish.</li> </ul> </li> <li> <p>After installation, launch VirtualBox from the Start Menu.</p> </li> </ol>"},{"location":"phase-2/virtualization/lab03/#step-2-downloading-a-lightweight-linux-os","title":"Step 2: Downloading a Lightweight Linux OS","text":"<p>For this lab, we will use Lubuntu \u2014 a lightweight, beginner-friendly Linux distribution.</p> <ol> <li> <p>Go to the official Lubuntu downloads page:    \ud83d\udc49 https://lubuntu.me/downloads/</p> </li> <li> <p>Download the latest LTS ISO (as of September 2025: Lubuntu 24.04 LTS).</p> </li> <li> <p>Optional: Verify the download integrity by checking the checksum provided on the website.</p> </li> </ol>"},{"location":"phase-2/virtualization/lab03/#step-3-navigating-virtualbox-interface","title":"Step 3: Navigating VirtualBox Interface","text":"<p>When you open VirtualBox, you will see: - Toolbar: Create, Start, Settings, and other VM management options. - Main Window: List of all created VMs. - Details Panel: Shows the configuration of the selected VM.</p>"},{"location":"phase-2/virtualization/lab03/#step-4-creating-a-new-virtual-machine","title":"Step 4: Creating a New Virtual Machine","text":"<ol> <li>Click New in VirtualBox.</li> <li> <p>Enter the following details:</p> <ul> <li>Name: <code>Lubuntu_VM</code></li> <li>Type: Linux</li> <li>Version: Ubuntu (64-bit)</li> </ul> </li> <li> <p>Assign hardware resources:</p> <ul> <li>RAM: 2048 MB (2 GB)</li> <li>CPU: 2 processors</li> </ul> </li> <li> <p>Create a virtual hard disk:</p> <ul> <li>Select VDI (VirtualBox Disk Image)</li> <li>Choose Dynamically allocated</li> <li>Set size to 20 GB</li> </ul> </li> <li> <p>Attach the downloaded Lubuntu ISO:</p> <ul> <li>Go to Settings \u2192 Storage</li> <li>Under Controller: IDE, click the Empty disk icon</li> <li>Choose Optical Disk \u2192 Select a disk file</li> <li>Browse and select the downloaded <code>lubuntu-24.04.iso</code></li> </ul> </li> </ol>"},{"location":"phase-2/virtualization/lab03/#step-5-deploying-the-iso-and-installing-linux","title":"Step 5: Deploying the ISO and Installing Linux","text":"<ol> <li>Start the VM.</li> <li>The Lubuntu installer will appear.</li> <li> <p>Follow these beginner-friendly steps:</p> <ul> <li>Select Language: English (default)</li> <li>Choose Install Lubuntu</li> <li>Select Erase disk and install (safe inside VM)</li> <li>Set a username and password</li> <li>Continue installation until finished</li> <li>Restart the VM and log in to your new Linux desktop.</li> </ul> </li> </ol>"},{"location":"phase-2/virtualization/lab03/#step-6-networking-configuration","title":"Step 6: Networking Configuration","text":"<p>VirtualBox provides different networking modes:</p> <ul> <li>NAT: Default; allows internet but VM is hidden from local network.</li> <li>Bridged Adapter: VM appears as another device on the same network (recommended).</li> <li>Host-Only: VM communicates only with host.</li> <li>Internal: VM communicates only with other VMs.</li> <li>NAT Network: Like NAT, but supports multiple VMs.</li> </ul> <p>\ud83d\udc49 For this lab, select Bridged Adapter:</p> <ol> <li>Go to Settings \u2192 Network</li> <li>Change Attached to: <code>Bridged Adapter</code></li> <li>Select your active network adapter (e.g., Wi-Fi or Ethernet).</li> </ol>"},{"location":"phase-2/virtualization/lab03/#step-7-accessing-the-vm","title":"Step 7: Accessing the VM","text":""},{"location":"phase-2/virtualization/lab03/#logging-in","title":"Logging in","text":"<ul> <li>Use the credentials you created during installation.</li> <li>You can interact with the desktop interface.</li> </ul>"},{"location":"phase-2/virtualization/lab03/#terminal-access-from-windows-11","title":"Terminal Access from Windows 11","text":"<ol> <li> <p>Find the VM\u2019s IP address:    <pre><code>ip addr\n</code></pre>    Look for an entry like <code>192.168.x.x</code></p> </li> <li> <p>Using Windows Terminal:    <pre><code>ssh username@192.168.x.x\n</code></pre></p> </li> <li> <p>If SSH is not installed, run inside the VM:    <pre><code>sudo apt update &amp;&amp; sudo apt install openssh-server\n</code></pre></p> </li> <li> <p>Using PuTTY (optional):</p> <ul> <li>Download PuTTY from: https://www.putty.org/</li> <li>Enter the VM\u2019s IP address in PuTTY.</li> <li>Login with your username and password.</li> </ul> </li> </ol>"},{"location":"phase-2/virtualization/lab03/#troubleshooting-tips","title":"Troubleshooting Tips","text":"<ul> <li>Black screen at boot: Ensure virtualization is enabled in BIOS/UEFI.</li> <li>No internet: Switch between NAT and Bridged mode.</li> <li>Cannot SSH: Check if OpenSSH is installed and running with:   <pre><code>sudo systemctl status ssh\n</code></pre></li> <li>Slow performance: Increase RAM/CPU allocation in VirtualBox settings.</li> </ul> <p>\u2705 You have successfully created and configured a Virtual Machine using VirtualBox!</p>"},{"location":"phase-2/virtualization/lab03/#video-walk-through","title":"Video Walk Through","text":""},{"location":"phase-2/virtualization/lab03/#installing-an-oracle-virtualbox","title":"Installing an Oracle VirtualBox","text":""},{"location":"phase-2/virtualization/lab03/#installing-lubuntu-on-virtualbox","title":"Installing Lubuntu on VirtualBox","text":""},{"location":"phase-2/virtualization/lab04/","title":"Lab 04: Deploying a Code on the Virtual Machine","text":""},{"location":"phase-2/virtualization/lab04/#introduction","title":"Introduction","text":"<p>In this lab, you will deploy a simple web application on the Linux Virtual Machine (VM) you created in Lab 03. We will use Apache, one of the most popular web servers, to host a \u201cHello World\u201d HTML page.</p> <p>By the end of this lab, you will: - Understand what Apache is and why it is used. - Learn where to run commands (inside the VM vs. outside on Windows). - Install and configure Apache inside your Linux VM. - Deploy and access a simple HTML web page from both inside the VM and your host machine.</p>"},{"location":"phase-2/virtualization/lab04/#step-1-what-is-apache","title":"Step 1: What is Apache?","text":"<p>Apache HTTP Server is free and open-source software that delivers web pages to users. When someone types your VM\u2019s IP address into a browser, Apache responds by sending back the web page files.</p> <p>Why Apache? - Easy to install and beginner-friendly. - Stable and widely used across the world. - Perfect for learning how web servers work.</p>"},{"location":"phase-2/virtualization/lab04/#step-2-tools-you-will-use","title":"Step 2: Tools You Will Use","text":"<ul> <li>Inside the VM: Linux Terminal (open from the VM\u2019s desktop menu).</li> <li>Outside the VM (Host Windows 11): A web browser like Microsoft Edge or Chrome to test access from your PC.</li> <li>Text Editor inside VM: We will use <code>nano</code> (a simple text editor in Linux).</li> </ul> <p>Keyboard shortcuts in nano:</p> <ul> <li>Save: <code>Ctrl + O</code>, then press Enter.</li> <li>Exit: <code>Ctrl + X</code>.</li> </ul>"},{"location":"phase-2/virtualization/lab04/#step-3-creating-a-sample-code","title":"Step 3: Creating a Sample Code","text":"<p>We will create a simple HTML file called <code>index.html</code>.</p> <p>Here is the code: <pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;title&gt;Hello World&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;h1&gt;Hello, World!&lt;/h1&gt;\n    &lt;p&gt;This is a simple webpage deployed on Apache.&lt;/p&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre></p> <p>Do not create it yet \u2014 we will add it later inside Apache\u2019s web directory.</p>"},{"location":"phase-2/virtualization/lab04/#step-4-setting-up-apache-inside-the-vm","title":"Step 4: Setting Up Apache (Inside the VM)","text":"<ol> <li> <p>Open a Terminal inside your VM.</p> </li> <li> <p>Update package lists:    <pre><code>sudo apt update\n</code></pre></p> </li> <li> <p>Install Apache:    <pre><code>sudo apt install apache2 -y\n</code></pre></p> </li> <li> <p>Start Apache:    <pre><code>sudo systemctl start apache2\n</code></pre></p> </li> <li> <p>Enable Apache to start automatically when the VM boots:    <pre><code>sudo systemctl enable apache2\n</code></pre></p> </li> <li> <p>Verify Apache is running:    <pre><code>systemctl status apache2\n</code></pre>    If successful, open a browser inside your VM and go to:    <pre><code>http://localhost\n</code></pre>    You should see the Apache welcome page.</p> </li> </ol>"},{"location":"phase-2/virtualization/lab04/#step-5-deploying-the-code-inside-the-vm","title":"Step 5: Deploying the Code (Inside the VM)","text":"<ol> <li> <p>Navigate to Apache\u2019s default web directory:    <pre><code>cd /var/www/html\n</code></pre></p> </li> <li> <p>Remove the default <code>index.html</code>:    <pre><code>sudo rm index.html\n</code></pre></p> </li> <li> <p>Create a new <code>index.html</code>:    <pre><code>sudo nano index.html\n</code></pre></p> </li> <li> <p>Paste the HTML code (from Step 3). Save with <code>Ctrl+O</code>, press Enter, then exit with <code>Ctrl+X</code>.</p> </li> <li> <p>Set proper permissions:    <pre><code>sudo chown -R www-data:www-data /var/www/html\nsudo chmod -R 755 /var/www/html\n</code></pre></p> </li> </ol>"},{"location":"phase-2/virtualization/lab04/#step-6-accessing-the-webpage","title":"Step 6: Accessing the Webpage","text":""},{"location":"phase-2/virtualization/lab04/#from-inside-the-vm","title":"From Inside the VM","text":"<ol> <li>Open Firefox (or the browser installed in your VM).</li> <li>Enter:    <pre><code>http://localhost\n</code></pre>    You should see your Hello World page.</li> </ol>"},{"location":"phase-2/virtualization/lab04/#from-the-host-machine-windows-11","title":"From the Host Machine (Windows 11)","text":"<ol> <li> <p>Find your VM\u2019s IP address inside the VM terminal:    <pre><code>ip addr\n</code></pre>    Look for a line like <code>inet 192.168.x.x</code> (not 127.0.0.1).</p> </li> <li> <p>Open your browser on Windows 11 and type:    <pre><code>http://&lt;vm-ip&gt;\n</code></pre>    Example: <code>http://192.168.1.55</code></p> </li> </ol> <p>If your VM networking is set to Bridged Adapter (from Lab 03), you will see the webpage from your host machine.</p>"},{"location":"phase-2/virtualization/lab04/#troubleshooting-tips","title":"Troubleshooting Tips","text":"<ul> <li>Apache not running: Restart with:   <pre><code>sudo systemctl restart apache2\n</code></pre></li> <li>Permission denied error: Check permissions on <code>/var/www/html</code>.</li> <li>Page not opening on host: Ensure VM network is set to Bridged Adapter in VirtualBox.</li> <li>Firewall issues: Allow Apache:   <pre><code>sudo ufw allow 'Apache Full'\n</code></pre></li> </ul> <p>\u2705 You have now successfully deployed and accessed a simple HTML web page hosted on your VM using Apache!</p>"},{"location":"phase-2/virtualization/lab04/#video-walkthrough","title":"Video Walkthrough","text":""},{"location":"phase-2/virtualization/lab04/#installing-apache-in-virtual-machine-using-windows-11-terminal","title":"Installing Apache in Virtual Machine using Windows 11 Terminal","text":""},{"location":"phase-3/00_terraform/","title":"Infrastructure as Code (IaC) with Terraform","text":""},{"location":"phase-3/00_terraform/#introduction-to-infrastructure-as-code-iac-and-terraform","title":"Introduction to Infrastructure as Code (IaC) and Terraform","text":""},{"location":"phase-3/00_terraform/#what-is-terraform","title":"What is Terraform?","text":""},{"location":"phase-3/00_terraform/#traditional-infrastructure-vs-iac","title":"Traditional Infrastructure vs IaC","text":"<p>Traditional Model</p> <ul> <li>Manual provisioning \u2192 Admins log into servers, install OS, configure networks, deploy applications.</li> <li> <p>Problems:</p> <ul> <li>Time-consuming (hours/days to set up infra)</li> <li>Error-prone (manual steps differ across environments)</li> <li>Scalability issues (hard to replicate for dev/test/prod)</li> </ul> </li> </ul> <p>Infrastructure as Code (IaC)</p> <ul> <li>Infra is defined using code (YAML, JSON, or HCL).</li> <li>Example: Instead of clicking buttons on AWS Console, you write <code>.tf</code> files that declare what you want (e.g., an EC2 VM).</li> <li> <p>Benefits:</p> <ul> <li>Versioning &amp; Auditability (Git tracks infra changes)</li> <li>Automation (fast provisioning + rollback)</li> <li>Reproducibility (same infra in dev/test/prod)</li> <li>Scalability (templates can spin up 100s of servers in minutes)</li> </ul> </li> </ul> <p>Terraform Overview</p> <ul> <li>Developed by HashiCorp.</li> <li>Cloud-agnostic: Works with AWS, Azure, GCP, VMware, OpenStack, Kubernetes.</li> <li> <p>Uses Declarative Configuration:</p> <ul> <li>You write what you need (desired state).</li> <li>Terraform figures out how to achieve it.</li> <li> <p>Key Commands:</p> </li> <li> <p><code>terraform init</code> \u2192 Initialize project &amp; download provider plugins.</p> </li> <li><code>terraform plan</code> \u2192 Preview infra changes before applying.</li> <li><code>terraform apply</code> \u2192 Provision infra.</li> <li><code>terraform destroy</code> \u2192 Tear down infra.</li> </ul> </li> </ul>"},{"location":"phase-3/00_terraform/#setting-up-the-terraform-environment","title":"Setting Up the Terraform Environment","text":""},{"location":"phase-3/00_terraform/#installation","title":"Installation","text":"<ol> <li>Download Terraform binary from terraform.io/downloads.</li> <li>Extract and move binary into PATH:</li> </ol> <pre><code>unzip terraform_1.8.5_linux_amd64.zip\nsudo mv terraform /usr/local/bin/\nterraform -version\n</code></pre>"},{"location":"phase-3/00_terraform/#configuring-a-cloud-provider-example-aws","title":"Configuring a Cloud Provider (Example: AWS)","text":"<ul> <li>Create IAM user with programmatic access.</li> <li>Generate Access Key + Secret Key.</li> <li>Configure credentials:</li> </ul> <p><pre><code>aws configure\n</code></pre> * Verify provider:</p> <pre><code>provider \"aws\" {\n  region = \"ap-south-1\"\n}\n</code></pre>"},{"location":"phase-3/00_terraform/#terraform-project-directory","title":"Terraform Project Directory","text":"<pre><code>project/\n\u251c\u2500\u2500 main.tf\n\u251c\u2500\u2500 variables.tf\n\u251c\u2500\u2500 outputs.tf\n\u251c\u2500\u2500 terraform.tfstate\n\u2514\u2500\u2500 .terraform/\n</code></pre>"},{"location":"phase-3/00_terraform/#writing-and-organizing-terraform-configuration-files","title":"Writing and Organizing Terraform Configuration Files","text":""},{"location":"phase-3/00_terraform/#hcl-hashicorp-configuration-language","title":"HCL (HashiCorp Configuration Language)","text":"<p>Blocks are fundamental:</p> <ul> <li>provider \u2192 Connects to a cloud</li> <li>resource \u2192 Defines infra objects</li> <li>variable \u2192 Input values</li> <li>output \u2192 Exported values</li> </ul>"},{"location":"phase-3/00_terraform/#example-simple-ec2-deployment","title":"Example: Simple EC2 Deployment","text":"<pre><code>provider \"aws\" {\n  region = \"ap-south-1\"\n}\n\nresource \"aws_instance\" \"web\" {\n  ami           = \"ami-0c55b159cbfafe1f0\"\n  instance_type = var.instance_type\n  tags = {\n    Name = \"TechOps-Web\"\n  }\n}\n\nvariable \"instance_type\" {\n  default = \"t2.micro\"\n}\n\noutput \"instance_ip\" {\n  value = aws_instance.web.public_ip\n}\n</code></pre>"},{"location":"phase-3/00_terraform/#best-practices","title":"Best Practices","text":"<p>Separate concerns:</p> <ul> <li><code>main.tf</code> \u2192 infra definition</li> <li><code>variables.tf</code> \u2192 input parameters</li> <li><code>outputs.tf</code> \u2192 useful outputs</li> <li>Store configs in Git.</li> <li>Use <code>terraform fmt</code> to format code.</li> </ul>"},{"location":"phase-3/00_terraform/#terraform-state-management","title":"Terraform State Management","text":""},{"location":"phase-3/00_terraform/#state-file","title":"State File","text":"<ul> <li>Stored as <code>terraform.tfstate</code>.</li> <li>Contains current infra state (resources, IDs, configs).</li> <li>Needed for Terraform to know what already exists.</li> </ul>"},{"location":"phase-3/00_terraform/#problems-with-local-state","title":"Problems with Local State","text":"<ul> <li>Single-user access.</li> <li>File corruption risk.</li> <li>Not suitable for teams.</li> </ul>"},{"location":"phase-3/00_terraform/#remote-state","title":"Remote State","text":"<ul> <li>Store in S3, Azure Blob, GCS, Terraform Cloud.</li> <li> <p>Enables:</p> <ul> <li>Collaboration (multiple users)</li> <li>State locking (prevents concurrent writes)</li> </ul> </li> </ul>"},{"location":"phase-3/00_terraform/#example-aws-s3-remote-state","title":"Example: AWS S3 Remote State","text":"<pre><code>terraform {\n  backend \"s3\" {\n    bucket = \"techops-terraform-state\"\n    key    = \"prod/terraform.tfstate\"\n    region = \"ap-south-1\"\n  }\n}\n</code></pre>"},{"location":"phase-3/00_terraform/#important-state-commands","title":"Important State Commands","text":"<ul> <li><code>terraform state list</code> \u2192 list resources tracked</li> <li><code>terraform refresh</code> \u2192 sync state with real infra</li> <li><code>terraform state rm &lt;resource&gt;</code> \u2192 remove resource from state</li> </ul>"},{"location":"phase-3/00_terraform/#terraform-modules-and-reusability","title":"Terraform Modules and Reusability","text":""},{"location":"phase-3/00_terraform/#why-use-modules","title":"Why Use Modules?","text":"<ul> <li>Avoid duplicating code.</li> <li>Improve maintainability.</li> <li>Share infra templates across projects.</li> </ul>"},{"location":"phase-3/00_terraform/#local-module-example","title":"Local Module Example","text":"<pre><code>/modules\n  \u2514\u2500\u2500 ec2-instance\n      \u251c\u2500\u2500 main.tf\n      \u251c\u2500\u2500 variables.tf\n      \u2514\u2500\u2500 outputs.tf\n/project\n  \u2514\u2500\u2500 main.tf\n</code></pre> <p>Calling the module:</p> <pre><code>module \"webserver\" {\n  source        = \"./modules/ec2-instance\"\n  instance_type = \"t2.micro\"\n}\n</code></pre>"},{"location":"phase-3/00_terraform/#public-registry-modules","title":"Public Registry Modules","text":"<ul> <li>HashiCorp maintains a registry: registry.terraform.io.</li> <li>Example: VPC, RDS, Kubernetes cluster modules.</li> </ul>"},{"location":"phase-3/00_terraform/#best-practices_1","title":"Best Practices","text":"<ul> <li>Parameterize with <code>variables.tf</code>.</li> <li>Output critical info (IP, DNS, credentials).</li> <li>Store reusable modules in a Git repo.</li> </ul>"},{"location":"phase-3/00_terraform/#terraform-workflow-recap","title":"Terraform Workflow Recap","text":"<ol> <li>Write config files (<code>.tf</code>).</li> <li>Initialize project \u2192 <code>terraform init</code>.</li> <li>Plan infra \u2192 <code>terraform plan</code>.</li> <li>Apply infra \u2192 <code>terraform apply</code>.</li> <li>Check state \u2192 <code>terraform show</code>.</li> <li>Destroy when no longer needed \u2192 <code>terraform destroy</code>.</li> </ol>"},{"location":"phase-3/00_terraform/#real-world-applications","title":"Real-World Applications","text":"<ul> <li>Automating AWS multi-tier VPC setups.</li> <li>Deploying Kubernetes clusters (EKS, GKE, AKS).</li> <li>Provisioning CI/CD runners.</li> <li>Managing DNS records, SSL certs.</li> <li>Hybrid infra (on-prem VMware + cloud AWS).</li> </ul>"},{"location":"phase-3/01_devops/","title":"DevOps","text":"<p>--</p>"},{"location":"phase-3/01_devops/#what-is-devops","title":"What is DevOps?","text":""},{"location":"phase-3/02_devops_tools/","title":"DevOps Basic Tools","text":"<p>--</p>"},{"location":"phase-3/02_devops_tools/#devops-basic-tools_1","title":"DevOps Basic Tools","text":""},{"location":"phase-3/03_iac/","title":"Infrastructure as Code (IaC)","text":""},{"location":"phase-3/03_iac/#objectives","title":"\ud83e\udde0 Objectives","text":"<p>By the end of this session, students will:</p> <ul> <li>Understand what Infrastructure as Code (IaC) means.</li> <li>Differentiate between imperative and declarative approaches.</li> <li>Explore real-world benefits of IaC.</li> <li>Learn about popular IaC tools like Terraform, Ansible, Puppet, and Chef.</li> </ul>"},{"location":"phase-3/03_iac/#what-is-infrastructure-as-code","title":"\ud83d\udcd6 What is Infrastructure as Code?","text":"<p>Infrastructure as Code (IaC) is the practice of managing and provisioning infrastructure (servers, networks, storage, databases) using machine-readable configuration files instead of manual processes or GUIs.</p> <p>Think of IaC as \"treating infrastructure like software\":</p> <ul> <li>Code defines what your servers should look like.</li> <li>Version control stores the configuration.</li> <li>Automation tools build the infrastructure consistently.</li> </ul>"},{"location":"phase-3/03_iac/#two-approaches-in-iac","title":"\u2696\ufe0f Two Approaches in IaC","text":"<ol> <li> <p>Imperative (Procedural)</p> <ul> <li>Tells the system how to reach the desired state (step by step).</li> <li>Example: Shell scripts, Puppet in procedural mode.</li> </ul> </li> <li> <p>Declarative (Desired State)</p> <ul> <li>Tells the system what the final state should look like.</li> <li>Example: Terraform, Ansible.</li> </ul> </li> </ol> <p>Analogy</p> <p>Imperative = \u201cBake a cake step by step.\u201d</p> <p>Declarative = \u201cI want a chocolate cake.\u201d (The system figures out steps).</p>"},{"location":"phase-3/03_iac/#benefits-of-iac","title":"\ud83c\udfaf Benefits of IaC","text":"<ul> <li>Consistency \u2192 No configuration drift.</li> <li>Speed \u2192 Faster provisioning and scaling.</li> <li>Versioning \u2192 Track infra changes like source code.</li> <li>Collaboration \u2192 Teams can peer-review infra just like code.</li> <li>Scalability \u2192 Reuse configs across dev, test, prod.</li> </ul>"},{"location":"phase-3/03_iac/#popular-iac-tools","title":"\ud83d\udd27 Popular IaC Tools","text":"<ul> <li>Terraform (HashiCorp) \u2192 Declarative, cloud-agnostic.</li> <li>Ansible (Red Hat) \u2192 Simple YAML playbooks, agentless.</li> <li>Puppet \u2192 Used in enterprise, can be both declarative/imperative.</li> <li>Chef \u2192 Ruby DSL, more developer-centric.</li> </ul>"},{"location":"phase-3/03_iac/#iac-lifecycle","title":"\ud83d\udcca IaC Lifecycle","text":"<pre><code>flowchart LR\n    A[Write Configuration Code] --&gt; B[Plan Changes]\n    B --&gt; C[Apply Configuration]\n    C --&gt; D[Provision Infrastructure]\n    D --&gt; E[Manage &amp; Update]\n    E --&gt; F[Destroy when no longer needed]</code></pre>"},{"location":"phase-3/03_iac/#real-world-examples","title":"\ud83c\udf0d Real-World Examples","text":"<ul> <li>Terraform on AWS: Spin up EC2, VPCs, security groups with one command.</li> <li>Ansible Playbooks: Configure web servers with consistent packages.</li> <li>Hybrid Infra: Use Terraform to create infra and Ansible to configure apps.</li> </ul>"},{"location":"phase-3/04_container_orchestration/","title":"Container Orchestration (Kubernetes &amp; Docker Swarm)","text":""},{"location":"phase-3/04_container_orchestration/#objectives","title":"\ud83e\udde0 Objectives","text":"<p>By the end of this session, students will:</p> <ul> <li>Understand why container orchestration is necessary.</li> <li>Learn the fundamentals of Kubernetes and Docker Swarm.</li> <li>Compare Kubernetes and Swarm for enterprise vs. lightweight use cases.</li> </ul>"},{"location":"phase-3/04_container_orchestration/#why-orchestration","title":"\ud83d\udcd6 Why Orchestration?","text":"<p>Running one or two Docker containers manually is fine. But in production, apps might need hundreds of containers across multiple servers.</p> <p>Problems without orchestration:</p> <ul> <li>How to start/stop containers on many nodes?</li> <li>How to handle failures?</li> <li>How to scale up and down?</li> <li>How to load balance?</li> </ul> <p>Container orchestration solves all these challenges.</p> <p></p>"},{"location":"phase-3/04_container_orchestration/#kubernetes-k8s","title":"\ud83d\ude80 Kubernetes (K8s)","text":"<ul> <li>Created by Google, managed by CNCF.</li> <li> <p>Production-grade orchestration platform.</p> </li> <li> <p>Key Concepts:</p> <ul> <li>Pod: Smallest unit, group of containers.</li> <li>Deployment: Defines how pods run (replicas, updates).</li> <li>Service: Exposes pods inside/outside cluster.</li> <li>Ingress: Manages external access (like a reverse proxy).</li> <li>ConfigMap/Secret: Store app configs and credentials.</li> </ul> </li> </ul> <p>Features:</p> <ul> <li>Self-healing \u2192 Restart failed containers automatically.</li> <li>Auto-scaling \u2192 Scale pods up/down based on load.</li> <li>Rolling updates \u2192 Zero downtime deployments.</li> </ul>"},{"location":"phase-3/04_container_orchestration/#docker-swarm","title":"\ud83d\udc33 Docker Swarm","text":"<p>Docker\u2019s native clustering and orchestration tool</p> <p>Docker Swarm is built directly into Docker, meaning if you already know Docker, you can quickly extend it to run containers across multiple machines. Instead of managing single hosts manually, Swarm groups them together into a cluster (called a swarm) that behaves like one big virtual Docker engine.</p> <p>Easier to set up than Kubernetes</p> <p>Kubernetes requires multiple components (API server, controller manager, etcd, kubelet) to work together, which makes setup complex. In contrast, Docker Swarm can be initialized with a single command:</p> <pre><code>docker swarm init\n</code></pre> <p>Adding worker nodes is just another simple command with a token. This makes Swarm much more approachable for beginners or small teams.</p> <p>Good for small to medium projects</p> <p>Swarm works best when you need orchestration but don\u2019t want the overhead of Kubernetes. For example, a startup with a few microservices (say 10\u201320 containers) can use Swarm to manage scaling, load balancing, and service discovery without needing a large DevOps team. It\u2019s lightweight, integrated with Docker CLI, and fits well into smaller environments.</p> <p>Lacks the depth of Kubernetes (fewer features)</p> <p>While Swarm is great for simplicity, it doesn\u2019t offer the advanced ecosystem of Kubernetes. Features like:</p> <ul> <li>Auto-scaling based on metrics</li> <li>Advanced traffic routing (Ingress controllers, service meshes)</li> <li>Rich ecosystem of monitoring/logging integrations</li> <li>Declarative configuration through YAML manifests are not as mature in Swarm. For enterprise-level applications with thousands of containers, Kubernetes is the industry standard.</li> </ul> <p></p>"},{"location":"phase-3/04_container_orchestration/#kubernetes-vs-docker-swarm","title":"\u2696\ufe0f Kubernetes vs. Docker Swarm","text":"Feature Kubernetes Docker Swarm Setup Complexity High Low Scalability Very High Moderate Ecosystem/Community Huge Small Enterprise Adoption Standard Niche"},{"location":"phase-3/04_container_orchestration/#orchestration-flow-mermaid-diagram","title":"\ud83d\udcca Orchestration Flow (Mermaid Diagram)","text":"<pre><code>flowchart TD\n    A[Developer Pushes Image] --&gt; B[Registry - Docker Hub/ECR]\n    B --&gt; C[Cluster Orchestrator]\n    C --&gt; D[Nodes with Containers]\n    C --&gt; E[Scaling Pods/Services]\n    C --&gt; F[Load Balancer for Users]</code></pre>"},{"location":"phase-3/04_container_orchestration/#real-world-example","title":"\ud83c\udf0d Real-World Example","text":"<ul> <li> <p>E-commerce site using Kubernetes:</p> </li> <li> <p>Cart service in 5 pods.</p> </li> <li>Payment service in 3 pods.</li> <li>Search service in 10 pods.</li> <li>All automatically scaled and balanced by K8s.</li> </ul>"},{"location":"phase-3/05_micro_services_deployment/","title":"Microservice Deployment","text":""},{"location":"phase-3/05_micro_services_deployment/#objectives","title":"\ud83e\udde0 Objectives","text":"<p>By the end of this session, students will:</p> <ul> <li>Understand monolithic vs. microservices architecture.</li> <li>Learn how containers enable microservices.</li> <li>Explore deployment strategies like rolling updates, blue-green, canary.</li> </ul>"},{"location":"phase-3/05_micro_services_deployment/#monolith-vs-microservices","title":"\ud83d\udcd6 Monolith vs. Microservices","text":"<ul> <li>Monolithic app = One big application, tightly coupled.</li> <li>Microservices = Multiple smaller services, loosely coupled, each responsible for one function.</li> </ul> <p>Example:</p> <ul> <li>Monolith = single e-commerce app.</li> <li>Microservices = independent services (cart, payments, search, user auth).</li> </ul>"},{"location":"phase-3/05_micro_services_deployment/#why-containers-for-microservices","title":"\ud83d\udc33 Why Containers for Microservices?","text":"<ul> <li>Encapsulate dependencies.</li> <li>Ensure consistency across environments.</li> <li>Easy scaling (scale only the service you need).</li> </ul>"},{"location":"phase-3/05_micro_services_deployment/#deployment-strategies","title":"\ud83d\ude80 Deployment Strategies","text":"<ul> <li>Rolling Update: Replace old pods with new gradually.</li> <li>Blue-Green Deployment: Run two environments (blue = current, green = new). Switch traffic once tested.</li> <li>Canary Release: Release to a small % of users first, then expand.</li> </ul>"},{"location":"phase-3/05_micro_services_deployment/#challenges-in-microservices","title":"\u26a0\ufe0f Challenges in Microservices","text":"<ul> <li>Service discovery: How do services find each other?</li> <li>Networking: Secure and efficient communication.</li> <li>Monitoring &amp; Logging: Observability across multiple services.</li> <li>Data consistency: Distributed databases.</li> </ul>"},{"location":"phase-3/05_micro_services_deployment/#tools-for-microservices","title":"\ud83d\udd27 Tools for Microservices","text":"<ul> <li>Kubernetes \u2192 Orchestration platform.</li> <li>Istio/Linkerd (Service Meshes) \u2192 Advanced routing, observability, security.</li> <li>Prometheus + Grafana \u2192 Monitoring.</li> <li>Elastic Stack (ELK) \u2192 Logging and search.</li> </ul>"},{"location":"phase-3/05_micro_services_deployment/#microservices-deployment-flow","title":"\ud83d\udcca Microservices Deployment Flow","text":"<pre><code>flowchart LR\n    A[Developer builds microservice] --&gt; B[Container Image Built]\n    B --&gt; C[Push to Docker Hub]\n    C --&gt; D[Kubernetes Cluster]\n    D --&gt; E[Pods Running Microservice]\n    E --&gt; F[Service Mesh/Ingress]\n    F --&gt; G[End User Access]</code></pre>"},{"location":"phase-3/05_micro_services_deployment/#real-world-example","title":"\ud83c\udf0d Real-World Example","text":"<ul> <li> <p>Netflix:</p> <ul> <li>Runs thousands of microservices for streaming, recommendations, payments.</li> <li>Uses Kubernetes + custom orchestration.</li> </ul> </li> <li> <p>Amazon:</p> <ul> <li>Each service (cart, payments, suggestions) runs as microservices.</li> <li>Independent teams manage each service.</li> </ul> </li> </ul>"},{"location":"phase-3/06_ansible/","title":"Ansible","text":""},{"location":"phase-3/06_ansible/#ansible-and-configuration-management","title":"Ansible and Configuration Management","text":""},{"location":"phase-3/06_ansible/#1-what-is-ansible","title":"1. What is Ansible?","text":"<p>Ansible is an open-source IT automation and configuration management tool.</p> <ul> <li>It helps system administrators, DevOps engineers, and cloud teams automate repetitive tasks like installing software, configuring servers, deploying applications, and managing security patches.</li> <li>Instead of logging into 50 servers one by one, you write a simple script (called a Playbook) in YAML, and Ansible executes it on all servers at once using SSH (Linux) or WinRM (Windows).</li> </ul> <p>\ud83d\udccc Think of Ansible as a remote control for your entire infrastructure.</p>"},{"location":"phase-3/06_ansible/#2-where-is-ansible-used","title":"2. Where is Ansible Used?","text":"<p>Organizations use Ansible in many domains:</p> <ul> <li>Server Provisioning: Setting up new Linux/Windows servers in AWS, Azure, or on-premise data centers.</li> <li>Configuration Management: Ensuring all servers have the same OS settings, firewall rules, users, and security patches.</li> <li>Application Deployment: Automating deployment of apps (e.g., deploying a web app to Kubernetes clusters).</li> <li>Cloud Orchestration: Managing AWS EC2, Azure VMs, GCP instances, Kubernetes pods.</li> <li>Security Automation: Enforcing compliance policies, applying OS hardening, rolling out security updates.</li> <li>CI/CD Pipelines: Integrating with Jenkins/GitHub Actions to deploy apps automatically after every code change.</li> </ul>"},{"location":"phase-3/06_ansible/#3-who-does-ansible-compete-with","title":"3. Who Does Ansible Compete With?","text":"<p>Ansible operates in the Configuration Management &amp; Automation space, competing with:</p> <ul> <li>Puppet \u2013 Agent-based, declarative, uses its own DSL (harder to learn).</li> <li>Chef \u2013 Agent-based, Ruby DSL, popular in early DevOps adoption.</li> <li>SaltStack \u2013 Uses an agent (Salt Minion), scales well, strong event-driven automation.</li> <li>Terraform \u2013 Infrastructure as Code (IaC) tool, focuses more on provisioning infra rather than config mgmt.</li> </ul> <p>\ud83d\udc49 Ansible\u2019s edge: Unlike Puppet and Chef, no agent is required. It\u2019s agentless, uses existing SSH/WinRM, and YAML (easy to read/write).</p>"},{"location":"phase-3/06_ansible/#4-benefits-of-ansible","title":"4. Benefits of Ansible","text":"<p>Why do so many companies love Ansible?</p> <ul> <li>Agentless: No extra software required on managed nodes. Only Python/SSH is needed.</li> <li>Human-readable YAML: Easy to learn for beginners and non-programmers.</li> <li>Idempotency: If a task is already applied (e.g., \u201cApache installed\u201d), Ansible won\u2019t repeat it unnecessarily.</li> <li>Cross-platform: Works on Linux, Windows, cloud, and network devices (Cisco, Juniper).</li> <li>Scalable: Can manage 10 or 10,000 nodes with the same simplicity.</li> <li>Community + Enterprise Support: Huge open-source community, plus enterprise-grade Red Hat support.</li> <li>Integration: Works with CI/CD, cloud APIs, security tools, Kubernetes.</li> </ul> <p>\ud83d\udccc In short: Simple, scalable, and safe automation.</p>"},{"location":"phase-3/06_ansible/#5-how-organizations-use-the-paid-ansible-automation-platform","title":"5. How Organizations Use the Paid \u201cAnsible Automation Platform\u201d","text":"<p>Red Hat offers a commercial version called Ansible Automation Platform (AAP). Enterprises adopt it for:</p> <ul> <li>Centralized Control: AAP includes Ansible Tower (now Automation Controller) \u2192 Web UI, RBAC (role-based access), logging, scheduling.</li> <li>Collaboration: Teams can run playbooks securely without needing direct SSH access.</li> <li>Governance: Tracks who ran which playbook, when, and on which servers (audit trails).</li> <li>Automation Hub: Private library of approved roles/playbooks for reuse.</li> <li>Scalability: Handles thousands of nodes with job distribution and high availability.</li> <li>Compliance &amp; Security: Integrates with LDAP, SSO, enterprise-grade monitoring.</li> </ul> <p>\ud83d\udca1 Example: A bank uses AAP to ensure all servers always comply with PCI-DSS security standards. Instead of manual audits, they run Ansible playbooks daily to check and fix compliance.</p>"},{"location":"phase-3/06_ansible/#6-why-ansible-is-easier-than-competitors","title":"6. Why Ansible is Easier than Competitors","text":"<ul> <li>No new language: Puppet (DSL), Chef (Ruby), SaltStack (Jinja + YAML). Ansible \u2192 plain YAML.</li> <li>Agentless: No background services or daemons to maintain on target systems.</li> <li>Quick adoption: New engineers can learn YAML playbooks in a day or two.</li> <li>Push-based model: Immediate execution from control node (unlike Puppet/Chef which rely on agents pulling configs).</li> <li>Consistency across hybrid environments: Same playbook works for AWS, Azure, on-prem, or containers.</li> </ul> <p>\ud83d\udccc That\u2019s why many organizations migrating from Puppet/Chef have chosen Ansible as a simpler, modern alternative.</p>"},{"location":"phase-3/06_ansible/#7-core-components-of-ansible","title":"7. Core Components of Ansible","text":"<p>To understand Ansible deeply, you need to know its building blocks:</p>"},{"location":"phase-3/06_ansible/#a-inventory","title":"(a) Inventory","text":"<ul> <li>A file that defines which machines Ansible manages.</li> <li>Example:</li> </ul> <p><pre><code>[webservers]\n192.168.1.10\n192.168.1.11\n</code></pre> * Can be static (INI/YAML file) or dynamic (cloud inventory scripts that auto-fetch AWS EC2 instances).</p>"},{"location":"phase-3/06_ansible/#b-modules","title":"(b) Modules","text":"<ul> <li>Small programs that Ansible runs on managed nodes to perform tasks (install package, start service, copy file).</li> <li>Example: <code>apt</code>, <code>yum</code>, <code>service</code>, <code>user</code>, <code>ec2_instance</code>.</li> <li>Thousands of built-in modules for Linux, Windows, cloud, and network devices.</li> </ul>"},{"location":"phase-3/06_ansible/#c-tasks","title":"(c) Tasks","text":"<ul> <li>A single action that Ansible performs (e.g., install Apache).</li> <li>Example:</li> </ul> <pre><code>- name: Install Apache\n  apt:\n    name: apache2\n    state: present\n</code></pre>"},{"location":"phase-3/06_ansible/#d-plays","title":"(d) Plays","text":"<ul> <li>A mapping between hosts and tasks.</li> <li>Example: Run Apache installation tasks only on <code>webservers</code>.</li> </ul>"},{"location":"phase-3/06_ansible/#e-playbooks","title":"(e) Playbooks","text":"<ul> <li>YAML files that contain one or more Plays.</li> <li>They describe what should be done, on which servers, in what order.</li> <li>Example: Install Apache + start service across all web servers.</li> </ul>"},{"location":"phase-3/06_ansible/#f-handlers","title":"(f) Handlers","text":"<ul> <li>Special tasks that run only when triggered. Useful for restarting services after a config change.</li> <li>Example:</li> </ul> <pre><code>handlers:\n  - name: restart apache\n    service:\n      name: apache2\n      state: restarted\n</code></pre>"},{"location":"phase-3/06_ansible/#g-variables","title":"(g) Variables","text":"<ul> <li>Used to customize playbooks for different environments.</li> <li>Example:</li> </ul> <pre><code>vars:\n  http_port: 80\n</code></pre>"},{"location":"phase-3/06_ansible/#h-templates","title":"(h) Templates","text":"<ul> <li>Jinja2-based configuration files with variables.</li> <li>Example: Apache config template with <code>{{ http_port }}</code>.</li> </ul>"},{"location":"phase-3/06_ansible/#i-roles","title":"(i) Roles","text":"<ul> <li>A structured way to organize playbooks for reusability.</li> <li>Example: A \u201cwebserver\u201d role contains tasks, handlers, templates, and vars all bundled together.</li> <li>Encourages modular design \u2192 teams can share and reuse roles.</li> </ul>"},{"location":"phase-3/06_ansible/#j-plugins","title":"(j) Plugins","text":"<ul> <li>Extend Ansible with extra features (connection plugins, lookup plugins, filter plugins).</li> </ul> <p>\u2705 Together, these components make Ansible powerful yet simple:</p> <ul> <li>Inventory \u2192 Where to run</li> <li>Modules \u2192 What to run</li> <li>Playbooks/Plays \u2192 How to run it</li> <li>Roles \u2192 How to reuse it</li> </ul>"},{"location":"phase-3/06_ansible/#understanding-architecture","title":"Understanding Architecture","text":""},{"location":"phase-3/06_ansible/#high-level-control-node-inventory-managed-nodes","title":"High Level - (Control node \u2192 Inventory \u2192 Managed nodes)","text":"<pre><code>flowchart LR\n  A[Control Node - Ansible] --&gt; B[Inventory]\n  B --&gt; C1[webservers group]\n  B --&gt; C2[dbservers group]\n  C1 --&gt; D1[web-01 - SSH/WinRM]\n  C1 --&gt; D2[web-02 - SSH/WinRM]\n  C2 --&gt; E1[db-01 - SSH/WinRM]\n  A --&gt; F[Playbooks - YAML]\n  F --&gt; G[Modules - apt, yum, service, template, ec2, etc.]\n  G --&gt; D1\n  G --&gt; D2\n  G --&gt; E1\n  A -.-&gt; H[Ansible Automation Platform - UI, RBAC, Logging] \n  H -.-&gt; A\n</code></pre>"},{"location":"phase-3/06_ansible/#explanation","title":"Explanation:","text":"<p>Control Node runs Ansible and playbooks. Inventory describes hosts and groups. Playbooks use modules to perform actions on the managed nodes over SSH/WinRM. In enterprise, Ansible Automation Platform sits on top to provide UI, RBAC, scheduling, and audit trails.</p>"},{"location":"phase-3/06_ansible/#playbook-execution-flow","title":"Playbook execution flow","text":"<pre><code>flowchart TD\n  P[Playbook.yml] --&gt; PL[Play 1: hosts: webservers]\n  PL --&gt; T1[Task 1: Install package - module: apt/yum]\n  PL --&gt; T2[Task 2: Deploy template - module: template]\n  PL --&gt; T3[Task 3: Start service - module: service]\n  T2 --&gt; H{Template changed?}\n  H --&gt;|yes| R[Notify handler: restart web service]\n  H --&gt;|no| S[Do nothing]\n  R --&gt; HND[Handler: restart web service]\n  T1 &amp; T2 &amp; T3 --&gt; RESULT[Return status per-host - changed/ok/failed]\n  RESULT --&gt; LOGS[Logs / stdout / Automation Controller]\n</code></pre>"},{"location":"phase-3/06_ansible/#explanation_1","title":"Explanation:","text":"<p>A playbook contains one or more plays. Each play targets a host/group and defines tasks. Tasks call modules. If a task that modifies configuration triggers a handler, the handler runs at the end of the play. Each host returns results (ok/changed/failed) which go to logs or the Automation Controller.</p>"},{"location":"phase-3/06_ansible/#8-setting-up-ansible-environment","title":"8. Setting Up Ansible Environment","text":"<p>Objectives:</p> <ul> <li>Install Ansible on Linux/Mac/Windows WSL.</li> <li>Verify installation and configure first control node.</li> </ul> <p>Key Concepts:</p> <ul> <li>Control Node: Machine where Ansible is installed.</li> <li>Managed Nodes: Target systems (Linux/Windows).</li> <li>Requirements: Python 3, SSH access, sudo privileges.</li> </ul> <p>Setup Overview:</p> On Linux (Ubuntu)On CentOS/RHELOn macOS (Homebrew)On Windows <pre><code>sudo apt update\nsudo apt install ansible -y\nansible --version\n</code></pre> <pre><code>sudo yum install epel-release -y\nsudo yum install ansible -y\n</code></pre> <pre><code>brew install ansible\n</code></pre> <p>Use WSL2 or Ansible via Docker.</p>"},{"location":"phase-3/06_ansible/#9-ansible-playbooks-and-yaml-basics","title":"9. Ansible Playbooks and YAML Basics","text":"<p>Objectives:</p> <ul> <li>Learn YAML syntax used in Ansible.</li> <li>Write your first playbook.</li> </ul> <p>Key Concepts:</p> <ul> <li>Playbooks: Declarative scripts written in YAML describing desired system states.</li> <li> <p>YAML Rules:</p> </li> <li> <p>Indentation with spaces (no tabs).</p> </li> <li>Key-value pairs.</li> <li>Lists start with <code>-</code>.</li> </ul> <p>Example Playbook:</p> <pre><code>---\n- name: Install Apache on webservers\n  hosts: webservers\n  become: yes\n  tasks:\n    - name: Install Apache package\n      apt:\n        name: apache2\n        state: present\n</code></pre>"},{"location":"phase-3/06_ansible/#10-managing-ansible-inventory","title":"10. Managing Ansible Inventory","text":"<p>Objectives:</p> <ul> <li>Understand inventory formats and groups.</li> <li>Configure static and dynamic inventories.</li> </ul> <p>Key Concepts:</p> <ul> <li>Inventory: File listing managed nodes.</li> <li>Static Inventory (INI format):</li> </ul> <p><pre><code>[webservers]\nserver1 ansible_host=192.168.1.10 ansible_user=ubuntu\nserver2 ansible_host=192.168.1.11 ansible_user=ubuntu\n</code></pre> * Dynamic Inventory: Pulls hosts from cloud providers (AWS EC2, Azure). * Ansible Config File (<code>ansible.cfg</code>): Defines inventory path, defaults, SSH settings.</p>"},{"location":"phase-3/06_ansible/#11-ansible-roles-and-reusability","title":"11. Ansible Roles and Reusability","text":"<p>Objectives:</p> <ul> <li>Learn role-based structure for scalable automation.</li> <li>Explore Galaxy for reusable roles.</li> </ul> <p>Key Concepts:</p> <ul> <li>Role: Predefined structure for tasks, variables, templates, files. Promotes modularity.</li> <li>Role Directory Layout:</li> </ul> <p><pre><code>roles/\n  webserver/\n    tasks/main.yml\n    handlers/main.yml\n    templates/\n    vars/main.yml\n</code></pre> * Ansible Galaxy: Public repository of community roles.</p> <p><pre><code>ansible-galaxy install geerlingguy.apache\n</code></pre> * Best Practices:</p> <ul> <li>Use roles for repeatable patterns (e.g., LAMP stack).</li> <li>Version-control roles in GitHub.</li> <li>Tag tasks for selective execution.</li> </ul>"},{"location":"phase-3/lab16/","title":"Lab 16: Basic Git &amp; GitHub","text":"<p>Lab Info</p> <p>Estimated time: 90\u2013120 minutes Audience: Absolute beginners (assumes no prior git/GitHub experience) Tools used: Git (Git Bash on Windows or native Linux shell), GitHub account, a text editor (Notepad / VS Code / nano), web browser.</p> <p>Learning goals</p> <ul> <li>Install Git on Windows and Linux.</li> <li>Create a GitHub account and repository.</li> <li>Generate SSH keys on local machines and add them to GitHub.</li> <li>Initialize a local git repository with a <code>README.md</code>.</li> <li>Push the repository to GitHub over SSH.</li> <li>Create a branch, edit files, push branch, open a Pull Request (PR), merge it, and delete the remote branch.</li> <li>Make and commit changes directly on GitHub and then pull those into the local copy.</li> <li>Practice the full round-trip workflow engineers use every day.</li> </ul>"},{"location":"phase-3/lab16/#1-install-git-windows-or-linux","title":"1. Install Git (Windows OR Linux)","text":"WindowsLinux (Debian/Ubuntu)Linux (Redhat/CentOS) <ol> <li>Open your browser and go to https://git-scm.com/download/win and download the installer (Git for Windows).</li> <li> <p>Run the installer and accept defaults. Important options:</p> <ul> <li>Use the bundled Git Bash as your default terminal for Git.</li> <li>Choose the option to use the OpenSSH provided by Git (default).</li> </ul> </li> <li> <p>After install, open Git Bash from the Start menu.</p> </li> <li>Verify installation:</li> </ol> <pre><code>git --version\n</code></pre> <p>You should see output like <code>git version 2.x.x</code>.</p> <p>Explanation: You installed Git, which provides the command-line tools to track file changes and communicate with remote repositories. Git Bash gives you a Unix-like shell on Windows which works well with SSH.</p> <pre><code>sudo apt update\nsudo apt install -y git\ngit --version\n</code></pre> <p>Explanation: On Linux you install the system Git package. The <code>git --version</code> confirms it\u2019s available.</p> <pre><code>sudo dnf install -y git        # or `yum install -y git`\ngit --version\n</code></pre> <p>Explanation: On Linux you install the system Git package. The <code>git --version</code> confirms it\u2019s available.</p>"},{"location":"phase-3/lab16/#2-create-a-github-account","title":"2. Create a GitHub account","text":"<ol> <li>Open your web browser and go to https://github.com.</li> <li>Click Sign up (or Create account) and follow the guided steps: choose username, email, password, and verify.</li> <li>(Optional) Choose the free plan.</li> </ol> <p>Explanation: GitHub is a popular Git hosting service that stores your repositories online and provides collaboration features (PRs, issues, web editor). You need an account to push code and create pull requests.</p>"},{"location":"phase-3/lab16/#3-create-and-upload-ssh-keys-to-github-windows-linux","title":"3. Create and upload SSH keys to GitHub (Windows &amp; Linux)","text":"<p>Why SSH? SSH keys let you connect to GitHub securely without typing your password every time.</p>"},{"location":"phase-3/lab16/#31-generate-ssh-key-both-windows-git-bash-linux","title":"3.1 Generate SSH key (both Windows Git Bash &amp; Linux)","text":"<p>Open Git Bash (Windows) or your Linux shell and run:</p> <pre><code># generate an RSA key (ED25519 is also good - alternative below)\nssh-keygen -t ed25519 -C \"your_email@example.com\"\n</code></pre> <p>If your system doesn't support <code>ed25519</code>, use:</p> <pre><code>ssh-keygen -t rsa -b 4096 -C \"your_email@example.com\"\n</code></pre> <p>When prompted:</p> <ul> <li>Press Enter to accept default file location (<code>~/.ssh/id_ed25519</code>).</li> <li>Enter a passphrase (recommended) or press Enter for none.</li> </ul> <p>Explanation: <code>ssh-keygen</code> creates a private key (keep secret) and a public key (you will upload). The <code>-C</code> tag is a label (usually your email).</p>"},{"location":"phase-3/lab16/#32-start-the-ssh-agent-and-add-the-key","title":"3.2 Start the SSH agent and add the key","text":"<p>In Git Bash (Windows):</p> <pre><code>eval \"$(ssh-agent -s)\"\nssh-add ~/.ssh/id_ed25519\n</code></pre> <p>In Linux (if needed):</p> <pre><code>eval \"$(ssh-agent -s)\"\nssh-add ~/.ssh/id_ed25519\n</code></pre> <p>Explanation: The SSH agent holds your decrypted private keys while your session runs; <code>ssh-add</code> registers your key so Git can use it.</p>"},{"location":"phase-3/lab16/#33-copy-the-public-key-and-add-to-github","title":"3.3 Copy the public key and add to GitHub","text":"<ol> <li>Print the public key:</li> </ol> <pre><code>cat ~/.ssh/id_ed25519.pub\n</code></pre> <ol> <li> <p>Select and copy the whole key (starts with <code>ssh-ed25519</code> or <code>ssh-rsa</code> and ends with your email).</p> </li> <li> <p>On GitHub:</p> <ul> <li>Click your profile photo \u2192 Settings \u2192 SSH and GPG keys \u2192 New SSH key.</li> <li>Title: <code>Laptop - Windows</code> or <code>Desktop - Linux</code> (helpful label).</li> <li>Paste the public key into the field and Add SSH key. Confirm your GitHub password if prompted.</li> </ul> </li> </ol> <p>Verify connection:</p> <ol> <li>Back to your terminal/Git Bash on your local machine</li> </ol> <pre><code>ssh -T git@github.com\n</code></pre> <p>Expected friendly message (first time may ask to confirm fingerprint):</p> <ul> <li>If success: <code>Hi username! You've successfully authenticated...</code> or a similar greeting.</li> </ul> <p>Explanation: You uploaded the public key to GitHub so GitHub can verify your machine when you push over SSH. <code>ssh -T git@github.com</code> tests the connection.</p>"},{"location":"phase-3/lab16/#4-create-a-repo-locally-readmemd-and-initialize-git","title":"4. Create a repo locally (README.md) and initialize git","text":"<p>We'll create a simple project folder with a <code>README.md</code> and commit it.</p>"},{"location":"phase-3/lab16/#41-create-directory-and-initialize","title":"4.1 Create directory and initialize","text":"<p>In your terminal:</p> <pre><code># choose a place, e.g., your home directory or projects folder\nmkdir -p ~/git-labs/readme-demo\ncd ~/git-labs/readme-demo\n\n# initialize a new git repository\ngit init -b main\n</code></pre> <p><code>-b main</code> creates the branch <code>main</code> (modern default).</p>"},{"location":"phase-3/lab16/#42-configure-git-identity-first-time-only","title":"4.2 Configure Git identity (first-time only)","text":"<pre><code>git config --global user.name \"Your Name\"\ngit config --global user.email \"your_email@example.com\"\n</code></pre>"},{"location":"phase-3/lab16/#43-create-readmemd-and-commit","title":"4.3 Create README.md and commit","text":"<p>Create <code>README.md</code> (use any editor; examples below use a one-line echo):</p> <pre><code>echo \"# README Demo\" &gt; README.md\necho \"This is my first README for the Git &amp; GitHub lab.\" &gt;&gt; README.md\n\ngit add README.md\ngit commit -m \"Initial commit: add README.md\"\n</code></pre> <p>Explanation: <code>git init</code> creates a <code>.git</code> folder that tracks history. <code>git add</code> stages changes, and <code>git commit</code> records them. <code>README.md</code> is a simple file we track.</p>"},{"location":"phase-3/lab16/#5-create-remote-repo-on-github-and-push-local-repo-ssh","title":"5. Create remote repo on GitHub and push local repo (SSH)","text":""},{"location":"phase-3/lab16/#51-create-a-remote-repository-on-github-web-ui","title":"5.1 Create a remote repository on GitHub (web UI)","text":"<ol> <li>On GitHub, click + \u2192 New repository.</li> <li>Name: <code>readme-demo</code> (or your chosen name). Keep it Public for the lab (or Private if required).</li> <li>Do not initialize with a README (we already have one locally). Click Create repository.</li> </ol> <p>You will see instructions; copy the SSH remote URL:</p> <pre><code>git@github.com:your-username/readme-demo.git\n</code></pre>"},{"location":"phase-3/lab16/#52-add-remote-and-push","title":"5.2 Add remote and push","text":"<p>Back in your terminal:</p> <pre><code>git remote add origin git@github.com:your-username/readme-demo.git\ngit branch --show-current       # should show main\ngit push -u origin main\n</code></pre> <p><code>-u</code> sets the upstream; future <code>git push</code>/<code>git pull</code> will default to <code>origin main</code>.</p> <p>Explanation: You linked your local repo to the GitHub remote <code>origin</code> and pushed commits. Now the repo appears on GitHub.</p>"},{"location":"phase-3/lab16/#6-branching-editing-pr-merge-and-deleting-remote-branch","title":"6. Branching, editing, PR, merge, and deleting remote branch","text":"<p>This shows how collaboration works: create a feature branch, push, open a Pull Request, merge it into <code>main</code>, then delete the branch.</p>"},{"location":"phase-3/lab16/#61-create-a-new-branch-locally","title":"6.1 Create a new branch locally","text":"<pre><code>git checkout -b feature/update-readme\n# make an edit to README.md\necho \"\" &gt;&gt; README.md\necho \"## Updates from feature branch\" &gt;&gt; README.md\n\ngit add README.md\ngit commit -m \"Update README: add feature section\"\n</code></pre> <p><code>git checkout -b</code> both creates and switches to the branch.</p> <p>Explanation: A branch lets you make changes without affecting <code>main</code> until you decide to merge. This is how teams develop features in isolation.</p>"},{"location":"phase-3/lab16/#62-push-branch-to-github","title":"6.2 Push branch to GitHub","text":"<pre><code>git push -u origin feature/update-readme\n</code></pre> <p>Explanation: Pushing publishes your branch so others (and the GitHub UI) can see the proposed changes.</p>"},{"location":"phase-3/lab16/#63-create-pull-request-pr-on-github-web","title":"6.3 Create Pull Request (PR) on GitHub (web)","text":"<ol> <li>Go to your repository on GitHub. You\u2019ll usually see a banner Compare &amp; pull request for your pushed branch \u2014 click it.    Or: Pull requests \u2192 New pull request, choose base <code>main</code> and compare <code>feature/update-readme</code>.</li> <li>Title the PR: <code>Update README \u2014 add feature section</code>.</li> <li>Add a short description and click Create pull request.</li> <li>Review the changes and click Merge pull request \u2192 Confirm merge.</li> <li>After merging, GitHub will offer to Delete branch \u2014 click Delete branch.</li> </ol> <p>Explanation: A Pull Request is a formal request to merge your branch into <code>main</code>. It lets reviewers see diffs, discuss, and then merge. Deleting the remote branch after merge keeps the repository tidy (history is preserved).</p>"},{"location":"phase-3/lab16/#64-or-delete-remote-branch-from-terminal-optional","title":"6.4 Or delete remote branch from terminal (Optional)","text":"<p>If you prefer command line deletion:</p> <pre><code># local branch deletion\ngit branch -d feature/update-readme\n\n# delete remote branch\ngit push origin --delete feature/update-readme\n</code></pre> <p>Explanation: <code>git branch -d</code> deletes the local copy (only if merged). <code>git push origin --delete</code> removes the branch on GitHub.</p>"},{"location":"phase-3/lab16/#7-make-changes-directly-on-github-edit-readme-on-the-website","title":"7. Make changes directly on GitHub (edit README on the website)","text":"<ol> <li>On GitHub repo page, open <code>README.md</code>.</li> <li>Click the pencil icon (Edit this file).</li> <li>Add a new line: <code>This change was made directly on GitHub.</code></li> <li> <p>Scroll down to Commit changes:</p> <ul> <li>Choose Commit directly to the <code>main</code> branch (for this lab).</li> <li>Add a commit message and click Commit changes.</li> </ul> </li> </ol> <p>Explanation: GitHub\u2019s web editor allows quick edits without cloning. Committing to <code>main</code> simulates, for example, small fixes or documentation updates done via the web UI.</p>"},{"location":"phase-3/lab16/#8-pull-the-latest-changes-locally-make-new-local-changes-and-push-again","title":"8. Pull the latest changes locally, make new local changes and push again","text":""},{"location":"phase-3/lab16/#81-pull-the-changes-from-github-to-local-main","title":"8.1 Pull the changes from GitHub to local main","text":"<p>Back in terminal:</p> <pre><code>git checkout main\ngit pull origin main\n</code></pre> <p>You should now see the change you made on GitHub in your local <code>README.md</code>.</p> <p>Explanation: <code>git pull</code> updates your local branch with the remote changes. Always pull before starting new local work to avoid conflicts.</p>"},{"location":"phase-3/lab16/#82-make-a-new-local-change-and-push","title":"8.2 Make a new local change and push","text":"<pre><code># make a local edit\necho \"\" &gt;&gt; README.md\necho \"Local edit: pulled GitHub changes and now adding more.\" &gt;&gt; README.md\n\ngit add README.md\ngit commit -m \"Local: extend README after pulling remote changes\"\ngit push origin main\n</code></pre> <p>Explanation: You added a local change after syncing. Pushing uploads your commit to GitHub. This completes the round-trip: local \u2192 remote \u2192 remote edit \u2192 local pull \u2192 local \u2192 remote.</p>"},{"location":"phase-3/lab16/#quick-command-summary-copypaste-cheat-sheet","title":"Quick Command Summary (copy/paste cheat-sheet)","text":"<pre><code># basic identity\ngit config --global user.name \"Your Name\"\ngit config --global user.email \"you@example.com\"\n\n# init repo\nmkdir repo &amp;&amp; cd repo\ngit init -b main\n\n# create files\necho \"# Title\" &gt; README.md\ngit add README.md\ngit commit -m \"Initial commit\"\n\n# add remote &amp; push\ngit remote add origin git@github.com:username/repo.git\ngit push -u origin main\n\n# branch workflow\ngit checkout -b feature/x\n# edit files...\ngit add .\ngit commit -m \"Work\"\ngit push -u origin feature/x\n# create PR on GitHub, merge there\ngit checkout main\ngit pull origin main\ngit branch -d feature/x\ngit push origin --delete feature/x\n\n# verify SSH\nssh -T git@github.com\n</code></pre>"},{"location":"phase-3/lab16/#troubleshooting-tips","title":"Troubleshooting &amp; tips","text":"<ul> <li> <p>Permission denied (publickey) when pushing:</p> <ul> <li>Ensure your SSH key was added to GitHub and <code>ssh-agent</code> has the private key loaded.</li> <li>Test with <code>ssh -T git@github.com</code>. If you see an error, re-check key upload and <code>ssh-add</code>.</li> </ul> </li> <li> <p>User identity not set: Git will prompt. Set <code>user.name</code> and <code>user.email</code> as shown.</p> </li> <li>Remote denied error when pushing: Confirm correct remote URL <code>git@github.com:username/repo.git</code>.</li> <li>Default branch is <code>master</code> on older setups: adapt commands or create <code>main</code> with <code>git branch -M main</code>.</li> <li>Conflicts when pulling: Git will tell you files conflict; open the files, resolve the conflict markers, then <code>git add</code> and <code>git commit</code>.</li> </ul>"},{"location":"phase-3/lab16/#what-you-just-learned-conceptual-explanation-visualize-the-workflow","title":"What you just learned \u2014 conceptual explanation (visualize the workflow)","text":"<ul> <li>Local repository: Your machine\u2019s project folder with a <code>.git</code> folder that tracks changes and history.</li> <li>Commit: A saved snapshot of changes (like a safe restore point).</li> <li>Branch: A parallel line of development; you can experiment without risking <code>main</code>.</li> <li>Remote (origin): The copy of the repository stored on GitHub \u2014 a central place for collaboration.</li> <li>Push: Upload your local commits to the remote.</li> <li>Pull: Fetch remote changes and merge them into your local branch.</li> <li>Pull Request (PR): A reviewable, auditable change request that lets teammates review/merge code.</li> <li>Merging: Combining changes from a branch into another (typically <code>main</code>).</li> <li>SSH Keys: Secure, passwordless authentication between your machine and GitHub.</li> </ul> <p>Visualize it as a set of islands:</p> <ul> <li>Your laptop is an island (local).</li> <li>GitHub is the central island (remote).</li> <li>Bridges (push/pull) carry your changes across.</li> <li>Branches are temporary islands you can create and remove as you work on features.</li> </ul>"},{"location":"phase-3/lab16/#extra-exercises-optional","title":"Extra exercises (optional)","text":"<ul> <li>Try creating an <code>issue</code> on GitHub and link it in the PR description.</li> <li>Use <code>git log --graph --oneline --all</code> to see the commit graph.</li> <li>Try cloning your repo to a second local folder and simulate two collaborators editing.</li> </ul>"},{"location":"phase-3/lab17/","title":"Lab: Docker Setup on RHEL/CentOS and Ubuntu/Debian","text":"<p>Lab Info</p> <p>Estimated Time: 60\u201390 minutes Audience: Beginners Tools used: RHEL 9 / CentOS Stream, Ubuntu 22.04 / Debian 11, Docker CE (Community Edition)</p> <p>Learning Objectives</p> <ul> <li>Install Docker on Linux systems.</li> <li>Understand how to start and enable Docker service.</li> <li>Run a test container to verify installation.</li> <li>Launch a simple Nginx container to see Docker in action.</li> <li>Visualize Docker workflow in DevOps.</li> </ul>"},{"location":"phase-3/lab17/#install-docker","title":"Install Docker","text":"RHEL / CentOSUbuntu / Debian"},{"location":"phase-3/lab17/#step-1-update-system","title":"Step 1: Update system","text":"<pre><code>sudo dnf update -y\n</code></pre> <p>Explanation: Updates your system packages for stability and compatibility.</p>"},{"location":"phase-3/lab17/#step-2-remove-old-versions-if-any","title":"Step 2: Remove old versions (if any)","text":"<pre><code>sudo dnf remove docker \\\n                docker-client \\\n                docker-client-latest \\\n                docker-common \\\n                docker-latest \\\n                docker-latest-logrotate \\\n                docker-logrotate \\\n                docker-engine\n</code></pre> <p>Explanation: Removes old Docker versions that may cause conflicts.</p>"},{"location":"phase-3/lab17/#step-3-enable-docker-ce-repository","title":"Step 3: Enable Docker CE repository","text":"<pre><code>sudo dnf config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\n</code></pre> <p>Explanation: Docker CE is not in RHEL/CentOS base repos. This command adds Docker\u2019s official repo.</p>"},{"location":"phase-3/lab17/#step-4-install-docker-ce","title":"Step 4: Install Docker CE","text":"<pre><code>sudo dnf install -y docker-ce docker-ce-cli containerd.io docker-compose-plugin\n</code></pre> <p>Explanation: Installs Docker Engine, CLI, container runtime, and Docker Compose plugin.</p>"},{"location":"phase-3/lab17/#step-5-start-and-enable-docker-service","title":"Step 5: Start and enable Docker service","text":"<pre><code>sudo systemctl start docker\nsudo systemctl enable docker\nsudo systemctl status docker\n</code></pre> <p>Explanation: Starts Docker now and ensures it starts on boot.</p>"},{"location":"phase-3/lab17/#step-6-verify-installation","title":"Step 6: Verify installation","text":"<pre><code>sudo docker run hello-world\n</code></pre> <p>Explanation: Runs a test image from Docker Hub. If successful, Docker is working.</p>"},{"location":"phase-3/lab17/#step-7-run-an-nginx-container","title":"Step 7: Run an Nginx container","text":"<pre><code>sudo docker run -d -p 8080:80 --name webserver nginx\n</code></pre> <ul> <li>Visit: <code>http://&lt;your-server-ip&gt;:8080</code></li> </ul> <p>Explanation: Launches an Nginx web server container. Port <code>8080</code> on your host maps to container\u2019s port <code>80</code>.</p>"},{"location":"phase-3/lab17/#step-1-update-system_1","title":"Step 1: Update system","text":"<pre><code>sudo apt update\nsudo apt upgrade -y\n</code></pre> <p>Explanation: Updates package lists and upgrades existing packages.</p>"},{"location":"phase-3/lab17/#step-2-remove-old-versions","title":"Step 2: Remove old versions","text":"<pre><code>sudo apt remove docker docker-engine docker.io containerd runc\n</code></pre> <p>Explanation: Ensures no legacy Docker is present.</p>"},{"location":"phase-3/lab17/#step-3-install-required-packages","title":"Step 3: Install required packages","text":"<pre><code>sudo apt install -y ca-certificates curl gnupg lsb-release\n</code></pre> <p>Explanation: These tools allow adding secure repositories and managing keys.</p>"},{"location":"phase-3/lab17/#step-4-add-dockers-official-gpg-key","title":"Step 4: Add Docker\u2019s official GPG key","text":"<pre><code>sudo mkdir -p /etc/apt/keyrings\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\n</code></pre> <p>Explanation: Adds Docker\u2019s signing key to verify package integrity.</p>"},{"location":"phase-3/lab17/#step-5-set-up-repository","title":"Step 5: Set up repository","text":"<pre><code>echo \\\n\"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] \\\nhttps://download.docker.com/linux/ubuntu \\\n$(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n</code></pre> <p>Explanation: Adds Docker\u2019s official repo to apt sources.</p>"},{"location":"phase-3/lab17/#step-6-install-docker-ce","title":"Step 6: Install Docker CE","text":"<pre><code>sudo apt update\nsudo apt install -y docker-ce docker-ce-cli containerd.io docker-compose-plugin\n</code></pre> <p>Explanation: Installs Docker engine, CLI, container runtime, and Compose plugin.</p>"},{"location":"phase-3/lab17/#step-7-start-and-enable-docker-service","title":"Step 7: Start and enable Docker service","text":"<pre><code>sudo systemctl start docker\nsudo systemctl enable docker\nsudo systemctl status docker\n</code></pre> <p>Explanation: Starts Docker now and on future boots.</p>"},{"location":"phase-3/lab17/#step-8-verify-installation","title":"Step 8: Verify installation","text":"<pre><code>sudo docker run hello-world\n</code></pre> <p>Explanation: Confirms Docker can pull images from Docker Hub and run containers.</p>"},{"location":"phase-3/lab17/#step-9-run-an-nginx-container","title":"Step 9: Run an Nginx container","text":"<pre><code>sudo docker run -d -p 8080:80 --name webserver nginx\n</code></pre> <ul> <li>Visit: <code>http://&lt;your-server-ip&gt;:8080</code></li> </ul> <p>Explanation: Runs a web server inside a container and exposes it.</p>"},{"location":"phase-3/lab17/#visualization-of-what-happened","title":"Visualization of what happened","text":"<ul> <li>Docker Engine: core service managing containers.</li> <li>Images: pre-packaged software (like templates).</li> <li>Containers: running instances of images.</li> <li>Docker Hub: central registry where images come from.</li> <li>hello-world: confirms Docker works.</li> <li>nginx: practical example of running an application container.</li> </ul>"},{"location":"phase-3/lab18/","title":"Lab 18: Setting Up Jenkins using Docker","text":"<p>Learning Objectives</p> <p>By the end of this lab, you will be able to:</p> <ul> <li>Set up a Jenkins server using Docker</li> <li>Access Jenkins from the browser</li> <li>Prepare Jenkins for CI/CD with plugins</li> </ul> <p>Prerequisites</p> <ul> <li>Docker must be installed (from Lab 17)</li> <li>Internet connection</li> </ul> <p>\u26a0\ufe0f Note: Use the same CentOS/RHEL VM from Lab 17 where Docker is already installed. No need to create a new VM.</p>"},{"location":"phase-3/lab18/#step-1-pull-jenkins-docker-image","title":"Step 1: Pull Jenkins Docker Image","text":"<pre><code>docker pull jenkins/jenkins:lts\n</code></pre> <p>\ud83d\udca1 <code>lts</code> means Long-Term Support, a stable Jenkins version recommended for production.</p>"},{"location":"phase-3/lab18/#step-2-create-a-docker-volume-for-jenkins-data","title":"Step 2: Create a Docker Volume for Jenkins Data","text":"<pre><code>docker volume create jenkins_home\n</code></pre> <p>\ud83d\udca1 This ensures Jenkins data (plugins, jobs, users) persists even if the container is removed.</p>"},{"location":"phase-3/lab18/#step-3-run-jenkins-container","title":"Step 3: Run Jenkins Container","text":"<pre><code>docker run -d \\\n  --name jenkins \\\n  -p 8080:8080 -p 50000:50000 \\\n  -v jenkins_home:/var/jenkins_home \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  jenkins/jenkins:lts\n</code></pre> <ul> <li><code>-p 8080:8080</code>: Maps Jenkins web UI to port 8080.</li> <li><code>-p 50000:50000</code>: Required for Jenkins agents (slaves).</li> <li><code>-v jenkins_home:/var/jenkins_home</code>: Persists Jenkins data.</li> <li><code>-v /var/run/docker.sock:/var/run/docker.sock</code>: Allows Jenkins to use Docker inside the container.</li> </ul>"},{"location":"phase-3/lab18/#step-4-access-jenkins-in-browser","title":"Step 4: Access Jenkins in Browser","text":"<p>Open your browser and go to:</p> <pre><code>http://localhost:8080\n</code></pre> <p>If accessing from a host machine, first find the VM IP:</p> <pre><code>ip addr\n</code></pre> <p>Look under your active network interface (<code>eth0</code>, <code>ens33</code>, etc.) for the IP address. Example: <code>http://192.168.1.100:8080</code></p>"},{"location":"phase-3/lab18/#step-5-unlock-jenkins","title":"Step 5: Unlock Jenkins","text":"<p>Retrieve the initial admin password:</p> <pre><code>docker exec -it jenkins cat /var/jenkins_home/secrets/initialAdminPassword\n</code></pre> <p>Copy this password and paste it into the Jenkins web prompt.</p>"},{"location":"phase-3/lab18/#step-6-install-suggested-plugins","title":"Step 6: Install Suggested Plugins","text":"<ul> <li>Choose Install suggested plugins</li> <li>Wait for installation to complete</li> </ul> <p>\ud83d\udca1 Jenkins plugins add features like GitHub integration, Docker pipelines, etc.</p>"},{"location":"phase-3/lab18/#step-7-create-admin-user","title":"Step 7: Create Admin User","text":"<p>Fill in the details:</p> <ul> <li>Username</li> <li>Password</li> <li>Full Name</li> <li>Email Address</li> </ul> <p>Click Save and Continue.</p>"},{"location":"phase-3/lab18/#step-8-verify-jenkins-is-ready","title":"Step 8: Verify Jenkins is Ready","text":"<p>You should now see the Jenkins Dashboard. \ud83c\udf89</p>"},{"location":"phase-3/lab18/#whats-next","title":"\ud83d\ude80 What\u2019s Next?","text":"<p>In the Lab 19, you\u2019ll:</p> <ul> <li>Connect Jenkins with GitHub</li> <li>Create your first Jenkins pipeline</li> <li>Run a CI/CD workflow for a sample application</li> </ul>"},{"location":"phase-3/lab19/","title":"Lab 19: Clone and Containerize Flask Web App","text":"<p>Objective</p> <p>By the end of this lab, you will be able to: - Clone a Flask app from GitHub - Understand the app\u2019s folder structure - Add a Dockerfile - Build and run the Flask app as a container</p> <p>Prerequisites</p> <ul> <li>Docker installed (Lab 17)</li> <li>Git configured (Lab 18)</li> </ul>"},{"location":"phase-3/lab19/#step-1-clone-the-flask-web-app-repo","title":"Step 1: Clone the Flask Web App Repo","text":""},{"location":"phase-3/lab19/#11-navigate-to-workspace-directory","title":"1.1 Navigate to workspace directory","text":"<pre><code>cd ~\nmkdir devops-labs &amp;&amp; cd devops-labs\n</code></pre>"},{"location":"phase-3/lab19/#12-clone-the-repository","title":"1.2 Clone the Repository","text":"<pre><code>git clone https://github.com/Sid-Trainings/flask-sample-webapp.git\ncd flask-sample-webapp\n</code></pre>"},{"location":"phase-3/lab19/#step-2-review-app-structure","title":"Step 2: Review App Structure","text":"<p>You should see: <pre><code>-README.md\n-app.py\n-app.yaml\n-app_test.py\n-requirements-test.txt\n-requirements.txt\n-templates/\n  -index.html\n</code></pre></p> <ul> <li><code>app.py</code>: Main Flask app entry point</li> <li><code>requirements.txt</code>: Python dependencies</li> <li><code>templates/index.html</code>: The HTML5 Bootstrap page</li> </ul>"},{"location":"phase-3/lab19/#step-3-create-dockerfile","title":"Step 3: Create Dockerfile","text":""},{"location":"phase-3/lab19/#31-create-file","title":"3.1 Create File","text":"<pre><code>nano Dockerfile\n</code></pre>"},{"location":"phase-3/lab19/#32-paste-below-content","title":"3.2 Paste Below Content","text":"<pre><code># Use Python base image\nFROM python:3.9-slim\n\n# Set work directory\nWORKDIR /app\n\n# Copy files\nCOPY . /app\n\n# Install dependencies\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Expose port\nEXPOSE 5000\n\n# Run the app\nCMD [\"python\", \"app.py\"]\n</code></pre> <p>Save and exit.</p> <p>Press Crtl+O --&gt; Enter and Crtl+X to save the file in nano editor</p>"},{"location":"phase-3/lab19/#step-4-build-docker-image","title":"Step 4: Build Docker Image","text":"<pre><code>docker build -t flask-demo-app .\n</code></pre>"},{"location":"phase-3/lab19/#step-5-run-flask-app-container","title":"Step 5: Run Flask App Container","text":"<pre><code>docker run -d -p 5000:5000 flask-demo-app\n</code></pre> <p>Access the app in browser: <pre><code>http://localhost:5000\n</code></pre></p>"},{"location":"phase-3/lab19/#verification","title":"\u2705 Verification","text":"<p>If the app loads with your styled HTML page and sections (Welcome, Docker Ready, etc.), you\u2019ve successfully containerized and deployed it locally.</p>"},{"location":"phase-3/lab19/#whats-next","title":"\ud83d\ude80 What\u2019s Next?","text":"<p>In Lab 20, you'll push this Docker image to Docker Hub.</p>"},{"location":"phase-3/lab20/","title":"Lab 20: Push Docker Image to Docker Hub","text":"<p>Objective</p> <p>By the end of this lab, you will be able to:</p> <ul> <li>Tag and push a Docker image to Docker Hub</li> <li>Verify the image on your Docker Hub profile</li> </ul> <p>Prerequisites</p> <ul> <li>Docker installed and image built (Lab 19)</li> <li>Docker Hub account</li> </ul>"},{"location":"phase-3/lab20/#docker-hub-account-creation","title":"Docker Hub Account Creation","text":"<p>In your desktop go to following address:</p> <ul> <li><code>https://hub.docker.com/</code></li> <li>Click on <code>Sign Up</code></li> <li>Select Personal Tab</li> <li>Enter your email address</li> <li>Put your desired Username</li> <li>Enter your password</li> <li>Click on <code>Sign Up</code></li> </ul>"},{"location":"phase-3/lab20/#step-1-login-to-docker-hub","title":"Step 1: Login to Docker Hub","text":"<p><pre><code>docker login -u &lt;your_username&gt;\n</code></pre> Enter your Docker Hub username and password when prompted.</p>"},{"location":"phase-3/lab20/#step-2-tag-your-docker-image","title":"Step 2: Tag Your Docker Image","text":"<p>Replace <code>&lt;your_dockerhub_username&gt;</code> with your actual Docker Hub username: <pre><code>docker tag flask-demo-app &lt;your_dockerhub_username&gt;/flask-demo-app:v1\n</code></pre></p> <p>Example: <pre><code>docker tag flask-demo-app sidtrainings/flask-demo-app:v1\n</code></pre></p> <p>What are Docker Tags? Docker tags are used to assign a unique identifier to a Docker image, allowing you to manage and organize different versions of your images. Tags are essentially aliases for image IDs and can be used to specify versions, variants, or other distinguishing characteristics of an image.</p> <p>Tagging an Image To tag an image in Docker, you can use the <code>docker tag</code> command. This command creates a new tag for an existing image, allowing you to reference the image by the new tag. The general syntax for the docker tag command is: <pre><code>docker tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG]\n</code></pre></p>"},{"location":"phase-3/lab20/#step-3-push-the-image-to-docker-hub","title":"Step 3: Push the Image to Docker Hub","text":"<pre><code>docker push &lt;your_dockerhub_username&gt;/flask-demo-app:v1\n</code></pre>"},{"location":"phase-3/lab20/#step-4-verify-on-docker-hub","title":"Step 4: Verify on Docker Hub","text":"<ul> <li>Go to https://hub.docker.com</li> <li>Login to your account</li> <li>Navigate to Repositories and confirm your image <code>flask-demo-app:v1</code> is listed</li> </ul>"},{"location":"phase-3/lab20/#optional-step-5-pull-and-run-the-image-from-docker-hub","title":"(OPTIONAL) Step 5: Pull and Run the Image from Docker Hub","text":"<p>Now that your image is on Docker Hub, you (or anyone) can use it anywhere Docker is installed.</p> <p>\ud83d\udd3d To pull the image: <pre><code>docker pull your-dockerhub-username/flask-demo-app:v1\n</code></pre> Replace <code>your-dockerhub-username</code> with your actual Docker Hub username.</p> <p>\u25b6\ufe0f To run the container: <pre><code>docker run -d -p 8081:5000 your-dockerhub-username/flask-demo-app:v1\n</code></pre> Now, visit http://localhost:8081 (or VM-IP:8081 if running on a remote machine) to see your Flask app in action!</p>"},{"location":"phase-3/lab20/#whats-next","title":"\ud83d\ude80 What\u2019s Next?","text":"<p>In Lab 21, you will write a Jenkins pipeline to automate image build and deployment.</p>"},{"location":"phase-3/lab21/","title":"Lab 21: Jenkins Pipeline for Local CI","text":"<p>Objective</p> <p>By the end of this lab, you will be able to: - Create a Jenkins Pipeline for building, testing, and deploying a Dockerized app - Deploy the app locally using Docker via Jenkins</p> <p>Prerequisites</p> <ul> <li>Jenkins is up and running (from Lab 18)</li> <li>Flask app is built (Lab 19)</li> <li>Docker installed on the host machine (Lab 17)</li> </ul>"},{"location":"phase-3/lab21/#step-1-prepare-github-repository","title":"Step 1: Prepare GitHub Repository","text":""},{"location":"phase-3/lab21/#11-fork-or-clone-the-flask-app-repository","title":"1.1 Fork or clone the Flask app repository","text":"<pre><code>git clone https://github.com/Sid-Trainings/flask-sample-webapp.git\ncd flask-sample-webapp\n</code></pre>"},{"location":"phase-3/lab21/#12a-push-it-to-your-own-github-repo","title":"1.2a Push it to your own GitHub repo","text":"Using SSHUsing HTTP(S) <pre><code>git remote rename origin upstream\ngit remote add origin git@github.com:&lt;your_username&gt;/flask-sample-webapp.git\ngit add .\ngit commit -m \"added Dockerfile\"\ngit push -u origin main\n</code></pre> <pre><code>git remote rename origin upstream\ngit remote add origin https://github.com/skarkhanis95/flask-sample-webapp.git\ngit add .\ngit commit -m \"added Dockerfile\"\ngit push -u origin main\n</code></pre>"},{"location":"phase-3/lab21/#step-2-configure-github-credentials-in-jenkins","title":"Step 2: Configure GitHub Credentials in Jenkins","text":"<ol> <li>Go to Manage Jenkins &gt; Credentials</li> <li>Under (global), click Add Credentials</li> <li>Choose Username and Password</li> <li>Add your GitHub username and Personal Access Token (PAT)</li> <li>Save it with an ID like <code>github-creds</code></li> </ol>"},{"location":"phase-3/lab21/#step-3-recreate-jenkins-container-with-docker-access","title":"Step 3: Recreate Jenkins Container with Docker Access","text":"<p>If Jenkins is running inside Docker, stop and recreate the container with required permissions:</p>"},{"location":"phase-3/lab21/#31-stop-and-remove-jenkins","title":"3.1 Stop and remove Jenkins","text":"<pre><code>docker stop jenkins\ndocker rm jenkins\n</code></pre>"},{"location":"phase-3/lab21/#32-run-jenkins-as-root-and-mount-docker-socket","title":"3.2 Run Jenkins as root and mount Docker socket","text":"<pre><code>docker run -d \\\n  --name jenkins \\\n  -u root \\\n  -p 8080:8080 -p 50000:50000 \\\n  -v jenkins_home:/var/jenkins_home \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  jenkins/jenkins:lts\n</code></pre>"},{"location":"phase-3/lab21/#33-remove-your-local-python-app-from-docker-socket","title":"3.3 Remove your local python app from Docker socket","text":"<pre><code>docker ps\n</code></pre> <p>Note the Container ID or Container Name of your local python app. At this point you should have 2, one for Jenkins and one for your local Python Flask App</p> <pre><code>docker stop &lt;your_flask_app_container_id_or_name&gt;\ndocker rm &lt;your_flask_app_container_id_or_name&gt;\n</code></pre>"},{"location":"phase-3/lab21/#step-4-install-docker-cli-inside-jenkins-container","title":"Step 4: Install Docker CLI Inside Jenkins Container","text":""},{"location":"phase-3/lab21/#41-enter-the-container-as-root","title":"4.1 Enter the container as root","text":"<pre><code>docker exec -u 0 -it jenkins bash\n</code></pre>"},{"location":"phase-3/lab21/#42-install-docker","title":"4.2 Install Docker","text":"<pre><code>apt update\napt install -y docker.io\n</code></pre>"},{"location":"phase-3/lab21/#43-verify-docker-is-working","title":"4.3 Verify Docker is working","text":"<pre><code>docker version\n</code></pre> <p>This should show both Docker client and server info (the server comes from host)</p> <p>Type <code>exit</code> to leave the container.</p>"},{"location":"phase-3/lab21/#step-5-create-jenkins-pipeline-job","title":"Step 5: Create Jenkins Pipeline Job","text":"<ol> <li>Go to Jenkins Dashboard &gt; New Item</li> <li>Enter job name, select Pipeline, click OK</li> <li>Scroll to Pipeline section</li> <li>Choose Pipeline script from SCM</li> <li>Select Git, and enter your GitHub repo URL</li> <li>Use <code>github-creds</code> if prompted for credentials</li> <li>Set the branch to <code>main</code></li> <li>Save the job</li> </ol>"},{"location":"phase-3/lab21/#step-6-add-jenkinsfile-to-github-repo","title":"Step 6: Add Jenkinsfile to GitHub Repo","text":"<p>In the root of your Flask repo, create a file named <code>Jenkinsfile</code>:</p> <ol> <li>nano <code>Jenkinsfile</code></li> <li>Copy the below code and paste into Nano editor</li> </ol> <p>Modify the file below to replace  with your actual GitHub username <pre><code>pipeline {\n  agent any\n\n  stages {\n    stage('Clone Repository') {\n      steps {\n        git url: 'https://github.com/&lt;your-github-username&gt;/flask-sample-webapp.git', branch: 'main'\n      }\n    }\n\n    stage('Build Docker Image') {\n      steps {\n        sh 'docker build -t flask-demo-app .'\n      }\n    }\n\n    stage('Run Container') {\n      steps {\n        sh 'docker stop flask-container || true'\n        sh 'docker rm flask-container || true'\n        sh 'docker run -d --name flask-container -p 5000:5000 flask-demo-app'\n      }\n    }\n  }\n}\n</code></pre> <p>Replace your username</p> <p>Replace <code>&lt;your-github-username&gt;</code> with your actual GitHub username.</p> <ol> <li>Save and Exit the nano editor using Ctrl+O --&gt; press Enter --&gt; Crtl+X</li> </ol>"},{"location":"phase-3/lab21/#61-push-jenkinsfile-to-github","title":"6.1 Push Jenkinsfile to GitHub","text":"<pre><code>git add Jenkinsfile\ngit commit -m \"Add Jenkins pipeline\"\ngit push origin main\n</code></pre>"},{"location":"phase-3/lab21/#step-7-run-your-pipeline","title":"Step 7: Run Your Pipeline","text":"<ol> <li>Open Jenkins</li> <li>Go to your pipeline job</li> <li>Click Build Now</li> <li>Monitor output in the Console Output tab</li> </ol>"},{"location":"phase-3/lab21/#verification","title":"Verification","text":"<ul> <li>In your host browser, visit:   <pre><code>http://&lt;VM-IP&gt;:5000\n</code></pre></li> <li>You should see your Flask web app running via a container created by Jenkins</li> </ul> <p>\ud83d\udca1 Make sure your Flask app uses <code>app.run(host='0.0.0.0', port=5000)</code> to allow external access</p>"},{"location":"phase-3/lab22/","title":"Lab 22 \u2014 Terraform Workshop (AWS) for Docker Swarm","text":"<p>Format: mkdocs-material friendly Markdown (followed your lab style) Goal: students build the Terraform files step-by-step themselves (we give short snippets and ask for one input at a time). This teaches what each resource does, and avoids dumping a full monolith Terraform file.</p> <p>Objective</p> <p>By the end of this workshop students will be able to:</p> <ul> <li>Understand Terraform basics (provider, variables, resources, outputs).</li> <li>Create a VPC, public subnets, Internet Gateway, Route Table, Security Group.</li> <li>Launch EC2 instances (manager + 2 workers) with cloud-init user-data that installs Docker.</li> <li>Output instance IPs and SSH info.</li> <li>Apply and destroy the infrastructure with Terraform.</li> </ul> <p>Prerequisites</p> <ul> <li>AWS account with permission to create VPCs, EC2, security groups, keypairs, IAM (basic).</li> <li>AWS CLI configured locally (or set <code>AWS_ACCESS_KEY_ID</code> / <code>AWS_SECRET_ACCESS_KEY</code> env vars).</li> <li>Basic familiarity with terminal &amp; SSH.</li> </ul>"},{"location":"phase-3/lab22/#project-layout-you-will-create","title":"Project layout you will create","text":"<pre><code>swarm-terraform/\n\u251c\u2500 main.tf              # provider + optional locals\n\u251c\u2500 variables.tf         # all variables (students will fill defaults or input during apply)\n\u251c\u2500 vpc.tf               # VPC, subnets, IGW, route table\n\u251c\u2500 security.tf          # security group\n\u251c\u2500 keypair.tf           # optional AWS key pair resource\n\u251c\u2500 instances.tf         # EC2 instances (manager + workers)\n\u251c\u2500 outputs.tf           # public/private IP outputs\n\u251c\u2500 cloud-init-docker.sh # cloud-init script to install and configure docker in first boot\n</code></pre> <p>For Linux Users: create directory <code>mkdir ~/swarm-terraform &amp;&amp; cd ~/swarm-terraform</code> before starting. For Windows Users: Create the Folder <code>swarm-terraform</code> in any place that you prefer in your computer</p> <p>Got it \ud83d\udc4d \u2014 here are the Terraform installation steps for both Windows and Linux, explained simply so students (who are mostly beginners) can follow.</p>"},{"location":"phase-3/lab22/#installing-terraform","title":"Installing Terraform","text":"Windows InstallationLinux Installation (Ubuntu / Debian)"},{"location":"phase-3/lab22/#step-1-download-terraform","title":"Step 1: Download Terraform","text":"<ol> <li>Open a browser and go to the official Terraform downloads page: \ud83d\udc49 https://developer.hashicorp.com/terraform/downloads</li> <li>Choose Windows (AMD64) \u2014 download the <code>.zip</code> file.</li> </ol>"},{"location":"phase-3/lab22/#step-2-extract-the-zip","title":"Step 2: Extract the zip","text":"<ol> <li>Right-click the downloaded zip \u2192 Extract All.</li> <li>Inside you will see a single executable: <code>terraform.exe</code>.</li> </ol>"},{"location":"phase-3/lab22/#step-3-move-terraformexe-to-a-permanent-folder","title":"Step 3: Move terraform.exe to a permanent folder","text":"<p>Common choice:</p> <ul> <li><code>C:\\terraform\\terraform.exe</code> (or any folder you prefer).</li> </ul>"},{"location":"phase-3/lab22/#step-4-add-terraform-to-path","title":"Step 4: Add Terraform to PATH","text":"<ol> <li>Open Start Menu \u2192 search for Environment Variables.</li> <li>Click Edit the system environment variables.</li> <li>In System Properties \u2192 Advanced \u2192 click Environment Variables.</li> <li>Under \u201cSystem variables\u201d find <code>Path</code> \u2192 select \u2192 Edit.</li> <li>Click New, and add the path where you stored <code>terraform.exe</code> (e.g., <code>C:\\terraform</code>).</li> <li>Click OK \u2192 OK \u2192 OK to save.</li> </ol>"},{"location":"phase-3/lab22/#step-5-verify-installation","title":"Step 5: Verify installation","text":"<p>Open Command Prompt or PowerShell and run:</p> <pre><code>terraform version\n</code></pre> <p>You should see something like:</p> <pre><code>Terraform v1.6.x\non windows_amd64\n</code></pre> <p>\u2705 Done \u2014 Terraform is installed on Windows!</p>"},{"location":"phase-3/lab22/#step-1-update-packages-and-install-curl-unzip","title":"Step 1: Update packages and install curl, unzip","text":"<pre><code>sudo apt update\nsudo apt install -y curl unzip\n</code></pre>"},{"location":"phase-3/lab22/#step-2-download-terraform-binary","title":"Step 2: Download Terraform binary","text":"<p>Find latest version (example: 1.6.6). Run:</p> <pre><code>curl -fsSL https://releases.hashicorp.com/terraform/1.6.6/terraform_1.6.6_linux_amd64.zip -o terraform.zip\n</code></pre>"},{"location":"phase-3/lab22/#step-3-unzip-and-move-binary","title":"Step 3: Unzip and move binary","text":"<pre><code>unzip terraform.zip\nsudo mv terraform /usr/local/bin/\n</code></pre>"},{"location":"phase-3/lab22/#step-4-verify-installation","title":"Step 4: Verify installation","text":"<pre><code>terraform version\n</code></pre> <p>Output should look like:</p> <pre><code>Terraform v1.6.6\non linux_amd64\n</code></pre> <p>\u2705 Done \u2014 Terraform is installed on Linux!</p>"},{"location":"phase-3/lab22/#step-0-create-basic-files","title":"STEP 0 \u2014 Create basic files","text":"<p>Create <code>main.tf</code>:</p> <pre><code>terraform {\n  required_version = \"&gt;= 1.0.0\"\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"&gt;= 4.0\"\n    }\n  }\n}\n\nprovider \"aws\" {\n  region = var.aws_region\n}\n</code></pre> <p>Create <code>variables.tf</code>:</p> <p>Info</p> <ul> <li>Check your default region in AWS Web Console and configure the same here</li> <li>In <code>variable \"ssh_key_name\"</code> section, enter the same key that you have used before</li> </ul> <pre><code>variable \"aws_region\" {\n  description = \"AWS region to create resources in\"\n  type        = string\n  default     = \"eu-north-1\"   # change if you like\n}\n\nvariable \"vpc_cidr\" {\n  description = \"VPC CIDR\"\n  type        = string\n  default     = \"15.0.0.0/16\"\n}\n\nvariable \"public_subnet_cidrs\" {\n  description = \"List of public subnet CIDRs (at least 2 recommended)\"\n  type        = list(string)\n  default     = [\"15.0.1.0/24\", \"15.0.2.0/24\"]\n}\n\nvariable \"instance_type\" {\n  description = \"EC2 instance type\"\n  type        = string\n  default     = \"t3.small\"\n}\n\nvariable \"ssh_key_name\" {\n  description = \"Existing AWS key pair name (or empty to create one)\"\n  type        = string\n  default     = \"ditiss-chef-key\"\n}\n\nvariable \"ssh_public_key\" {\n  description = \"If creating a keypair, paste your public SSH key here\"\n  type        = string\n  default     = \"\"\n}\n\nvariable \"manager_count\" {\n  description = \"Number of Swarm manager nodes\"\n  type        = number\n  default     = 1\n}\n\nvariable \"worker_count\" {\n  description = \"Number of Swarm worker nodes\"\n  type        = number\n  default     = 2\n}\n</code></pre> <p>Explanation: <code>main.tf</code> sets the AWS provider. <code>variables.tf</code> collects small inputs from users so they can reason about each value (region, CIDRs, instance sizes, keypair choices).</p>"},{"location":"phase-3/lab22/#step-1-create-the-vpc","title":"STEP 1 \u2014 Create the VPC","text":"<p>Create <code>vpc.tf</code>:</p> <pre><code>resource \"aws_vpc\" \"swarm_vpc\" {\n  cidr_block           = var.vpc_cidr\n  enable_dns_hostnames = true\n  tags = {\n    Name = \"swarm-vpc\"\n  }\n}\n\nresource \"aws_internet_gateway\" \"igw\" {\n  vpc_id = aws_vpc.swarm_vpc.id\n  tags = { Name = \"swarm-igw\" }\n}\n\nresource \"aws_subnet\" \"public\" {\n  count                   = length(var.public_subnet_cidrs)\n  vpc_id                  = aws_vpc.swarm_vpc.id\n  cidr_block              = var.public_subnet_cidrs[count.index]\n  availability_zone       = data.aws_availability_zones.available.names[count.index]\n  map_public_ip_on_launch = true\n  tags = {\n    Name = \"swarm-public-${count.index + 1}\"\n  }\n}\n\nresource \"aws_route_table\" \"public_rt\" {\n  vpc_id = aws_vpc.swarm_vpc.id\n  route {\n    cidr_block = \"0.0.0.0/0\"\n    gateway_id = aws_internet_gateway.igw.id\n  }\n  tags = { Name = \"swarm-public-rt\" }\n}\n\nresource \"aws_route_table_association\" \"public_assoc\" {\n  count          = length(var.public_subnet_cidrs)\n  subnet_id      = aws_subnet.public[count.index].id\n  route_table_id = aws_route_table.public_rt.id\n}\n\ndata \"aws_availability_zones\" \"available\" {}\n</code></pre> <p>Explanation: This creates a VPC, an Internet Gateway (so instances can reach/pulled images from internet), two public subnets (one per AZ), and associates them with a public route table. Visualisation: VPC = private network; subnet = chunk of that network; IGW = door to Internet; route table = instructs traffic via the IGW.</p>"},{"location":"phase-3/lab22/#step-2-create-security-group","title":"STEP 2 \u2014 Create Security Group","text":"<p>Warning</p> <ul> <li><code>admin_ip</code> \u2014 is the public IP of your local computer, you can find the same using What is My IP. For lab purposes, you can keep default as <code>0.0.0.0/0</code> which allows access from any system in the world. But this is risky and should be avoided</li> </ul> <p>Create <code>security.tf</code>:</p> <pre><code>variable \"admin_ip\" {\n  description = \"Your admin public IP in CIDR format for SSH and HTTP access\"\n  type        = string\n  default     = \"0.0.0.0/0\"\n}\n\nresource \"aws_security_group\" \"swarm_sg\" {\n  name        = \"swarm-sg\"\n  description = \"Allow SSH, Swarm and app ports\"\n  vpc_id      = aws_vpc.swarm_vpc.id\n\n  ingress {\n    description = \"SSH\"\n    from_port   = 22\n    to_port     = 22\n    protocol    = \"tcp\"\n    cidr_blocks = [var.admin_ip]\n  }\n\n  ingress {\n    description = \"Swarm manager (2377)\"\n    from_port   = 2377\n    to_port     = 2377\n    protocol    = \"tcp\"\n    cidr_blocks = [aws_vpc.swarm_vpc.cidr_block]\n  }\n\n  ingress {\n    description = \"Swarm cluster discovery (7946/tcp)\"\n    from_port   = 7946\n    to_port     = 7946\n    protocol    = \"tcp\"\n    cidr_blocks = [aws_vpc.swarm_vpc.cidr_block]\n  }\n\n  ingress {\n    description = \"Swarm cluster discovery (7946/udp)\"\n    from_port   = 7946\n    to_port     = 7946\n    protocol    = \"udp\"\n    cidr_blocks = [aws_vpc.swarm_vpc.cidr_block]\n  }\n\n  ingress {\n    description = \"Swarm overlay network (4789/udp)\"\n    from_port   = 4789\n    to_port     = 4789\n    protocol    = \"udp\"\n    cidr_blocks = [aws_vpc.swarm_vpc.cidr_block]\n  }\n\n  ingress {\n    description = \"HTTP App (8080)\"\n    from_port   = 8080\n    to_port     = 8080\n    protocol    = \"tcp\"\n    cidr_blocks = [var.admin_ip]\n  }\n\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  tags = { Name = \"swarm-sg\" }\n}\n</code></pre> <p>Explanation: We create a SG that permits SSH from your IP, Swarm internal ports across the VPC CIDR (so manager &amp; workers can talk), and exposes port 8080 for the demo app only to your IP.</p>"},{"location":"phase-3/lab22/#step-3-key-pair","title":"STEP 3 \u2014 Key pair","text":"<p>Choice for students:</p> <p>Do you already have an AWS key pair you will use? (yes/no)</p> <ul> <li>If yes: set variable <code>ssh_key_name</code> to that key name in <code>variables.tf</code>. Terraform will attach it to instances.</li> <li>If no: paste your local public SSH key (e.g., <code>~/.ssh/id_rsa.pub</code>) into <code>variables.tf</code> (<code>ssh_public_key</code>) and Terraform will create a keypair in AWS.</li> </ul> <p>Create <code>keypair.tf</code> (paste \u2014 this will create a keypair if <code>ssh_public_key</code> is provided):</p> <pre><code>resource \"aws_key_pair\" \"swarm_key\" {\n  count      = var.ssh_public_key != \"\" ? 1 : 0\n  key_name   = \"swarm-key-${random_id.key_id.hex}\"\n  public_key = var.ssh_public_key\n}\n\nresource \"random_id\" \"key_id\" {\n  byte_length = 4\n}\n\n# a simple local value to pick either existing name or created one\nlocals {\n  ssh_key_name_final = var.ssh_key_name != \"\" ? var.ssh_key_name : (length(aws_key_pair.swarm_key) &gt; 0 ? aws_key_pair.swarm_key[0].key_name : \"\")\n}\n\noutput \"ssh_key_name\" {\n  value = local.ssh_key_name_final\n}\n</code></pre>"},{"location":"phase-3/lab22/#step-4-ec2-instances","title":"STEP 4 \u2014 EC2 Instances","text":"<p>Instance Information</p> <ul> <li><code>manager_count</code> and <code>worker_count</code> (from <code>variables.tf</code>, defaults 1 and 2)</li> <li>Confirm <code>instance_type</code> (default <code>t3.small</code>)</li> </ul> <p>Create <code>instances.tf</code> (paste \u2014 uses the <code>local.ssh_key_name_final</code> from previous step):</p> <pre><code>data \"aws_ami\" \"ubuntu\" {\n  most_recent = true\n  owners      = [\"099720109477\"] # Canonical Ubuntu\n  filter {\n    name   = \"name\"\n    values = [\"ubuntu/images/hvm-ssd/ubuntu-jammy-22.04-amd64-server-*\"]\n  }\n}\n\nresource \"aws_instance\" \"manager\" {\n  count         = var.manager_count\n  ami           = data.aws_ami.ubuntu.id\n  instance_type = var.instance_type\n  subnet_id     = aws_subnet.public[0].id\n  key_name      = local.ssh_key_name_final\n  vpc_security_group_ids = [aws_security_group.swarm_sg.id]\n  associate_public_ip_address = true\n\n  user_data = file(\"${path.module}/cloud-init-docker.sh\")\n\n  tags = {\n    Name = \"swarm-manager-${count.index + 1}\"\n    Role = \"swarm-manager\"\n  }\n}\n\nresource \"aws_instance\" \"worker\" {\n  count         = var.worker_count\n  ami           = data.aws_ami.ubuntu.id\n  instance_type = var.instance_type\n  subnet_id     = aws_subnet.public[count.index + 1 &gt;= length(aws_subnet.public) ? 0 : count.index + 1].id\n  key_name      = local.ssh_key_name_final\n  vpc_security_group_ids = [aws_security_group.swarm_sg.id]\n  associate_public_ip_address = true\n\n  user_data = file(\"${path.module}/cloud-init-docker.sh\")\n\n  tags = {\n    Name = \"swarm-worker-${count.index + 1}\"\n    Role = \"swarm-worker\"\n  }\n}\n</code></pre> <p>Create file <code>cloud-init-docker.sh</code>:</p> <pre><code>#!/bin/bash\n# cloud-init script to install Docker on Ubuntu (runs as root on first boot)\napt-get update\nDEBIAN_FRONTEND=noninteractive apt-get install -y apt-transport-https ca-certificates curl gnupg lsb-release\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg\necho \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" &gt; /etc/apt/sources.list.d/docker.list\napt-get update\napt-get install -y docker-ce docker-ce-cli containerd.io\nusermod -aG docker ubuntu || true\nsystemctl enable docker\nsystemctl start docker\n# add a tiny marker file to confirm cloud-init ran\necho \"Docker installed on $(hostname)\" &gt; /etc/motd.d/docker-installed\n</code></pre> <p>Explanation: We launch EC2 instances with a cloud-init script that installs Docker and starts it. Students will later SSH into manager and run <code>docker swarm init</code>.</p>"},{"location":"phase-3/lab22/#step-5-outputs","title":"STEP 5 \u2014 Outputs","text":"<p>Create <code>outputs.tf</code>:</p> <pre><code>output \"manager_public_ips\" {\n  value = [for i in aws_instance.manager : i.public_ip]\n}\n\noutput \"worker_public_ips\" {\n  value = [for i in aws_instance.worker : i.public_ip]\n}\n\noutput \"manager_private_ips\" {\n  value = [for i in aws_instance.manager : i.private_ip]\n}\n</code></pre> <p>Explanation: Outputs make it easy to find the public IPs to SSH into. Students can run <code>terraform output</code> or view values after <code>apply</code>.</p>"},{"location":"phase-3/lab22/#step-6-initialize-apply","title":"STEP 6 \u2014 Initialize &amp; apply","text":"<ul> <li>Start your terminal/cmd/powershell at the same folder where your project folder resides</li> </ul> <p>Commands (one-by-one):</p> <ol> <li><code>terraform init</code></li> <li><code>terraform validate</code></li> <li> <p><code>terraform plan</code> This will use all default values set in <code>variables.tf</code></p> <ul> <li>Or override defaults by passing them in cli <code>terraform plan -var=\"aws_region=ap-south-1\" -var=\"admin_ip=203.0.113.5/32\" -var=\"ssh_public_key=\\\"&lt;paste-your-ssh-pub-key&gt;\\\"\"</code></li> </ul> </li> <li> <p><code>terraform apply</code></p> </li> </ol> <p>Explanation: You are intentionally applying as a final step after you\u2019ve built the pieces \u2014 this reinforces the idea that Terraform plans then applies changes.</p>"},{"location":"phase-3/lab22/#step-7-verify-ec2-instances-docker","title":"STEP 7 \u2014 Verify EC2 instances &amp; Docker","text":"<p>Student commands:</p> <ul> <li><code>terraform output manager_public_ips</code></li> <li>SSH into manager: <code>ssh -i ~/.ssh/your_private_key ubuntu@&lt;manager_ip&gt;</code></li> <li>On manager: <code>sudo docker version</code> and <code>sudo docker run hello-world</code></li> </ul> <p>Explanation: Confirm the cloud-init ran and Docker is available. If cloud-init failed, inspect <code>/var/log/cloud-init-output.log</code>.</p>"},{"location":"phase-3/lab22/#troubleshooting-tips","title":"Troubleshooting tips","text":"<ul> <li>If <code>terraform apply</code> fails due to API limits or missing quotas, try again after a short wait.</li> <li>If EC2 boot fails (no Docker), inspect <code>cloud-init</code> logs: <code>/var/log/cloud-init-output.log</code>.</li> <li>If workers cannot join manager, ensure security group allows ports 2377, 7946, 4789 within VPC. Use <code>nc -zv &lt;ip&gt; 2377</code> for quick test.</li> <li>If plan shows resources to be recreated unexpectedly, check provider version &amp; data sources (AMI most_recent may change).</li> </ul>"},{"location":"phase-3/lab22a/","title":"Lab: Deploy a simple EC2 instance with Terraform (Optional)","text":"<p>Lab Info</p> <p>Duration: 2\u20134 hours (recommended for beginners) Session mapping: IaC &amp; Terraform labs (PG-DITISS) \u2014 hands-on practice after theory. Goal: Install Terraform &amp; AWS CLI on Windows/Linux/macOS, configure AWS credentials, write Terraform to provision an EC2 instance (with SSH access and NGINX installed via <code>user_data</code>), verify the web page, then destroy the resources.</p> <p>Learning objectives</p> <ul> <li>Install Terraform and AWS CLI on Windows, macOS and Linux.</li> <li>Create an AWS IAM user (programmatic access) and configure credentials locally.</li> <li> <p>Author Terraform files (<code>provider</code>, <code>data</code>, <code>resource</code>, <code>variables</code>, <code>outputs</code>) to provision:</p> </li> <li> <p>an EC2 instance (Amazon Linux 2)</p> </li> <li>a security group opening SSH (22) and HTTP (80)</li> <li>an AWS key pair (from a local public key)</li> <li>Run the standard Terraform workflow: <code>terraform init</code>, <code>terraform plan</code>, <code>terraform apply</code>, <code>terraform destroy</code>.</li> <li>SSH to the instance and validate NGINX is serving the test page.</li> <li>Clean up resources and understand cost considerations.</li> </ul> <p>Warning (cost): Although this lab uses small instance types (e.g., <code>t2.micro</code> / <code>t3.micro</code>) which may be in AWS Free Tier, you may still incur charges for non-free resources. Always <code>terraform destroy</code> when finished.</p>"},{"location":"phase-3/lab22a/#a-pre-requisites","title":"A. Pre-requisites","text":"<ul> <li>AWS account with permission to create IAM users, EC2 instances, key pairs, and security groups (or an instructor pre-created IAM credentials for the lab).</li> <li> <p>Local machine (Windows / macOS / Linux) with:</p> </li> <li> <p>shell (bash, PowerShell or Git Bash)</p> </li> <li>internet access</li> <li>text editor (VS Code recommended)</li> <li>Basic Linux shell familiarity (ssh, chmod).</li> </ul>"},{"location":"phase-3/lab22a/#b-install-tools","title":"B. Install tools","text":""},{"location":"phase-3/lab22a/#1-terraform-quick-install-per-os","title":"1) Terraform \u2014 quick install per OS","text":"macOS (recommended: Homebrew)Ubuntu / Debian LinuxWindows (PowerShell, Chocolatey or Scoop) <pre><code># if Homebrew installed:\nbrew tap hashicorp/tap\nbrew install hashicorp/tap/terraform\nterraform -version\n</code></pre> <pre><code># download latest zip (replace &lt;VERSION&gt; with desired release if you want)\nVERSION=1.8.5   # example \u2014 you can use latest\nwget https://releases.hashicorp.com/terraform/${VERSION}/terraform_${VERSION}_linux_amd64.zip\nsudo apt-get update &amp;&amp; sudo apt-get install -y unzip\nunzip terraform_${VERSION}_linux_amd64.zip\nsudo mv terraform /usr/local/bin/\nterraform -version\n</code></pre> <p>(Alternative: use distro packages or HashiCorp apt repo \u2014 both are fine. If using cloud VMs you can often use package managers.)</p> <ul> <li>With Chocolatey (run as Admin PowerShell):</li> </ul> <pre><code>choco install terraform -y\nterraform -version\n</code></pre> <ul> <li>Or download the Windows zip from https://developer.hashicorp.com/terraform/downloads and add the terraform.exe to your PATH.</li> </ul>"},{"location":"phase-3/lab22a/#2-aws-cli","title":"2) AWS CLI","text":"macOS (Homebrew)Ubuntu / DebianWindows <pre><code>brew install awscli\naws --version\n</code></pre> <pre><code>sudo apt-get update\nsudo apt-get install -y awscli\naws --version\n</code></pre> <p>(If you want AWS CLI v2, follow AWS docs to install the v2 bundle for your OS.)</p> <ul> <li>Use Chocolatey:</li> </ul> <pre><code>choco install awscli -y\naws --version\n</code></pre> <ul> <li>Or download the MSI installer from AWS.</li> </ul>"},{"location":"phase-3/lab22a/#3-ssh-keypair-create-locally","title":"3) SSH keypair (create locally)","text":"<p>You will create an SSH key pair to access the EC2 instance.</p> Linux / macOSWindows <pre><code>ssh-keygen -t rsa -b 4096 -f ~/.ssh/techops_key -N \"\"\n# This creates:\n#  - private: ~/.ssh/techops_key\n#  - public : ~/.ssh/techops_key.pub\n</code></pre> <p>(PowerShell / Git Bash / WSL): use the same <code>ssh-keygen</code> command in Git Bash or WSL, or use PuTTYgen and export OpenSSH public key.</p> <p>Keep the private key secure and set permissions:</p> <pre><code>chmod 600 ~/.ssh/techops_key\n</code></pre>"},{"location":"phase-3/lab22a/#c-create-an-iam-user-for-the-lab-console-steps","title":"C. Create an IAM user for the lab (console steps)","text":"<ol> <li>Sign in to AWS Console \u2192 IAM \u2192 Users \u2192 Add user.</li> <li>Enter username (e.g., <code>terraform-lab-user</code>). Choose Programmatic access checkbox (creates access key / secret).</li> <li>Permissions: For a simple lab, attach the AWS managed policy AmazonEC2FullAccess and AmazonS3ReadOnlyAccess if you plan to use S3 backend later.    Note: For production / least privilege, create a narrower policy (allow <code>ec2:*</code> only as necessary).</li> <li>Create user, copy Access key ID and Secret access key (or download <code>.csv</code>). Keep them safe.</li> </ol>"},{"location":"phase-3/lab22a/#d-configure-aws-credentials-locally","title":"D. Configure AWS credentials locally","text":"<pre><code>aws configure --profile techops\n# Enter Access Key ID, Secret Access Key, default region (e.g., ap-south-1), default output json\n</code></pre> <p>This stores credentials in <code>~/.aws/credentials</code> and <code>~/.aws/config</code>.</p>"},{"location":"phase-3/lab22a/#e-terraform-project-files-code","title":"E. Terraform project \u2014 files &amp; code","text":"<p>Create a folder for the lab:</p> <pre><code>mkdir terraform-ec2-lab &amp;&amp; cd terraform-ec2-lab\n</code></pre> <p>Create these files:</p>"},{"location":"phase-3/lab22a/#1-variablestf","title":"1. <code>variables.tf</code>","text":"<pre><code>variable \"region\" {\n  description = \"AWS Region to deploy to\"\n  type        = string\n  default     = \"ap-south-1\"\n}\n\nvariable \"instance_type\" {\n  description = \"EC2 instance type\"\n  type        = string\n  default     = \"t2.micro\"\n}\n\nvariable \"key_name\" {\n  description = \"Name for AWS key pair to create/use\"\n  type        = string\n  default     = \"techops-key\"\n}\n\nvariable \"public_key_path\" {\n  description = \"Path to local public key file (ssh public key)\"\n  type        = string\n  default     = \"~/.ssh/techops_key.pub\"\n}\n\nvariable \"my_ip_cidr\" {\n  description = \"CIDR to allow SSH from \u2014 set to your IP (e.g. 203.0.113.5/32) or 0.0.0.0/0 for demo\"\n  type        = string\n  default     = \"0.0.0.0/0\"\n}\n</code></pre>"},{"location":"phase-3/lab22a/#2-providertf","title":"2. <code>provider.tf</code>","text":"<pre><code>terraform {\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~&gt; 5.0\" # optional\n    }\n  }\n  required_version = \"&gt;= 1.4.0\"\n}\n\nprovider \"aws\" {\n  region  = var.region\n  # If you configured a profile with `aws configure --profile techops`, uncomment:\n  # profile = \"techops\"\n}\n</code></pre>"},{"location":"phase-3/lab22a/#3-datatf-look-up-latest-amazon-linux-2-ami-region-agnostic","title":"3. <code>data.tf</code> \u2014 look up latest Amazon Linux 2 AMI (region agnostic)","text":"<pre><code>data \"aws_ami\" \"amazon_linux_2\" {\n  most_recent = true\n  owners      = [\"amazon\"]\n\n  filter {\n    name   = \"name\"\n    values = [\"amzn2-ami-hvm-*-x86_64-gp2\"]\n  }\n}\n</code></pre>"},{"location":"phase-3/lab22a/#4-resourcestf","title":"4. <code>resources.tf</code>","text":"<pre><code># Security group for SSH and HTTP\nresource \"aws_security_group\" \"web_sg\" {\n  name        = \"techops-web-sg\"\n  description = \"Allow SSH and HTTP\"\n\n  ingress {\n    description = \"SSH\"\n    from_port   = 22\n    to_port     = 22\n    protocol    = \"tcp\"\n    cidr_blocks = [var.my_ip_cidr]\n  }\n\n  ingress {\n    description = \"HTTP\"\n    from_port   = 80\n    to_port     = 80\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  tags = {\n    Name = \"techops-web-sg\"\n  }\n}\n\n# Create/import key pair using local public key\nresource \"aws_key_pair\" \"deployer\" {\n  key_name   = var.key_name\n  public_key = file(var.public_key_path)\n}\n\n# EC2 instance\nresource \"aws_instance\" \"web\" {\n  ami                    = data.aws_ami.amazon_linux_2.id\n  instance_type          = var.instance_type\n  vpc_security_group_ids = [aws_security_group.web_sg.id]\n  key_name               = aws_key_pair.deployer.key_name\n\n  user_data = &lt;&lt;-EOF\n              #!/bin/bash\n              yum update -y\n              yum install -y nginx\n              systemctl enable nginx\n              systemctl start nginx\n              echo \"Hello from TechOps Inc. - $(hostname -f)\" &gt; /usr/share/nginx/html/index.html\n              EOF\n\n  tags = {\n    Name = \"TechOps-Web-Instance\"\n  }\n}\n</code></pre>"},{"location":"phase-3/lab22a/#5-outputstf","title":"5. <code>outputs.tf</code>","text":"<pre><code>output \"instance_id\" {\n  value = aws_instance.web.id\n}\n\noutput \"instance_public_ip\" {\n  value = aws_instance.web.public_ip\n}\n\noutput \"instance_public_dns\" {\n  value = aws_instance.web.public_dns\n}\n</code></pre>"},{"location":"phase-3/lab22a/#6-optional-devtfvars-example-variable-values","title":"6. Optional: <code>dev.tfvars</code> (example variable values)","text":"<pre><code>region         = \"ap-south-1\"\ninstance_type  = \"t2.micro\"\nkey_name       = \"techops-key\"\npublic_key_path = \"~/.ssh/techops_key.pub\"\nmy_ip_cidr     = \"0.0.0.0/0\" # replace with your IP/cidr for better security\n</code></pre>"},{"location":"phase-3/lab22a/#f-run-the-lab-terraform-commands-step-by-step","title":"F. Run the lab: Terraform commands (step-by-step)","text":"<ol> <li>Init</li> </ol> <pre><code>terraform init\n</code></pre> <ul> <li> <p>This downloads the AWS provider plugin and initializes the working directory.</p> </li> <li> <p>Format &amp; Validate (optional but recommended)</p> </li> </ul> <pre><code>terraform fmt\nterraform validate\n</code></pre> <ol> <li>Plan</li> </ol> <pre><code>terraform plan -var-file=\"dev.tfvars\"\n</code></pre> <ul> <li> <p>Review the plan carefully. Terraform will show which resources will be created.</p> </li> <li> <p>Apply</p> </li> </ul> <pre><code>terraform apply -var-file=\"dev.tfvars\"\n# or with auto-approve (not recommended for beginners)\nterraform apply -var-file=\"dev.tfvars\" -auto-approve\n</code></pre> <ul> <li> <p>On success, Terraform will print outputs including the <code>instance_public_ip</code>.</p> </li> <li> <p>Verify</p> </li> <li> <p>In terminal:</p> </li> </ul> <pre><code>terraform output instance_public_ip\n# Example output: 3.10.123.45\n</code></pre> <ul> <li> <p>Open <code>http://&lt;instance_public_ip&gt;/</code> in a browser \u2014 you should see the \"Hello from TechOps Inc.\" page.</p> </li> <li> <p>SSH into the instance</p> </li> <li> <p>For Amazon Linux 2 (ec2-user):</p> </li> </ul> <pre><code>ssh -i ~/.ssh/techops_key ec2-user@&lt;instance_public_ip&gt;\n</code></pre> <ul> <li>For Ubuntu AMIs (if used):</li> </ul> <pre><code>ssh -i ~/.ssh/techops_key ubuntu@&lt;instance_public_ip&gt;\n</code></pre> <ul> <li> <p>If \"Permission denied (publickey)\", check that:</p> </li> <li> <p>The private key path is correct and file permissions are <code>chmod 600</code>.</p> </li> <li> <p>The instance was launched with the same key name (check <code>aws ec2 describe-instances</code> or <code>terraform show</code>).</p> </li> <li> <p>Explore</p> </li> <li> <p>Check nginx status on the instance:</p> </li> </ul> <pre><code>sudo systemctl status nginx\ncurl http://localhost\n</code></pre>"},{"location":"phase-3/lab22a/#g-tear-down-cleanup","title":"G. Tear down / Cleanup","text":"<ol> <li>Destroy with Terraform</li> </ol> <pre><code>terraform destroy -var-file=\"dev.tfvars\"\n# confirm when prompted; or:\nterraform destroy -var-file=\"dev.tfvars\" -auto-approve\n</code></pre> <ul> <li> <p>This attempts to remove all the resources Terraform created (EC2, SG, key pair created by Terraform).</p> </li> <li> <p>Manual cleanup (if needed)</p> </li> <li> <p>If you created the key pair manually in AWS console, delete it there.</p> </li> <li>Check IAM users / access keys created for the lab and rotate/delete them if they were temporary.</li> </ul>"},{"location":"phase-3/lab22a/#h-troubleshooting-common-issues-fixes","title":"H. Troubleshooting \u2014 common issues &amp; fixes","text":"<ul> <li> <p>Credentials / permission denied errors</p> </li> <li> <p><code>Error: No valid credential sources found</code> \u2192 Ensure <code>aws configure</code> was run or environment vars are set.</p> </li> <li> <p><code>AuthFailure</code> or <code>AccessDenied</code> \u2192 The IAM user lacks required permissions (attach <code>AmazonEC2FullAccess</code> for the lab).</p> </li> <li> <p>Invalid AMI / AMI not found</p> </li> <li> <p>AMI ids are region-specific. Using the <code>data \"aws_ami\"</code> data source solves this. If you hardcoded an AMI ID, choose the correct one for your selected region.</p> </li> <li> <p>SSH: Permission denied (publickey)</p> </li> <li> <p>Wrong username (use <code>ec2-user</code> for Amazon Linux; <code>ubuntu</code> for Ubuntu).</p> </li> <li>Private key file permissions too open \u2014 run <code>chmod 600 ~/.ssh/techops_key</code>.</li> <li> <p>Key pair mismatch (instance was launched with a different key name).</p> </li> <li> <p>Port 22 blocked</p> </li> <li> <p>Check the security group's ingress rules (allowed CIDR). Use <code>0.0.0.0/0</code> for testing (NOT recommended permanently). Better: restrict to your public IP, e.g. <code>203.0.113.5/32</code>.</p> </li> <li> <p>State or backend lock errors (team scenarios)</p> </li> <li> <p>If using remote state in S3 with locking, a concurrent <code>terraform apply</code> may cause a lock. Wait, or consult <code>terraform force-unlock</code> (use with caution).</p> </li> </ul>"},{"location":"phase-3/lab22a/#i-quick-checklist-for-students-copypaste","title":"I. Quick checklist for students (copy/paste)","text":"<ol> <li>Install Terraform &amp; AWS CLI \u2014 verify <code>terraform -version</code> and <code>aws --version</code>.</li> <li>Create SSH key pair locally: <code>ssh-keygen -t rsa -b 4096 -f ~/.ssh/techops_key</code>.</li> <li>Create AWS IAM user with programmatic access, note access key &amp; secret.</li> <li><code>aws configure --profile techops</code> (or set env vars).</li> <li>Clone this lab folder and create/modify <code>dev.tfvars</code>.</li> <li><code>terraform init</code> \u2192 <code>terraform plan -var-file=\"dev.tfvars\"</code> \u2192 <code>terraform apply -var-file=\"dev.tfvars\"</code>.</li> <li><code>terraform output instance_public_ip</code> \u2192 visit web page \u2192 <code>ssh -i ~/.ssh/techops_key ec2-user@&lt;ip&gt;</code>.</li> <li><code>terraform destroy -var-file=\"dev.tfvars\"</code> when done.</li> </ol>"},{"location":"phase-3/lab23/","title":"Lab 23: Connecting to Docker Swarm Manager &amp; Workers and Joining the Cluster","text":"<p>Objective</p> <p>By the end of this section you will:</p> <ul> <li>Initialize Docker Swarm on the manager node.</li> <li>Connect worker nodes to the manager.</li> <li>Verify that the cluster is up and running.</li> <li>Continue with service creation, scaling, and updating.</li> </ul>"},{"location":"phase-3/lab23/#initialize-the-swarm-on-the-manager-node","title":"Initialize the Swarm on the Manager Node","text":"Using PuTTY (Windows)Using Windows Terminal (OpenSSH) <ol> <li>Open PuTTY.</li> <li> <p>In the Host Name (or IP address) box, enter the Public IP of the Manager node.</p> </li> <li> <p>Example: <code>3.110.25.200</code></p> </li> <li>In Connection \u2192 Data, set the login username to <code>ubuntu</code> (for Ubuntu AMI).</li> <li> <p>In Connection \u2192 SSH \u2192 Auth, browse to your private key (.ppk) file.</p> </li> <li> <p>If you only have <code>.pem</code> from AWS, first convert it to <code>.ppk</code> using PuTTYgen.</p> </li> <li>Click Open \u2192 accept the warning \u2192 log in.</li> <li>Once logged in, run:</li> </ol> <pre><code>docker swarm init --advertise-addr &lt;manager_private_ip&gt;\n</code></pre> <p>Replace <code>&lt;manager_private_ip&gt;</code> with the private IP address of the manager (shown in AWS console). Example:</p> <pre><code>docker swarm init --advertise-addr 10.0.1.10\n</code></pre> <ol> <li>Open Windows Terminal</li> <li>Navigate to the folder with your AWS key (<code>.pem</code>). Example:</li> </ol> <p><pre><code>cd C:\\Users\\YourName\\Downloads\n</code></pre> 3. Connect to the Manager using SSH:</p> <pre><code>ssh -i mykey.pem ubuntu@&lt;manager_public_ip&gt;\n</code></pre> <p>Example:</p> <p><pre><code>ssh -i mykey.pem ubuntu@3.110.25.200\n</code></pre> 4. Once logged in, run:</p> <pre><code>docker swarm init --advertise-addr &lt;manager_private_ip&gt;\n</code></pre> <p>Example:</p> <pre><code>docker swarm init --advertise-addr 10.0.1.10\n</code></pre> <p>\u2705 Output: You will see a message like this:</p> <pre><code>Swarm initialized: current node (abcd1234...) is now a manager.\n\nTo add a worker to this swarm, run the following command:\n\n    docker swarm join --token SWMTKN-1-xyz &lt;manager_private_ip&gt;:2377\n</code></pre> <p>\ud83d\udc49 Copy the entire <code>docker swarm join</code> command. You\u2019ll use it on the worker nodes.</p>"},{"location":"phase-3/lab23/#add-worker-nodes-to-the-swarm","title":"Add Worker Nodes to the Swarm","text":"Using PuTTYUsing Windows Terminal (OpenSSH) <ol> <li>Open PuTTY again.</li> <li>Enter the Public IP of Worker 1.</li> <li>Set username to <code>ubuntu</code>.</li> <li>Load the same private key <code>.ppk</code> as before.</li> <li>Connect and log in.</li> <li>Run the join command you copied from the Manager:</li> </ol> <pre><code>docker swarm join --token SWMTKN-1-xyz 10.0.1.10:2377\n</code></pre> <p>Repeat the same process for Worker 2 (and any additional workers).</p> <ol> <li>From PowerShell, connect to Worker 1:</li> </ol> <p><pre><code>ssh -i mykey.pem ubuntu@&lt;worker1_public_ip&gt;\n</code></pre> 2. Run the join command:</p> <p><pre><code>docker swarm join --token SWMTKN-1-xyz 10.0.1.10:2377\n</code></pre> 3. Repeat for Worker 2:</p> <pre><code>ssh -i mykey.pem ubuntu@&lt;worker2_public_ip&gt;\ndocker swarm join --token SWMTKN-1-xyz 10.0.1.10:2377\n</code></pre>"},{"location":"phase-3/lab23/#verify-nodes-on-the-manager","title":"Verify Nodes on the Manager","text":"<p>Reconnect to the Manager node (PuTTY or SSH) and run:</p> <pre><code>docker node ls\n</code></pre> <p>\u2705 You should see:</p> <ul> <li>1 Manager (Leader).</li> <li>2 Workers (Ready).</li> </ul> <p>Example:</p> <pre><code>ID                            HOSTNAME   STATUS   AVAILABILITY   MANAGER STATUS   ENGINE VERSION\nabcd1234efgh                  manager1   Ready    Active         Leader           24.0.7\nijkl5678mnop                  worker1    Ready    Active                          24.0.7\nqrst9012uvwx                  worker2    Ready    Active                          24.0.7\n</code></pre>"},{"location":"phase-3/lab24/","title":"Lab 24: Build, Push, and Orchestrate NGINX with Docker Swarm","text":""},{"location":"phase-3/lab24/#objective","title":"\ud83e\udde0 Objective","text":"<p>By the end of this lab, you will be able to:</p> <ul> <li>Build a custom Docker image with NGINX and a custom homepage.</li> <li>Push the image to Docker Hub.</li> <li>Deploy and manage the image as a Swarm service on the Manager node.</li> <li>Scale replicas up and down, and update the service with a new version.</li> </ul>"},{"location":"phase-3/lab24/#prerequisites","title":"\ud83d\udd27 Prerequisites","text":"<ul> <li>Docker Swarm initialized with 1 Manager and 2 Workers (from Lab 23).</li> <li>A Docker Hub account.</li> <li>Internet access from the Manager node.</li> </ul>"},{"location":"phase-3/lab24/#step-1-create-a-project-folder-on-manager-node","title":"\ud83d\udda5\ufe0f Step 1: Create a Project Folder on Manager Node","text":"<p>SSH into the Manager node (using PuTTY or Windows Terminal + SSH). Then run:</p> <pre><code>mkdir ~/nginx-lab\ncd ~/nginx-lab\n</code></pre>"},{"location":"phase-3/lab24/#step-2-create-custom-indexhtml","title":"\ud83d\udcdd Step 2: Create Custom <code>index.html</code>","text":"<p>Create a simple homepage file:</p> <pre><code>cat &gt; index.html &lt;&lt;'EOF'\n&lt;!doctype html&gt;\n&lt;html&gt;\n  &lt;head&gt;&lt;title&gt;Lab 24 - NGINX v1&lt;/title&gt;&lt;/head&gt;\n  &lt;body&gt;\n    &lt;h1&gt;Welcome to Lab 24!&lt;/h1&gt;\n    &lt;p&gt;This is Version 1 of our NGINX service running on Docker Swarm.&lt;/p&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\nEOF\n</code></pre>"},{"location":"phase-3/lab24/#step-3-create-dockerfile","title":"\u2699\ufe0f Step 3: Create Dockerfile","text":"<pre><code>cat &gt; Dockerfile &lt;&lt;'EOF'\nFROM nginx:stable-alpine\nCOPY index.html /usr/share/nginx/html/index.html\nEXPOSE 80\nEOF\n</code></pre>"},{"location":"phase-3/lab24/#step-4-build-docker-image","title":"\ud83c\udfd7\ufe0f Step 4: Build Docker Image","text":"<p>Replace <code>yourhubuser</code> with your actual Docker Hub username:</p> <pre><code>docker build -t yourhubuser/lab24-nginx:v1 .\n</code></pre> <p>Verify the image:</p> <pre><code>docker images | grep lab24-nginx\n</code></pre>"},{"location":"phase-3/lab24/#step-5-push-image-to-docker-hub","title":"\ud83d\ude80 Step 5: Push Image to Docker Hub","text":"<p>Login and push:</p> <pre><code>docker login\ndocker push yourhubuser/lab24-nginx:v1\n</code></pre> <p>Check on Docker Hub \u2192 you should see <code>lab24-nginx</code> repo with tag <code>v1</code>.</p>"},{"location":"phase-3/lab24/#step-6-deploy-service-on-docker-swarm","title":"\ud83c\udf10 Step 6: Deploy Service on Docker Swarm","text":"<p>On Manager:</p> <pre><code>docker service create \\\n  --name lab24-service \\\n  --replicas 2 \\\n  --publish published=8080,target=80 \\\n  yourhubuser/lab24-nginx:v1\n</code></pre> <p>Check status:</p> <pre><code>docker service ls\ndocker service ps lab24-service\n</code></pre> <p>Test in browser:</p> <pre><code>http://&lt;manager_public_ip&gt;:8080\n</code></pre>"},{"location":"phase-3/lab24/#step-7-scale-service","title":"\ud83d\udcc8 Step 7: Scale Service","text":"<p>Scale up to 5 replicas:</p> <pre><code>docker service scale lab24-service=5\n</code></pre> <p>Check distribution:</p> <pre><code>docker service ps lab24-service\n</code></pre> <p>Scale down to 2 replicas:</p> <pre><code>docker service scale lab24-service=2\n</code></pre>"},{"location":"phase-3/lab24/#step-8-update-homepage-and-create-v2-image","title":"\ud83d\udcdd Step 8: Update Homepage and Create v2 Image","text":"<p>Edit <code>index.html</code>:</p> <pre><code>cat &gt; index.html &lt;&lt;'EOF'\n&lt;!doctype html&gt;\n&lt;html&gt;\n  &lt;head&gt;&lt;title&gt;Lab 24 - NGINX v2&lt;/title&gt;&lt;/head&gt;\n  &lt;body&gt;\n    &lt;h1&gt;Welcome back to Lab 24!&lt;/h1&gt;\n    &lt;p&gt;This is Version 2, showing a rolling update in Docker Swarm.&lt;/p&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\nEOF\n</code></pre> <p>Build &amp; push new version:</p> <pre><code>docker build -t yourhubuser/lab24-nginx:v2 .\ndocker push yourhubuser/lab24-nginx:v2\n</code></pre>"},{"location":"phase-3/lab24/#step-9-rolling-update-service","title":"\ud83d\udd04 Step 9: Rolling Update Service","text":"<p>Update service to new version:</p> <pre><code>docker service update --image yourhubuser/lab24-nginx:v2 lab24-service\n</code></pre> <p>Check update status:</p> <pre><code>docker service ps lab24-service\n</code></pre> <p>Refresh browser \u2192 you should now see Version 2 homepage.</p>"},{"location":"phase-3/lab24/#step-10-cleanup","title":"\ud83e\uddf9 Step 10: Cleanup","text":"<pre><code>docker service rm lab24-service\ndocker image rm yourhubuser/lab24-nginx:v1 yourhubuser/lab24-nginx:v2\n</code></pre>"},{"location":"phase-3/lab24/#terraform-clean-up","title":"Terraform Clean up","text":"<p>IMPORTANT CLEAN UP AWS USING TERRAFORM</p> <p>Complete the next lab to destroy all AWS resources to avoid cost on your credit cards</p>"},{"location":"phase-3/lab24/#troubleshooting-tips","title":"Troubleshooting tips","text":"<ul> <li>If you entered wrong <code>yourhubuser</code> during lab copy/paste then <ul> <li><code>docker service ls</code> You\u2019ll see your service (e.g., lab24-service) with replicas 0/2 or stuck in Pending state.</li> <li><code>docker service rm lab24-service</code></li> <li>Verify: <code>docker service ls</code></li> </ul> </li> </ul>"},{"location":"phase-3/lab24/#what-you-learned","title":"\ud83d\udd0e What You Learned","text":"<ul> <li>How to build Docker images directly on the Manager node.</li> <li>How to push images to Docker Hub for use across the Swarm cluster.</li> <li>How to orchestrate services with scaling and rolling updates.</li> </ul>"},{"location":"phase-3/lab25/","title":"Lab 25: Destroying All Terraform Resources","text":"<ol> <li>Go to your Terraform project folder (where <code>main.tf</code> is located):</li> </ol> <pre><code>cd ~/swarm-terraform\n</code></pre> <ol> <li>Initialize (only needed if not already initialized):</li> </ol> <pre><code>terraform init\n</code></pre> <ol> <li>Run destroy with confirmation prompt:</li> </ol> <pre><code>terraform destroy\n</code></pre> <p>Terraform will show you a plan of what will be deleted and ask:</p> <pre><code>Do you really want to destroy all resources?  Enter a value: yes\n</code></pre> <ol> <li>To skip the confirmation prompt (use with care):</li> </ol> <pre><code>terraform destroy -auto-approve\n</code></pre> <p>\u2705 This will remove:</p> <ul> <li>EC2 instances (manager + workers)</li> <li>Security groups</li> <li>VPC, subnets, route tables, internet gateway</li> <li>Key pair (if created by Terraform)</li> </ul> <p>\u26a0\ufe0f Important for students:</p> <ul> <li>Always run <code>terraform destroy</code> from the same folder where you ran <code>terraform apply</code> (so it uses the same <code>terraform.tfstate</code>).</li> <li>Double-check the AWS Console afterwards to ensure no stray resources (like EBS volumes or elastic IPs) remain.</li> </ul>"},{"location":"phase-3/lab26/","title":"Lab 26: Ansible Setup and Configuration Management - 1","text":"<p>Objective</p> <ul> <li>Install Ansible on the control node (local VM or cloud instance).</li> <li>Configure passwordless SSH authentication.</li> <li>Run first Ansible command.</li> <li>Write and execute a simple playbook to deploy a web server.</li> </ul>"},{"location":"phase-3/lab26/#step-1-install-ansible-on-control-node","title":"Step 1: Install Ansible on Control Node","text":"On Linux (Ubuntu)On CentOS/RHELOn macOS (Homebrew)On Windows <pre><code>sudo apt update\nsudo apt install ansible -y\nansible --version\n</code></pre> <pre><code>sudo yum install epel-release -y\nsudo yum install ansible -y\n</code></pre> <pre><code>brew install ansible\n</code></pre> <ul> <li>Use WSL2 (Ubuntu) and follow Linux steps.</li> <li>Or use Docker container:</li> </ul> <pre><code>docker run -it --rm williamyeh/ansible ansible --version\n</code></pre>"},{"location":"phase-3/lab26/#step-2-configure-target-nodes","title":"Step 2: Configure Target Node(s)","text":"<ul> <li>Create a second VM (Ubuntu/EC2) as managed node.</li> <li>Ensure it has an SSH server installed:</li> </ul> <pre><code>sudo apt install openssh-server -y\n</code></pre>"},{"location":"phase-3/lab26/#step-3-setup-ssh-key-authentication","title":"Step 3: Setup SSH Key Authentication","text":"<p>On control node:</p> <pre><code>ssh-keygen -t rsa -b 4096\nssh-copy-id your_user_name@target-node-ip\n\n# For Virtual Machines on AWS and using Amazon Linux the username is 'ec2-user`\n# For Virtual Machines on AWS and using Ubunut the username is 'ubuntu'\n</code></pre> <p>Test:</p> <pre><code>ssh your_user_name@target-node-ip\n</code></pre> <p>(No password should be asked now \u2705).</p>"},{"location":"phase-3/lab26/#step-4-verify-setup-with-ansible-ad-hoc-command","title":"Step 4: Verify Setup with Ansible Ad-hoc Command","text":"<p>Create an inventory file <code>inventory.ini</code>:</p> <pre><code>[web]\n192.168.1.20 ansible_user=ubuntu\n</code></pre> <p>Run ping:</p> <pre><code>ansible -i inventory.ini all -m ping\n</code></pre> <p>Expected output:</p> <pre><code>192.168.1.20 | SUCCESS =&gt; {\n    \"changed\": false,\n    \"ping\": \"pong\"\n}\n</code></pre>"},{"location":"phase-3/lab26/#step-5-write-a-simple-playbook","title":"Step 5: Write a Simple Playbook","text":"<p>File: <code>webserver.yml</code></p> <pre><code>---\n- name: Install and start Apache web server\n  hosts: web\n  become: yes\n  tasks:\n    - name: Install Apache\n      apt:\n        name: apache2\n        state: present\n        update_cache: yes\n\n    - name: Ensure Apache is running\n      service:\n        name: apache2\n        state: started\n        enabled: yes\n</code></pre> <p>Run it:</p> <pre><code>ansible-playbook -i inventory.ini webserver.yml\n</code></pre>"},{"location":"phase-3/lab26/#step-6-verify-web-server","title":"Step 6: Verify Web Server","text":"<ul> <li>On target node:</li> </ul> <p><pre><code>systemctl status apache2\n</code></pre> * From browser:   <code>http://&lt;target-node-ip&gt;</code> \u2192 should show Apache default page.</p> <p>\u2705 Checkpoint: Students must take a screenshot of the Apache welcome page.</p>"},{"location":"phase-3/lab27/","title":"Lab 27: Ansible - Managing Inventory &amp; Roles","text":"<p>Objective</p> <ul> <li>Use static inventory with multiple nodes.</li> <li>Create a role for database installation.</li> <li>Apply the role via a playbook.</li> </ul>"},{"location":"phase-3/lab27/#step-0-deploy-another-vm","title":"Step 0: Deploy another VM","text":"<p>Setup SSH Key Authentication same as before for new VM</p> <p>On control node:</p> <pre><code>ssh-copy-id your_user_name@target-node-ip\n\n# For Virtual Machines on AWS and using Amazon Linux the username is 'ec2-user`\n# For Virtual Machines on AWS and using Ubunut the username is 'ubuntu'\n</code></pre> <p>Test:</p> <pre><code>ssh your_user_name@target-node-ip\n</code></pre> <p>(No password should be asked now \u2705).</p>"},{"location":"phase-3/lab27/#step-1-create-static-inventory-with-groups","title":"Step 1: Create Static Inventory with Groups","text":"<p>File: <code>inventory.ini</code></p> <pre><code>[web]\n192.168.1.20 ansible_user=ubuntu\n\n[db]\n192.168.1.30 ansible_user=ubuntu\n</code></pre>"},{"location":"phase-3/lab27/#step-2-create-a-role-for-database-server","title":"Step 2: Create a Role for Database Server","text":"<p>Use Ansible Galaxy init:</p> <pre><code>ansible-galaxy init roles/dbserver\n</code></pre> <p>This creates:</p> <pre><code>roles/dbserver/\n\u251c\u2500\u2500 defaults/main.yml\n\u251c\u2500\u2500 handlers/main.yml\n\u251c\u2500\u2500 tasks/main.yml\n\u251c\u2500\u2500 templates/\n\u251c\u2500\u2500 vars/main.yml\n\u2514\u2500\u2500 ...\n</code></pre>"},{"location":"phase-3/lab27/#step-3-define-database-tasks","title":"Step 3: Define Database Tasks","text":"<p>Edit <code>roles/dbserver/tasks/main.yml</code>:</p> <pre><code>---\n- name: Install MySQL\n  apt:\n    name: mysql-server\n    state: present\n    update_cache: yes\n\n- name: Ensure MySQL service is running\n  service:\n    name: mysql\n    state: started\n    enabled: yes\n</code></pre>"},{"location":"phase-3/lab27/#step-4-create-playbook-to-use-role","title":"Step 4: Create Playbook to Use Role","text":"<p>File: <code>dbserver.yml</code></p> <pre><code>---\n- name: Configure Database Server\n  hosts: db\n  become: yes\n  roles:\n    - dbserver\n</code></pre> <p>Run:</p> <pre><code>ansible-playbook -i inventory.ini dbserver.yml\n</code></pre>"},{"location":"phase-3/lab27/#step-5-verify-database-setup","title":"Step 5: Verify Database Setup","text":"<p>On DB node:</p> <pre><code>systemctl status mysql\nmysql --version\n</code></pre> <p>Expected: MySQL running.</p>"},{"location":"resources/labs-intro/","title":"Labs Introduction \u2014 IT Infrastructure &amp; DevOps","text":"<p>Welcome to the lab environment of this course.  </p> <p>Labs are the core of your learning journey: theory builds concepts, but labs build skills and confidence.  </p> <p>In this course, you will not just complete exercises \u2014 you will act as employees in a simulated tech company called TechOps Inc. </p> <p>You\u2019ll work in teams of 8~10 (your own mini-company), but every student is required to complete all labs individually to master the skills.</p>"},{"location":"resources/labs-intro/#scenario-narrative","title":"\ud83c\udfad Scenario Narrative","text":"<p>You have been hired into TechOps Inc. as part of the Platform &amp; DevOps Division. TechOps Inc. provides IT infrastructure, cloud, and DevOps solutions to clients.  </p> <p>Your mission: - Individually: Build your skills by completing every lab yourself. - As a company (team): Integrate individual work into checkpoint deliverables and, eventually, a final enterprise-ready environment.  </p> <p>Think of it like this:</p> <ul> <li>Individual labs = employee training &amp; proof-of-skill. </li> <li>Team checkpoints = project milestones delivered to management. </li> </ul>"},{"location":"resources/labs-intro/#team-composition","title":"\ud83e\uddd1\u200d\ud83e\udd1d\u200d\ud83e\uddd1 Team Composition","text":"<p>Each team = one subsidiary company of TechOps Inc. (10 members each).  </p> <p>Roles give special focus during integration, but every student must do all labs individually.  </p> <p>Suggested roles:</p> <ul> <li>Project Lead (Scrum Master) \u2014 manages Taiga board, sprint planning.  </li> <li>Cloud Architect \u2014 AWS infra (VPC, EC2, storage).  </li> <li>System Administrator \u2014 VM setup, baseline OS, security hardening.  </li> <li>DevOps Engineers (2x) \u2014 CI/CD pipelines, IaC automation.  </li> <li>Developers (2x) \u2014 containerize apps, basic testing.  </li> <li>Security Engineer \u2014 IAM, secrets, compliance.  </li> <li>Monitoring Specialist \u2014 Prometheus, Grafana dashboards.  </li> <li>Storage/Network Engineer \u2014 NAS, SAN, networking integration.  </li> </ul> <p>Note</p> <p>Everyone completes all labs individually. Roles matter only when your company integrates deliverables at checkpoints.  </p>"},{"location":"resources/labs-intro/#lab-workflow","title":"\ud83d\udee0\ufe0f Lab Workflow","text":"<p>Preparation:  </p> <ul> <li>Read the session guide before class.  </li> <li>Install or update tools (VirtualBox, Docker, AWS CLI, etc.).  </li> </ul> <p>Execution </p> <ul> <li>Follow the lab guide.  </li> <li>Document steps, configs, and troubleshooting.  </li> </ul> <p>Documentation </p> <ul> <li>Maintain an individual lab notebook (Markdown/Google Doc).  </li> <li>Capture objectives, steps, screenshots, outputs, and reflections.  </li> </ul> <p>Integration (Team) </p> <ul> <li>At checkpoints, the company integrates work into a unified deliverable.  </li> <li>Example: Everyone builds a SAN individually \u2192 team Storage/Network Engineer ensures the company SAN integrates across all VMs.  </li> </ul>"},{"location":"resources/labs-intro/#checkpoints-milestones","title":"\ud83d\udcca Checkpoints &amp; Milestones","text":"<p>Labs are grouped into phases, with checkpoints at the end:</p> <ol> <li>Checkpoint 1 (Session 9): Infra Blueprint \u2014 baseline VMs, data center design, NAS, SAN.  </li> <li>Checkpoint 2 (Session 13): Hybrid Infra \u2014 VM cluster + AWS VPC + storage integration.  </li> <li>Checkpoint 3 (Session 17): CI/CD-ready Infra \u2014 Docker app + Kubernetes + IaC.  </li> <li>Checkpoint 4 (Session 20): Ops Dashboard \u2014 CI/CD + monitoring.  </li> <li>Final Demo (Session 23): Enterprise-ready infra \u2014 integrated, secure, and highly available.  </li> </ol>"},{"location":"resources/labs-intro/#lab-notebook-example","title":"\ud83d\udcdd Lab Notebook Example","text":"<p>Session 6: IT Infrastructure Overview - Objective: Create baseline Ubuntu VM with snapshot. - Steps:   1. Download Ubuntu LTS ISO.   2. Create VM (2 vCPU, 4GB RAM, 40GB disk).   3. Installed updates + curl, git, ssh.   4. Created snapshot <code>baseline-v1</code>. - Output:   - Screenshot of VirtualBox VM summary.   - Config file: <code>/etc/os-release</code>. - Reflection:   - First attempt failed due to missing ISO \u2192 fixed by verifying checksum.  </p>"},{"location":"resources/labs-intro/#evaluation","title":"\ud83c\udfc6 Evaluation","text":"<ul> <li>Individual labs: checked via notebooks, spot checks, and lab exam.  </li> <li>Team checkpoints: graded as deliverables, demoed in class.  </li> <li>Final demo: team integration of all skills.  </li> </ul>"},{"location":"resources/labs-intro/#key-takeaways","title":"\u2705 Key Takeaways","text":"<ul> <li>You are now employees of TechOps Inc. </li> <li>You\u2019ll work in teams of 10 (subsidiary companies).  </li> <li>Every student must complete every lab individually.  </li> <li>Roles = focus during integration, not excuses to skip labs.  </li> <li>Labs build progressively toward checkpoint milestones and the final demo.  </li> </ul>"},{"location":"resources/tools/","title":"Tools &amp; Setup Guide","text":"<p>This course relies on a mix of open-source tools and cloud free tiers. Follow this guide to prepare your workstation and accounts.</p>"},{"location":"resources/tools/#core-tools","title":"Core Tools","text":"<ul> <li>Python 3 + venv \u2192 for MkDocs &amp; site builds  </li> <li>Git &amp; GitHub \u2192 version control, submissions  </li> <li>Slack \u2192 team communication, ChatOps  </li> <li>Taiga \u2192 Agile project management (Scrum/Kanban boards)  </li> </ul>"},{"location":"resources/tools/#infrastructure-virtualization","title":"Infrastructure &amp; Virtualization","text":"<ul> <li>VirtualBox (free) or VMware Workstation Player \u2192 VM hosting  </li> <li>Ubuntu LTS ISO \u2192 baseline Linux VM  </li> <li>Windows ISO (optional) \u2192 baseline Windows VM  </li> <li>TrueNAS CORE \u2192 NAS &amp; SAN labs  </li> </ul>"},{"location":"resources/tools/#cloud","title":"Cloud","text":"<ul> <li>AWS Free Tier account \u2192 EC2, S3, VPC labs  </li> <li>MinIO \u2192 local S3-compatible object storage  </li> </ul>"},{"location":"resources/tools/#containers-devops","title":"Containers &amp; DevOps","text":"<ul> <li>Docker Desktop / Docker Engine </li> <li>Minikube + kubectl \u2192 local Kubernetes cluster  </li> <li>Helm (optional) \u2192 package manager for Kubernetes  </li> <li>Jenkins \u2192 CI/CD pipelines (or GitHub Actions alternative)  </li> <li>Ansible \u2192 configuration management, automation  </li> <li>Terraform \u2192 Infrastructure as Code for cloud provisioning  </li> </ul>"},{"location":"resources/tools/#monitoring-logging","title":"Monitoring &amp; Logging","text":"<ul> <li>Prometheus \u2192 metrics collection  </li> <li>Grafana \u2192 dashboards &amp; visualizations  </li> <li>ELK Stack (optional) \u2192 logs aggregation  </li> </ul>"},{"location":"resources/tools/#security","title":"Security","text":"<ul> <li>AWS IAM \u2192 users, roles, policies  </li> <li>Vault (HashiCorp) (optional) \u2192 secrets management  </li> <li>OpenVAS or similar (optional) \u2192 vulnerability scanning  </li> </ul>"},{"location":"resources/tools/#suggested-folder-structure-per-team-repo","title":"Suggested Folder Structure (per team repo)","text":"<pre><code>team-repo/\n\u251c\u2500\u2500 infra/ # VM configs, Terraform, Ansible playbooks\n\u251c\u2500\u2500 app/ # Sample app (containerized)\n\u251c\u2500\u2500 cicd/ # Jenkins pipelines, workflows\n\u251c\u2500\u2500 monitoring/ # Prometheus, Grafana configs\n\u251c\u2500\u2500 security/ # IAM policies, hardening scripts\n\u2514\u2500\u2500 docs/ # Lab notes, screenshots, diagrams\n</code></pre>"},{"location":"resources/tools/#pre-course-checklist","title":"Pre-course Checklist","text":"<ul> <li> Install VirtualBox (or VMware Workstation)  </li> <li> Download Ubuntu LTS ISO  </li> <li> Create GitHub account  </li> <li> Create Slack account (invite link will be provided)  </li> <li> Create Taiga account (invite link will be provided)  </li> <li> Register AWS Free Tier account  </li> <li> Install Docker + Minikube + kubectl  </li> </ul>"},{"location":"roadmap/roadmap/","title":"Course Roadmap \u2014 IT Infrastructure &amp; DevOps (PG-DITISS Aug 2025)","text":"<p>Welcome to the Course Roadmap. This page gives you a high-level overview of all sessions, showing what you\u2019ll learn in each, before diving into the detailed session pages.</p>"},{"location":"roadmap/roadmap/#phase-0-foundations-agile-devops-mindset","title":"Phase 0 \u2013 Foundations: Agile &amp; DevOps Mindset","text":"<p>Target Dates</p> <ul> <li>Start Date: 04-Oct-2025</li> <li>End Date: 04-Oct-2025</li> </ul> <p>Phase 0 lays the foundation for the course by shifting the students\u2019 mindset from traditional IT delivery to Agile and DevOps-oriented thinking.</p> <ul> <li>Students begin with Agile principles and frameworks (Scrum, Kanban, XP) to internalize iterative, customer-focused development.</li> <li>They then connect these ideas with Lean practices to understand waste reduction, value streams, and continuous improvement.</li> <li>The lab track is designed to immediately immerse students in real-world Agile environments:<ul> <li>Lab 00 gets them onboarded with Slack, Taiga, and GitHub\u2014the same tools used in enterprise DevOps teams.</li> <li>Lab 01 simulates a Scrum sprint, ensuring they grasp backlog creation, ceremonies, and roles.</li> <li>Lab 02 introduces Kanban workflows to highlight flow and WIP limits.</li> </ul> </li> </ul> <p>By the end of Phase 0, students are \u201cworkplace ready\u201d with collaboration platforms configured and hands-on experience in Agile project execution. This prepares them to enter the infrastructure and DevOps-heavy sessions in later phases with the right team-based, iterative mindset.</p>"},{"location":"roadmap/roadmap/#phase-1-data-center-management","title":"Phase 1 \u2013 Data Center Management","text":"<p>Target Dates</p> <ul> <li>Start Date: 05-Oct-2025</li> <li>End Date: 05-Oct-2025</li> </ul> <p>Phase 1 dives into Data Center Management, equipping students with the knowledge to design, evaluate, and operate enterprise-class data centers.</p> <ul> <li> <p>Part A introduces data center management fundamentals: architecture, physical requirements, power and cooling systems, networking, site selection, and budget considerations. Students learn what constitutes a \u201cgood design\u201d and how classification standards like Uptime Institute Tiers guide resilience and availability.</p> </li> <li> <p>Part B focuses on the infrastructure inside the data center, covering modular cabling, distribution points, WAN connectivity, NOC operations, and security measures (physical, logical, and internet-facing). Students also explore consolidation strategies, server design, capacity planning, and disaster recovery.</p> </li> </ul> <p>The phase ends with security guidelines, source security issues, and system administration best practices, culminating in automation approaches to streamline operations.</p> <p>By completing Phase 1, students will be able to design and evaluate a data center for TechOps Inc., considering cost, performance, and resilience trade-offs\u2014a crucial foundation before moving into virtualization, cloud, and DevOps practices in later phases.</p>"},{"location":"roadmap/roadmap/#phase-2-virtualization-cloud","title":"Phase 2 \u00b7 Virtualization &amp; Cloud","text":"<p>Target Dates</p> <ul> <li>Start Date: 06-Oct-2025</li> <li>End Date: 12-Oct-2025</li> </ul> <p>Phase 2 transitions students from traditional infrastructure (Phase 1) to virtualization and cloud environments.</p> <p>Virtualization: Students begin with concepts, hypervisors, OS virtualization, and clustering. Labs 03\u201304 provide hands-on VM deployment and networking with VirtualBox.</p> <p>SAN: They then explore enterprise storage with SANs, including high availability, redundancy, and performance testing (Labs 05\u201309).</p> <p>Cloud Computing: The final and largest part of Phase 2 covers public and private clouds, starting with OpenStack and SDN, then moving to AWS/Azure/GCP. Students complete labs in cloud migration, monitoring, and disaster recovery (Labs 10\u201315).</p> <p>By the end of Phase 2, students can:</p> <ul> <li>Build and manage virtualized infrastructure.</li> <li>Configure SAN storage systems with high availability.</li> <li>Deploy workloads to public cloud platforms.</li> <li>Automate, monitor, and migrate resources across hybrid environments.</li> </ul> <p>This phase builds the practical foundation for DevOps workflows, setting the stage for CI/CD, containers, and automation in Phase 3.</p>"},{"location":"roadmap/roadmap/#phase-3-devops","title":"Phase 3 \u00b7 DevOps","text":"<p>Target Dates</p> <ul> <li>Start Date: 13-Oct-2025</li> <li>End Date: 19-Oct-2025</li> </ul> <p>Phase 3 is the core DevOps implementation phase, where students move from infrastructure and cloud (Phase 2) into automation, orchestration, and continuous delivery.</p> <ul> <li> <p>Foundations: Students learn DevOps culture, lifecycle, and foundational tools like Git, Jenkins, Docker, and Kubernetes. Labs 16\u201321 ensure hands-on tool familiarity.</p> </li> <li> <p>IaC with Terraform: Students provision real cloud infrastructure (EC2, VPCs) using Terraform, practicing declarative automation (Labs 22\u201323).</p> </li> <li> <p>Containers &amp; Microservices: Students build and orchestrate containerized applications with Kubernetes, simulating real enterprise microservices deployments (Labs 24\u201325).</p> </li> <li> <p>Configuration Management: Students automate server provisioning and configuration using Ansible (Labs 26\u201327).</p> </li> </ul> <p>By the end of Phase 3, students can:</p> <ul> <li>Set up complete DevOps toolchains.</li> <li>Automate cloud infrastructure provisioning.</li> <li>Deploy and scale microservices with Kubernetes.</li> <li>Manage configurations using Ansible.</li> </ul> <p>This phase makes them job-ready as DevOps engineers, integrating tools, automation, and real-world workflows.</p>"},{"location":"roadmap/syllabus/","title":"Syllabus","text":""},{"location":"roadmap/syllabus/#phase-0-sessions-labs","title":"Phase 0 - Sessions &amp; Labs","text":""},{"location":"roadmap/syllabus/#session-1-agile","title":"Session 1: Agile","text":"<p>Objectives</p> <ul> <li>Understand the principles of Agile.</li> <li>Explore the Agile Manifesto and its 12 principles.</li> <li>Compare Agile with traditional (waterfall) methodologies.</li> </ul> <p>Topics</p> <ul> <li>Origins and need for Agile.</li> <li>Agile Manifesto values.</li> <li>Benefits and challenges in adopting Agile.</li> </ul>"},{"location":"roadmap/syllabus/#session-2-agile-methodologies","title":"Session 2: Agile Methodologies","text":"<p>Objectives</p> <ul> <li>Learn different Agile frameworks and practices.</li> <li>Distinguish between Scrum, Kanban, and Extreme Programming (XP).</li> <li>Understand where and how to apply each methodology.</li> </ul> <p>Topics</p> <ul> <li>Scrum roles, ceremonies, and artifacts.</li> <li>Kanban principles and visual workflow.</li> <li>XP practices (pair programming, TDD, continuous integration).</li> <li>Agile at scale (SAFe, LeSS).</li> </ul>"},{"location":"roadmap/syllabus/#session-3-lean-in-devops","title":"Session 3: Lean in DevOps","text":"<p>Objectives</p> <ul> <li>Connect Lean principles to Agile and DevOps practices.</li> <li>Understand waste reduction and continuous improvement.</li> <li>Apply Lean thinking to IT and software delivery.</li> </ul> <p>Topics</p> <ul> <li>The 5 Lean principles.</li> <li>Eliminating waste in software processes.</li> <li>Value stream mapping for DevOps pipelines.</li> <li>Case studies: Lean transformation in IT.</li> </ul>"},{"location":"roadmap/syllabus/#session-4-understanding-labs","title":"Session 4: Understanding Labs","text":"<p>Objectives</p> <ul> <li>Familiarize with lab environment, tools, and submission workflow.</li> <li>Learn how labs integrate into Agile and DevOps practices.</li> </ul> <p>Topics</p> <ul> <li>Lab submission via GitHub.</li> <li>Lab evaluation process (peer + instructor review).</li> <li>Setting up collaboration tools (Slack/Taiga).</li> </ul>"},{"location":"roadmap/syllabus/#lab-00-environment-setup","title":"Lab 00: Environment Setup","text":"<p>Goal: Set up collaboration and task management tools.</p> <p>Tasks</p> <ul> <li>Join TechOps Inc. Slack workspace.</li> <li>Set up Taiga board for Agile project management.</li> <li>Create GitHub repo for lab submissions.</li> <li>Expected Outcome</li> <li>Students onboarded with communication and project tracking tools.</li> </ul>"},{"location":"roadmap/syllabus/#lab-01-agile-project-simulation","title":"Lab 01: Agile Project Simulation","text":"<p>Goal: Simulate a Scrum sprint using Taiga.</p> <p>Tasks</p> <ul> <li>Define product backlog with at least 5 user stories.</li> <li>Create sprint backlog and assign tasks.</li> <li>Run a sprint planning session.</li> <li>Conduct a daily standup (mock).</li> <li>Expected Outcome</li> <li>Students experience Agile ceremonies and backlog management.</li> </ul>"},{"location":"roadmap/syllabus/#lab-02-kanban-workflow","title":"Lab 02: Kanban Workflow","text":"<p>Goal: Implement a Kanban workflow.</p> <p>Tasks</p> <ul> <li>Set up Kanban board in Taiga.</li> <li>Define WIP (Work In Progress) limits.</li> <li>Track at least one feature from \u201cTo Do\u201d \u2192 \u201cIn Progress\u201d \u2192 \u201cDone.\u201d</li> <li>Expected Outcome</li> <li>Students understand flow-based Agile execution and bottleneck visualization.</li> </ul>"},{"location":"roadmap/syllabus/#checkpoints-quizzes","title":"Checkpoints &amp; Quizzes","text":"<ul> <li>Checkpoint 1: Submit GitHub repo link and Taiga board screenshot after Lab 00.</li> <li>Quiz 1: Multiple-choice on Agile Manifesto values and Lean principles.</li> <li>Checkpoint 2: Peer review of Lab 01 backlog and sprint plan.</li> <li>Quiz 2: Scenario-based questions on choosing Scrum vs Kanban.</li> </ul>"},{"location":"roadmap/syllabus/#phase-1-data-center-management","title":"Phase 1 \u2013 Data Center Management","text":""},{"location":"roadmap/syllabus/#part-a-data-center-management","title":"Part A: Data Center Management","text":""},{"location":"roadmap/syllabus/#session-1-overview","title":"Session 1: Overview","text":"<p>Objectives</p> <ul> <li>Define the role and importance of data centers in IT infrastructure.</li> <li>Understand types of data centers (enterprise, colocation, cloud).</li> </ul> <p>Topics</p> <ul> <li>What is a Data Center?</li> <li>Evolution of data centers.</li> <li>Core functions and services.</li> </ul>"},{"location":"roadmap/syllabus/#session-2-data-center-architecture","title":"Session 2: Data Center Architecture","text":"<p>Objectives</p> <ul> <li>Learn the high-level architecture of a data center.</li> <li>Identify tiers of components (compute, storage, networking).</li> </ul> <p>Topics</p> <ul> <li>Logical vs. physical design.</li> <li>Standard reference architectures.</li> <li>Redundancy and fault tolerance.</li> </ul>"},{"location":"roadmap/syllabus/#session-3-physical-area","title":"Session 3: Physical Area","text":"<p>Objectives</p> <ul> <li>Understand space requirements for servers, racks, and facilities.</li> <li>Plan floor layouts for scalability and safety.</li> </ul> <p>Topics</p> <ul> <li>Rack layout and hot/cold aisles.</li> <li>Raised floor vs slab floor.</li> <li>Floor space utilization metrics.</li> </ul>"},{"location":"roadmap/syllabus/#session-4-power","title":"Session 4: Power","text":"<p>Objectives</p> <ul> <li>Learn power distribution in data centers.</li> <li>Identify redundancy strategies (UPS, generators).</li> </ul> <p>Topics</p> <ul> <li>Power Usage Effectiveness (PUE).</li> <li>UPS systems, backup generators.</li> <li>Dual power feeds and fault tolerance.</li> </ul>"},{"location":"roadmap/syllabus/#session-5-cooling","title":"Session 5: Cooling","text":"<p>Objectives</p> <ul> <li>Explore cooling mechanisms and efficiency.</li> <li>Design airflow for optimal performance.</li> </ul> <p>Topics</p> <ul> <li>CRAC units and liquid cooling.</li> <li>Hot aisle/cold aisle containment.</li> <li>Cooling efficiency metrics.</li> </ul>"},{"location":"roadmap/syllabus/#session-6-networks","title":"Session 6: Networks","text":"<p>Objectives</p> <ul> <li>Understand networking inside a data center.</li> <li>Design connectivity and traffic flow.</li> </ul> <p>Topics</p> <ul> <li>LAN and SAN.</li> <li>Top-of-rack vs. end-of-row switches.</li> <li>Core, aggregation, and access layers.</li> </ul>"},{"location":"roadmap/syllabus/#session-7-weight-considerations","title":"Session 7: Weight Considerations","text":"<p>Objectives</p> <ul> <li>Learn about structural load constraints in data centers.</li> <li>Plan safe rack and equipment placement.</li> </ul> <p>Topics</p> <ul> <li>Floor loading capacities.</li> <li>Equipment weight distribution.</li> </ul>"},{"location":"roadmap/syllabus/#session-8-geo-location","title":"Session 8: Geo-Location","text":"<p>Objectives</p> <ul> <li>Evaluate site selection criteria for data centers.</li> <li>Understand geographic, climatic, and risk factors.</li> </ul> <p>Topics</p> <ul> <li>Seismic zones, flood zones.</li> <li>Connectivity to ISPs.</li> <li>Proximity to users and compliance regulations.</li> </ul>"},{"location":"roadmap/syllabus/#session-9-budget","title":"Session 9: Budget","text":"<p>Objectives</p> <ul> <li>Understand CAPEX vs OPEX in data center design.</li> <li>Balance cost with performance and redundancy.</li> </ul> <p>Topics</p> <ul> <li>Budgeting for facilities, equipment, staff.</li> <li>ROI considerations.</li> </ul>"},{"location":"roadmap/syllabus/#session-10-good-design","title":"Session 10: Good Design","text":"<p>Objectives</p> <ul> <li>Apply design best practices.</li> <li>Evaluate trade-offs in design choices.</li> </ul> <p>Topics</p> <ul> <li>Modularity and scalability.</li> <li>Efficiency vs redundancy.</li> <li>Emerging design trends.</li> </ul>"},{"location":"roadmap/syllabus/#session-11-classification-ratings","title":"Session 11: Classification &amp; Ratings","text":"<p>Objectives</p> <ul> <li>Learn about data center standards and tiers.</li> <li>Classify data centers based on uptime and resilience.</li> </ul> <p>Topics</p> <ul> <li>Uptime Institute Tier I\u2013IV.</li> <li>ISO/IEC standards.</li> <li>Energy Star and green data center metrics.</li> </ul>"},{"location":"roadmap/syllabus/#session-12-knowledge-check","title":"Session 12: Knowledge Check","text":"<ul> <li>Format: Quiz / checkpoint on Sessions 1\u201311.</li> <li>Objective: Reinforce understanding of architecture, power, cooling, and design principles.</li> </ul>"},{"location":"roadmap/syllabus/#part-b-infrastructure-in-a-data-center","title":"Part B: Infrastructure in a Data Center","text":""},{"location":"roadmap/syllabus/#session-13-infrastructure-overview","title":"Session 13: Infrastructure Overview","text":"<p>Objectives</p> <ul> <li>Identify key infrastructural elements inside a data center.</li> </ul> <p>Topics</p> <ul> <li>Compute, storage, and networking infrastructure.</li> </ul>"},{"location":"roadmap/syllabus/#session-14-modular-cabling-design","title":"Session 14: Modular Cabling Design","text":"<p>Objectives</p> <ul> <li>Understand structured cabling principles.</li> </ul> <p>Topics</p> <ul> <li>Cable management systems.</li> <li>Fiber vs copper.</li> <li>Scalability and modularity.</li> </ul>"},{"location":"roadmap/syllabus/#session-15-points-of-distribution","title":"Session 15: Points of Distribution","text":"<p>Objectives</p> <ul> <li>Learn cabling distribution methods.</li> </ul> <p>Topics</p> <ul> <li>Main Distribution Area (MDA).</li> <li>Horizontal and Vertical Distribution Areas.</li> </ul>"},{"location":"roadmap/syllabus/#session-16-isp-wan-links","title":"Session 16: ISP WAN Links","text":"<p>Objectives</p> <ul> <li>Plan WAN connectivity for redundancy.</li> </ul> <p>Topics</p> <ul> <li>ISP diversity.</li> <li>Bandwidth provisioning.</li> <li>SLAs and peering.</li> </ul>"},{"location":"roadmap/syllabus/#session-17-network-operations-center-noc","title":"Session 17: Network Operations Center (NOC)","text":"<p>Objectives</p> <ul> <li>Role of NOC in monitoring and management.</li> </ul> <p>Topics</p> <ul> <li>Incident management.</li> <li>Performance monitoring.</li> <li>24x7 operations.</li> </ul>"},{"location":"roadmap/syllabus/#session-18-physical-logical-security-cleaning","title":"Session 18: Physical &amp; Logical Security + Cleaning","text":"<p>Objectives</p> <ul> <li>Apply security best practices in data centers.</li> </ul> <p>Topics</p> <ul> <li>Physical access controls (biometrics, CCTV).</li> <li>Logical access controls.</li> <li>Facility maintenance and cleaning.</li> </ul>"},{"location":"roadmap/syllabus/#session-19-reasons-for-consolidation","title":"Session 19: Reasons for Consolidation","text":"<p>Objectives</p> <ul> <li>Understand drivers for data center consolidation.</li> </ul> <p>Topics</p> <ul> <li>Cost efficiency.</li> <li>Energy savings.</li> <li>Simplified management.</li> </ul>"},{"location":"roadmap/syllabus/#session-20-consolidation-opportunities","title":"Session 20: Consolidation Opportunities","text":"<p>Objectives</p> <ul> <li>Explore real opportunities to consolidate infrastructure.</li> </ul> <p>Topics</p> <ul> <li>Virtualization.</li> <li>Storage consolidation.</li> <li>Cloud migration.</li> </ul>"},{"location":"roadmap/syllabus/#session-21-data-center-servers","title":"Session 21: Data Center Servers","text":"<p>Objectives</p> <ul> <li>Understand server roles and configurations.</li> </ul> <p>Topics</p> <ul> <li>Rack servers, blade servers.</li> <li>High-density configurations.</li> </ul>"},{"location":"roadmap/syllabus/#session-22-server-capacity-planning","title":"Session 22: Server Capacity Planning","text":"<p>Objectives</p> <ul> <li>Forecast compute needs effectively.</li> </ul> <p>Topics</p> <ul> <li>CPU, memory, and storage planning.</li> <li>Workload analysis.</li> <li>Capacity planning tools.</li> </ul>"},{"location":"roadmap/syllabus/#session-23-disaster-recovery","title":"Session 23: Disaster Recovery","text":"<p>Objectives</p> <ul> <li>Implement disaster recovery in data centers.</li> </ul> <p>Topics</p> <ul> <li>RPO and RTO.</li> <li>Backup strategies.</li> <li>DR sites and replication.</li> </ul>"},{"location":"roadmap/syllabus/#session-24-data-center-security-guidelines","title":"Session 24: Data Center Security Guidelines","text":"<p>Objectives</p> <ul> <li>Learn security frameworks and guidelines.</li> </ul> <p>Topics</p> <ul> <li>ISO 27001.</li> <li>NIST Cybersecurity Framework.</li> <li>Vendor security practices.</li> </ul>"},{"location":"roadmap/syllabus/#session-25-internet-security-guidelines","title":"Session 25: Internet Security Guidelines","text":"<p>Objectives</p> <ul> <li>Address security for data center internet access.</li> </ul> <p>Topics</p> <ul> <li>Firewalls and IDS/IPS.</li> <li>DDoS protection.</li> <li>Zero trust.</li> </ul>"},{"location":"roadmap/syllabus/#session-26-source-security-issues","title":"Session 26: Source Security Issues","text":"<p>Objectives</p> <ul> <li>Identify common security issues in data centers.</li> </ul> <p>Topics</p> <ul> <li>Insider threats.</li> <li>Malware and vulnerabilities.</li> <li>Supply chain risks.</li> </ul>"},{"location":"roadmap/syllabus/#session-27-best-practices-in-system-administration","title":"Session 27: Best Practices in System Administration","text":"<p>Objectives</p> <ul> <li>Apply administration best practices.</li> </ul> <p>Topics</p> <ul> <li>Patch management.</li> <li>Backup/restore.</li> <li>Documentation and change management.</li> </ul>"},{"location":"roadmap/syllabus/#session-28-system-administration-automation","title":"Session 28: System Administration Automation","text":"<p>Objectives</p> <ul> <li>Automate routine system administration tasks.</li> </ul> <p>Topics</p> <ul> <li>Scripting basics.</li> <li>Tools for automation (Ansible, Puppet, Chef).</li> <li>Automation benefits and risks.</li> </ul>"},{"location":"roadmap/syllabus/#phase-2-virtualization-cloud","title":"Phase 2 \u2013 Virtualization &amp; Cloud","text":""},{"location":"roadmap/syllabus/#part-a-virtualization","title":"Part A: Virtualization","text":""},{"location":"roadmap/syllabus/#session-1-overview_1","title":"Session 1: Overview","text":"<p>Objectives</p> <ul> <li>Understand the role of virtualization in IT infrastructure.</li> <li>Learn how virtualization underpins cloud computing.</li> </ul> <p>Topics</p> <ul> <li>Definition and benefits of virtualization.</li> <li>Types: server, storage, network, desktop virtualization.</li> </ul>"},{"location":"roadmap/syllabus/#session-2-introduction-to-virtualization","title":"Session 2: Introduction to Virtualization","text":"<p>Objectives</p> <ul> <li>Explore historical context and evolution of virtualization.</li> </ul> <p>Topics</p> <ul> <li>From mainframes to hypervisors.</li> <li>Virtualization use cases in enterprises.</li> </ul>"},{"location":"roadmap/syllabus/#session-3-virtualization-concepts","title":"Session 3: Virtualization Concepts","text":"<p>Objectives</p> <ul> <li>Master key technical concepts of virtualization.</li> </ul> <p>Topics</p> <ul> <li>Hypervisors: Type 1 vs Type 2.</li> <li>VM lifecycle and snapshots.</li> <li>Resource sharing and overhead.</li> </ul>"},{"location":"roadmap/syllabus/#session-4-os-virtualization","title":"Session 4: OS Virtualization","text":"<p>Objectives</p> <ul> <li>Learn how OS-level virtualization differs from hardware virtualization.</li> </ul> <p>Topics</p> <ul> <li>Containers vs VMs.</li> <li>Namespace and cgroups.</li> <li>Use cases: Docker, LXC.</li> </ul>"},{"location":"roadmap/syllabus/#session-5-virtual-clusters","title":"Session 5: Virtual Clusters","text":"<p>Objectives</p> <ul> <li>Understand virtualization in clustered environments.</li> </ul> <p>Topics</p> <ul> <li>High availability clusters.</li> <li>Load balancing.</li> <li>Resource pooling.</li> </ul>"},{"location":"roadmap/syllabus/#lab-03-install-and-configure-virtualbox","title":"Lab 03: Install and Configure VirtualBox","text":"<p>Goal: Set up VirtualBox on host system.</p> <p>Tasks</p> <ul> <li>Install VirtualBox.</li> <li>Create a Linux VM.</li> <li>Test VM networking.</li> <li>Expected Outcome</li> <li>Working VM ready for labs.</li> </ul>"},{"location":"roadmap/syllabus/#lab-04-deploy-multiple-vms","title":"Lab 04: Deploy Multiple VMs","text":"<p>Goal: Practice managing multiple virtual machines.</p> <p>Tasks</p> <ul> <li>Deploy 2+ VMs.</li> <li>Configure networking between them.</li> <li>Expected Outcome</li> <li>Students can simulate cluster basics.</li> </ul>"},{"location":"roadmap/syllabus/#part-b-storage-area-network-san","title":"Part B: Storage Area Network (SAN)","text":""},{"location":"roadmap/syllabus/#session-6-san-overview","title":"Session 6: SAN Overview","text":"<p>Objectives</p> <ul> <li>Understand what SAN is and why it is used.</li> </ul> <p>Topics</p> <ul> <li>SAN vs NAS vs DAS.</li> <li>Enterprise storage challenges.</li> </ul>"},{"location":"roadmap/syllabus/#session-7-san-high-availability","title":"Session 7: SAN High Availability","text":"<p>Objectives</p> <ul> <li>Explore redundancy and failover in SAN.</li> </ul> <p>Topics</p> <ul> <li>Multipathing.</li> <li>Failover clustering.</li> <li>RAID levels.</li> </ul>"},{"location":"roadmap/syllabus/#session-8-san-components","title":"Session 8: SAN Components","text":"<p>Objectives</p> <ul> <li>Identify SAN hardware and software components.</li> </ul> <p>Topics</p> <ul> <li>HBAs, switches, storage arrays.</li> <li>Fibre Channel, iSCSI protocols.</li> </ul>"},{"location":"roadmap/syllabus/#labs-0509-san-hands-on","title":"Labs 05\u201309: SAN Hands-On","text":"<ul> <li>Lab 05: Configure FreeNAS storage.  </li> <li>Lab 06: Connect host to SAN using iSCSI.  </li> <li>Lab 07: Configure multipath and redundancy.  </li> <li>Lab 08: Test high availability failover.  </li> <li>Lab 09: Benchmark SAN performance.  </li> </ul> <p>Expected Outcome: Students gain practical SAN setup and troubleshooting experience.</p>"},{"location":"roadmap/syllabus/#part-c-cloud-computing","title":"Part C: Cloud Computing","text":""},{"location":"roadmap/syllabus/#session-9-introduction-to-cloud-computing","title":"Session 9: Introduction to Cloud Computing","text":"<p>Objectives</p> <ul> <li>Define cloud computing models and services.</li> </ul> <p>Topics</p> <ul> <li>NIST definition of cloud.</li> <li>Service models: IaaS, PaaS, SaaS.</li> <li>Deployment models: Public, Private, Hybrid.</li> </ul>"},{"location":"roadmap/syllabus/#session-10-hyper-converged-infrastructure-hci","title":"Session 10: Hyper-Converged Infrastructure (HCI)","text":"<p>Objectives</p> <ul> <li>Learn how compute, storage, and networking converge in HCI.</li> </ul> <p>Topics</p> <ul> <li>HCI vs traditional data centers.</li> <li>Benefits and challenges.</li> </ul>"},{"location":"roadmap/syllabus/#session-11-openstack","title":"Session 11: OpenStack","text":"<p>Objectives</p> <ul> <li>Explore OpenStack as an open-source cloud platform.</li> </ul> <p>Topics</p> <ul> <li>Keystone, Nova, Glance, Swift, Neutron.</li> <li>OpenStack architecture and use cases.</li> </ul>"},{"location":"roadmap/syllabus/#session-12-software-defined-networking-sdn","title":"Session 12: Software-Defined Networking (SDN)","text":"<p>Objectives</p> <ul> <li>Understand SDN concepts in cloud environments.</li> </ul> <p>Topics</p> <ul> <li>Control plane vs data plane.</li> <li>OpenFlow and network programmability.</li> </ul>"},{"location":"roadmap/syllabus/#lab-10-deploy-openstack-with-devstack","title":"Lab 10: Deploy OpenStack with DevStack","text":"<p>Goal: Set up OpenStack on a VM.</p> <p>Tasks</p> <ul> <li>Install DevStack.</li> <li>Configure Keystone and Nova.</li> <li>Launch a VM instance.</li> <li>Expected Outcome</li> <li>Students get exposure to cloud platform deployment.</li> </ul>"},{"location":"roadmap/syllabus/#session-13-public-cloud-overview","title":"Session 13: Public Cloud Overview","text":"<p>Objectives</p> <ul> <li>Explore major public cloud providers.</li> </ul> <p>Topics</p> <ul> <li>AWS, Azure, GCP basics.</li> <li>Regional availability.</li> </ul>"},{"location":"roadmap/syllabus/#session-14-services-of-public-cloud","title":"Session 14: Services of Public Cloud","text":"<p>Objectives</p> <ul> <li>Understand common cloud services.</li> </ul> <p>Topics</p> <ul> <li>Compute (EC2, VM), Storage (S3, Blob).</li> <li>Networking, Databases.</li> </ul>"},{"location":"roadmap/syllabus/#session-15-cloud-services-comparison","title":"Session 15: Cloud Services Comparison","text":"<p>Objectives</p> <ul> <li>Compare offerings across AWS, Azure, GCP.</li> </ul> <p>Topics</p> <ul> <li>Pricing.</li> <li>Feature availability.</li> <li>Strengths and limitations.</li> </ul>"},{"location":"roadmap/syllabus/#lab-11-launch-instances-in-aws-free-tier","title":"Lab 11: Launch Instances in AWS Free Tier","text":"<p>Goal: Work with public cloud services.</p> <p>Tasks</p> <ul> <li>Create AWS Free Tier account.</li> <li>Launch and connect to EC2.</li> <li>Expected Outcome</li> <li>Students gain first exposure to cloud workloads.</li> </ul>"},{"location":"roadmap/syllabus/#session-16-cloud-api-sdk","title":"Session 16: Cloud API &amp; SDK","text":"<p>Objectives</p> <ul> <li>Learn programmatic access to cloud.</li> </ul> <p>Topics</p> <ul> <li>AWS SDK, Azure CLI, GCP SDK.</li> <li>REST APIs and automation.</li> </ul>"},{"location":"roadmap/syllabus/#session-17-cloud-migration-disaster-recovery","title":"Session 17: Cloud Migration &amp; Disaster Recovery","text":"<p>Objectives</p> <ul> <li>Understand cloud migration strategies.</li> </ul> <p>Topics</p> <ul> <li>Lift and shift vs re-architect.</li> <li>Cloud-based DR solutions.</li> </ul>"},{"location":"roadmap/syllabus/#session-18-configuration-management-in-cloud","title":"Session 18: Configuration Management in Cloud","text":"<p>Objectives</p> <ul> <li>Explore tools for managing cloud infra.</li> </ul> <p>Topics</p> <ul> <li>Ansible, Terraform, CloudFormation.</li> <li>Infrastructure as Code.</li> </ul>"},{"location":"roadmap/syllabus/#session-19-cloud-migration-deep-dive","title":"Session 19: Cloud Migration Deep Dive","text":"<p>Objectives</p> <ul> <li>Execute migration planning and steps.</li> </ul> <p>Topics</p> <ul> <li>Assessment tools.</li> <li>Data transfer methods.</li> </ul>"},{"location":"roadmap/syllabus/#labs-1213-cloud-migration-practice","title":"Labs 12\u201313: Cloud Migration Practice","text":"<ul> <li>Lab 12: Simulate lift-and-shift migration.  </li> <li>Lab 13: Set up backup and restore for DR.  </li> </ul>"},{"location":"roadmap/syllabus/#session-20-cloud-logging-monitoring","title":"Session 20: Cloud Logging &amp; Monitoring","text":"<p>Objectives</p> <ul> <li>Monitor cloud resources effectively.</li> </ul> <p>Topics</p> <ul> <li>CloudWatch, Azure Monitor, GCP Stackdriver.</li> <li>Logging and alerting.</li> </ul>"},{"location":"roadmap/syllabus/#labs-1415-cloud-monitoring","title":"Labs 14\u201315: Cloud Monitoring","text":"<ul> <li>Lab 14: Configure CloudWatch alarms.  </li> <li>Lab 15: Create monitoring dashboards.  </li> </ul> <p>Expected Outcome: Students gain cloud operations and monitoring skills.</p>"},{"location":"roadmap/syllabus/#phase-3-devops","title":"Phase 3 \u2013 DevOps","text":""},{"location":"roadmap/syllabus/#part-a-devops-foundations","title":"Part A: DevOps Foundations","text":""},{"location":"roadmap/syllabus/#session-1-devops-foundations","title":"Session 1: DevOps Foundations","text":"<p>Objectives</p> <ul> <li>Understand the principles and culture of DevOps.</li> <li>Connect DevOps to Agile and Lean practices.</li> </ul> <p>Topics</p> <ul> <li>DevOps definition and goals.</li> <li>Key benefits: faster delivery, collaboration, automation.</li> <li>DevOps lifecycle stages (Plan \u2192 Code \u2192 Build \u2192 Test \u2192 Release \u2192 Deploy \u2192 Operate \u2192 Monitor).</li> </ul>"},{"location":"roadmap/syllabus/#session-2-devops-basic-tools","title":"Session 2: DevOps Basic Tools","text":"<p>Objectives</p> <ul> <li>Explore tools that form the DevOps ecosystem.</li> <li>Learn categories: version control, CI/CD, monitoring, automation.</li> </ul> <p>Topics</p> <ul> <li>Git &amp; GitHub.</li> <li>Jenkins, Docker, Kubernetes.</li> <li>Ansible, Terraform, Prometheus, Nagios.</li> </ul>"},{"location":"roadmap/syllabus/#labs-1621-devops-foundations-tools","title":"Labs 16\u201321: DevOps Foundations Tools","text":"<ul> <li>Lab 16: Git Basics \u2013 Create repo, push/pull, branching.  </li> <li>Lab 17: GitHub Collaboration \u2013 Forking, pull requests, issues.  </li> <li>Lab 18: Jenkins Setup \u2013 Install and run a sample pipeline.  </li> <li>Lab 19: Docker Basics \u2013 Build and run containers.  </li> <li>Lab 20: Docker Compose \u2013 Multi-container application.  </li> <li>Lab 21: Kubernetes (Minikube) \u2013 Deploy containerized application.  </li> </ul> <p>Expected Outcome: Students gain practical experience with the DevOps toolchain.</p>"},{"location":"roadmap/syllabus/#part-b-infrastructure-as-code-iac","title":"Part B: Infrastructure as Code (IaC)","text":""},{"location":"roadmap/syllabus/#session-3-infrastructure-as-code","title":"Session 3: Infrastructure as Code","text":"<p>Objectives</p> <ul> <li>Understand why IaC is critical for DevOps.</li> <li>Compare declarative vs imperative approaches.</li> </ul> <p>Topics</p> <ul> <li>IaC benefits: consistency, speed, scalability.</li> <li>Popular IaC tools.</li> </ul>"},{"location":"roadmap/syllabus/#session-4-terraform","title":"Session 4: Terraform","text":"<p>Objectives</p> <ul> <li>Learn how to define and deploy infrastructure with Terraform.</li> </ul> <p>Topics</p> <ul> <li>Providers, resources, and state files.</li> <li>Terraform workflow: init, plan, apply, destroy.</li> <li>Modules and reusability.</li> </ul>"},{"location":"roadmap/syllabus/#labs-2223-terraform","title":"Labs 22\u201323: Terraform","text":"<ul> <li>Lab 22 (Optional): Install Terraform and explore CLI.  </li> <li>Lab 22: Deploy EC2 instance with Terraform (AWS Free Tier).  </li> <li>Lab 23: Manage multiple resources with Terraform (VPC, subnets, EC2).  </li> </ul> <p>Expected Outcome: Students can provision cloud infrastructure declaratively.</p>"},{"location":"roadmap/syllabus/#part-c-container-orchestration-microservices","title":"Part C: Container Orchestration &amp; Microservices","text":""},{"location":"roadmap/syllabus/#session-5-container-orchestration","title":"Session 5: Container Orchestration","text":"<p>Objectives</p> <ul> <li>Explore orchestration tools and concepts.</li> </ul> <p>Topics</p> <ul> <li>Kubernetes architecture.</li> <li>Pods, services, deployments.</li> <li>Scaling and rolling updates.</li> </ul>"},{"location":"roadmap/syllabus/#session-6-microservices-deployment","title":"Session 6: Microservices Deployment","text":"<p>Objectives</p> <ul> <li>Deploy microservices in containerized environments.</li> </ul> <p>Topics</p> <ul> <li>Microservices vs monoliths.</li> <li>Deployment pipelines for microservices.</li> <li>Service discovery and load balancing.</li> </ul>"},{"location":"roadmap/syllabus/#labs-2425-containers-microservices","title":"Labs 24\u201325: Containers &amp; Microservices","text":"<ul> <li>Lab 24: Build custom Docker image for Nginx app and push to Docker Hub.  </li> <li>Lab 25: Deploy multi-service application on Kubernetes (Minikube).  </li> </ul> <p>Expected Outcome: Students understand end-to-end container orchestration for microservices.</p>"},{"location":"roadmap/syllabus/#part-d-configuration-management-with-ansible","title":"Part D: Configuration Management with Ansible","text":""},{"location":"roadmap/syllabus/#session-7-ansible","title":"Session 7: Ansible","text":"<p>Objectives</p> <ul> <li>Automate server configuration and application deployment.</li> </ul> <p>Topics</p> <ul> <li>Ansible architecture and inventory.</li> <li>Playbooks and roles.</li> <li>Common modules.</li> </ul>"},{"location":"roadmap/syllabus/#labs-2627-ansible","title":"Labs 26\u201327: Ansible","text":"<ul> <li>Lab 26: Install Ansible and configure SSH for target nodes.  </li> <li>Lab 27: Write playbooks to install and start web servers (Apache/Nginx).  </li> </ul> <p>Expected Outcome: Students automate infrastructure tasks with Ansible.</p>"}]}